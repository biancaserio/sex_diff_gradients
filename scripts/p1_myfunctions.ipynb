{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bea96b-720c-4903-b477-e1282b9784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_sub_conn_matrices(path_conn_matrices):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that fetches the connectivity matrices of all subjects from path and stores them in a variable \n",
    "    \n",
    "    Input:\n",
    "    - path containing all the subject connectivity matrices\n",
    "    \n",
    "    Output (dictionary containing):\n",
    "    - conn_matrices: np array contianing the connectivty matrices of all subjects (in the form of 1 np array per subject)\n",
    "    - sub_list: list containing all the subject IDs\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # list that contains all the subject IDs of subjects with fc matrices\n",
    "    sub_list = []\n",
    "\n",
    "    # list that contains the fc matrices of all subjects in the form of 1 np array per subject\n",
    "    conn_matrices = []\n",
    "\n",
    "    # reads (lists) the content of the path containing the list of fc_matrices and stores the sorted contents in as a list in the variable list_fc_matrices\n",
    "    list_conn_matrices = os.listdir(path_conn_matrices)\n",
    "    list_conn_matrices.sort()\n",
    "\n",
    "    for e in list_conn_matrices:\n",
    "        if '.csv' in e:  # need to do this because there is a hidden files in the path_list_fc_matrices\n",
    "\n",
    "            # add subject to the subjects' list\n",
    "            sub_list.append(e.partition(\".\")[0])  # this partitions the subID.csv into a 3-tuple containing ('subID', '.', 'csv'), and I keep only the subID\n",
    "\n",
    "            # reads csv file in the form of an array\n",
    "            sub_matrix = np.genfromtxt(path_conn_matrices + e, delimiter=',')\n",
    "\n",
    "            # add subject's matrix to the fc_matrices_400 list\n",
    "            conn_matrices.append(sub_matrix)\n",
    "\n",
    "    print(f'Connectivity matrices found in path {path_conn_matrices}: N = {len(sub_list)}')\n",
    "    \n",
    "    dict_output = {'conn_matrices': conn_matrices, 'sub_list': sub_list}\n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a341ca3-4eca-414b-a125-d5d3f9da7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_gradients(mean_conn_matrix, display_output = True, data_reduction_algorithm = 'dm', save_screenshot = False, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the mean gradients from mean connectivity matrix (across subjects)\n",
    "    \n",
    "    Input:\n",
    "    - mean_conn_matrix: variable containing mean connectivity matrix across subjects\n",
    "    - display_output: True (default) or False - displays the plots specified below\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output (display):\n",
    "    - mean connectivity matrix + shape\n",
    "    - 3 first mean connectivity gradients\n",
    "    - scree plot of the variance explained by the 10 gradients + printed detail of variance explained and scaled varience explained\n",
    "    \n",
    "    Output:\n",
    "    - mean_grad: the mean gradients, computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    \n",
    "    '''  \n",
    "    \n",
    "    ## compute the mean gradients \n",
    "    \n",
    "    # GradientMaps function used to build the model parameters\n",
    "    mean_grad = GradientMaps(n_components = 10, random_state = 0, approach = data_reduction_algorithm, kernel = 'normalized_angle')\n",
    "\n",
    "    # fit function used to compute the gradients\n",
    "    mean_grad.fit(mean_conn_matrix)\n",
    "    \n",
    "    \n",
    "    if display_output:\n",
    "        \n",
    "        ## plot the mean connectivity matrix and shape\n",
    "        \n",
    "        plt.imshow(mean_conn_matrix)\n",
    "        plt.show()\n",
    "        print(mean_conn_matrix.shape)\n",
    "        \n",
    "        \n",
    "        ## plot the 3 first mean gradients\n",
    "        \n",
    "        # defining labeling scheme and mask\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "        # list containing placeholders (None) for the number of gradients I want to plot\n",
    "        grad = [None] * 3\n",
    "\n",
    "        for i in range(3):\n",
    "            # map the gradient to the parcels\n",
    "            grad[i] = map_to_labels((mean_grad.gradients_)[:, i], labeling, mask=mask, fill=np.nan)  # mean_grad contains 10 .gradients_ (1 gradient per column) - here I take all rows and individual select column based on gradient I want (first 3)\n",
    "\n",
    "        plot = plot_hemispheres(surf_lh, \n",
    "                                surf_rh, \n",
    "                                array_name=grad, \n",
    "                                embed_nb = True, \n",
    "                                size=(1200, 400), \n",
    "                                cmap='viridis_r', \n",
    "                                color_bar=True, \n",
    "                                label_text=['Gradient 1', 'Gradient 2', 'Gradient 3'], \n",
    "                                zoom=1.55,\n",
    "                                screenshot = save_screenshot,\n",
    "                                filename = resdir_fig+sample_modality+'_plotted_hemispheres_mean_gradients.png')\n",
    "        \n",
    "        display(plot)\n",
    "\n",
    "\n",
    "        ## plot the variance explained by the 10 gradients\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(5, 4))\n",
    "        ax.scatter(range(mean_grad.lambdas_.size), mean_grad.lambdas_)\n",
    "        ax.set_title(\"Variance explained by the 10 gradients\")\n",
    "        ax.set_xlabel('Component Nb')\n",
    "        ax.set_ylabel('Eigenvalue')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Total amount of variance explained by the {len(mean_grad.lambdas_)} gradients (uncorrected sum lambdas): {sum(mean_grad.lambdas_):.2f}\\n\")\n",
    "\n",
    "        # Scaled variance explained by individual gradients: lambda / total(i.e., sum lambdas) * 100 %\n",
    "        print(f\"Scaled variance explained by individual gradients:\\nG1: {mean_grad.lambdas_[0]/sum(mean_grad.lambdas_)*100:.2f}%\\nG2: {mean_grad.lambdas_[1]/sum(mean_grad.lambdas_)*100:.2f}%\\nG3: {mean_grad.lambdas_[2]/sum(mean_grad.lambdas_)*100:.2f}%\\n\")\n",
    "\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5b80ad2-1162-4c48-b8ee-b82a54fe2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aligned_gradients(conn_matrices, mean_grad, data_reduction_algorithm = 'dm'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the alligned gradients from all subject connectivity matrices\n",
    "    \n",
    "    Input:\n",
    "    - variable containing all subject connectivity matrices\n",
    "    - array including the mean connectivity gradients\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    \n",
    "    Output (dictionary containing arrays):  \n",
    "    - array_aligned_gradients\n",
    "    - array_aligned_G1\n",
    "    - array_aligned_G2\n",
    "    - array_aligned_G3\n",
    "    \n",
    "    Gradients computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    list_aligned_gradients = []  # will contain all participants (1014), all parcels (400), all gradients (10)\n",
    "    list_aligned_G1 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 1\n",
    "    list_aligned_G2 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 2\n",
    "    list_aligned_G3 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 3\n",
    "\n",
    "    # loop over all the connectivity matrices\n",
    "    for i in range(len(conn_matrices)):\n",
    "        # setting model parameters for gradients to be computed across subjects - with procrustes alignment\n",
    "        grad_procr = GradientMaps(n_components=10, random_state=0, approach = data_reduction_algorithm, kernel='normalized_angle', alignment='procrustes')  # specify alignment method here (procrustes)\n",
    "\n",
    "        # computing\n",
    "        # note that by using an alignment method, .fit yields a variable (grad_procr) containing both types of gradients, callable with: .gradients_ (original) and .aligned_ \n",
    "          # use ._gradients for mean_grad (mean grad was not even calculated with a reference so doesn't have ._aligned) and use .aligned_ for grad_procr \n",
    "\n",
    "        grad_procr.fit(conn_matrices[i], reference=mean_grad)  # align to the gradients of the gradients produced by the mean matrix (reference) \n",
    "\n",
    "        # append array to lists results (.T is necessary in order to be able to first access the gradients layer (10) so that can index the desired gradient, which will then contain all the parcels (400)\n",
    "        list_aligned_gradients.append(grad_procr.aligned_)\n",
    "        list_aligned_G1.append(grad_procr.aligned_.T[0])\n",
    "        list_aligned_G2.append(grad_procr.aligned_.T[1])\n",
    "        list_aligned_G3.append(grad_procr.aligned_.T[2])\n",
    "\n",
    "    # make gradient lists into arrays (for analyses)    \n",
    "    array_aligned_gradients = np.array(list_aligned_gradients)\n",
    "    array_aligned_G1 = np.array(list_aligned_G1)\n",
    "    array_aligned_G2 = np.array(list_aligned_G2)\n",
    "    array_aligned_G3 = np.array(list_aligned_G3)\n",
    "        \n",
    "        \n",
    "    ### dictionary to output\n",
    "    \n",
    "    dict_output = {'array_aligned_gradients': array_aligned_gradients, 'array_aligned_G1': array_aligned_G1, 'array_aligned_G2': array_aligned_G2, 'array_aligned_G3': array_aligned_G3}\n",
    "    \n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef128b14-2ab9-479b-b196-8b0593a98df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison(array_grad, sex_comp = None):\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Function that produced RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sexes\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot of mean gradient loadings across subjects per parcel, color coded by Yeo network, compard by sex\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframe of gradient loadings (shape: sub (vertical) x parcels (horizontal))\n",
    "    df_grad = pd.DataFrame(array_grad)\n",
    "\n",
    "    # adding a column containing the labels for the sex comparison\n",
    "    df_grad[\"sex\"] = sex_comp.tolist()\n",
    "\n",
    "    # separatating the dataframe into two dataframes containing only subjects of the given sex (because need to calculate mean across subjects for each parcel)\n",
    "    df_grad_cat_M = df_grad[df_grad[\"sex\"] == 'M']\n",
    "    df_grad_cat_F = df_grad[df_grad[\"sex\"] == 'F']\n",
    "\n",
    "    # removing the label of sex for the moment because need to have only the parcels in the same column\n",
    "    df_grad_cat_M = df_grad_cat_M.drop('sex', axis=1)\n",
    "    df_grad_cat_F = df_grad_cat_F.drop('sex', axis=1)\n",
    "\n",
    "    # transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    df_grad_cat_M = df_grad_cat_M.T\n",
    "    df_grad_cat_F = df_grad_cat_F.T\n",
    "\n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    df_grad_cat_M['mean gradient loadings across subjects per parcel'] = df_grad_cat_M.mean(axis=1)\n",
    "    df_grad_cat_F['mean gradient loadings across subjects per parcel'] = df_grad_cat_F.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    df_grad_cat_M['yeo network'] = yeo7_networks_array_labels\n",
    "    df_grad_cat_F['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    df_grad_cat_M = df_grad_cat_M[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    df_grad_cat_F = df_grad_cat_F[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # add label of sex for each dataframe before merging them in order to make males and females identifiable for plotting\n",
    "    df_grad_cat_M['sex'] = 'M'\n",
    "    df_grad_cat_F['sex'] = 'F'\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([df_grad_cat_M, df_grad_cat_F], axis = 'index')\n",
    "\n",
    "\n",
    "\n",
    "    ## plot \n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sex\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc26ec4e-7512-4d0e-87c4-bb4ce01f74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison_IndDiff(array_grad, sex_comp = None, plot_type = ['across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate']):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network and optionally by sex \n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "     \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    - plot_type: plot type display - should be one of the following 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot - display according to specified plot_type\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # defining conflicting inputted parameters - error messages\n",
    "    if sex_comp is not None and plot_type == 'across sexes overlayed' or sex_comp is not None and plot_type == 'across sexes separate':\n",
    "        print('ERROR: Conflicting inputted parameters - if you want across sexes, you must input sex_comp = None')\n",
    "    \n",
    "    elif sex_comp is None and plot_type == 'by sex overlayed' or sex_comp is None and plot_type == 'by sex separate':\n",
    "         print('ERROR: Conflicting inputted parameters - if you want by sex, you must provide a variable for sex_comp')\n",
    "            \n",
    "    # if no conflicting parameters, can procede with formatting gradient array for plotting and plotting \n",
    "    else:\n",
    "        \n",
    "        ## format gradient array for plotting\n",
    "        \n",
    "        # dataframe of the G1 loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "        df_grad = pd.DataFrame(array_grad.T)\n",
    "\n",
    "        # adding a column containing the Yeo network labels\n",
    "        df_grad['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "        # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need all subjects to be vertical (1 subject per row) in the dataframe in order to be labeled with their corresponding sex for comparison \n",
    "        df_grad = df_grad.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "        \n",
    "        if sex_comp is None:\n",
    "            df_grad[\"categorical comparison\"] = [1] * len(df_grad)  # making a column of just 1s so that there is no categorical comparison to display (all subject belong in same group)\n",
    "            \n",
    "        else:    \n",
    "            # adding a column containing the labels for the categorical comparison (according to inputted categorical variable\n",
    "            df_grad[\"categorical comparison\"] = sex_comp.tolist()\n",
    "\n",
    "        # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "        df_grad.index.name = \"sub\"\n",
    "        df_grad = df_grad.reset_index()\n",
    "\n",
    "        # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "        # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sex as ID variables\n",
    "        df_grad=pd.melt(df_grad, id_vars=[\"sub\", 'categorical comparison'], var_name='yeo network', value_name='mean gradient loadings across parcels per subject')\n",
    "\n",
    "\n",
    "\n",
    "        ## plot depending on requested plot type\n",
    "\n",
    "        if plot_type == 'across sexes overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "        elif plot_type == 'across sexes separate':    \n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            #hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=True, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex separate':\n",
    "\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"categorical comparison\",\n",
    "                            data=df_grad,\n",
    "                            palette=sns.color_palette(n_colors=2),\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            #figsize=(7,5),  # DELETE THIS\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65, \n",
    "                            dodge=True)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: mis-specified plot_type. Please choose from: 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a1f7d1c0-f2be-466b-a3e2-12455804c3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reg_results_R(reg_res, save_screenshot = False, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    Function that plots regression results coming from R script (t-values, p-values, FDR corrected q-values, and t-values corresponding to sig FDR corrected q values)\n",
    "    \n",
    "    Input: \n",
    "    - reg_res: slm results dataframe containing vales with the following names: t_val_sex, p_val_sex, q_val_sex (*** HARCODED WITH \"sex\" IN NAME - CHANGE THIS TO SIMPLY t_val IF I START USING THIS VISUALIZATION FUNCTION FOR OTHER R RESULTS ***)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ### t-values\n",
    "    tvals_mapped_to_labels = map_to_labels(np.asarray(reg_res.t_val_sex), labeling, mask=mask, fill=np.nan)  # t[0] because there is a double bracket for the t-values array, need [0] to access the values themselves\n",
    "    \n",
    "    tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"t-values\"],\n",
    "        zoom = 1.45, \n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_sex_contrast_t_val.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append(tvals_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ### p-values (uncorrected)\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    pvals = np.asarray(reg_res.p_val_sex.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(pvals, pvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    pvals_mapped_to_labels = map_to_labels(pvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values (uncorr.)\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_sex_contrast_p_val.png')\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)    \n",
    "        \n",
    "        \n",
    "                   \n",
    "    ### Q-values\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    Qvals = np.asarray(reg_res.q_val_sex.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(Qvals, Qvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    Qvals_mapped_to_labels = map_to_labels(Qvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    Qvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = Qvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"Q-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_sex_contrast_q_val.png')\n",
    "    \n",
    "    handles.append(Qvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    ### t-values (only FDR-corrected) showing sex differences\n",
    "    \n",
    "    ## find t-values\n",
    "    fdr_corrected_tvals = []\n",
    "    \n",
    "    for i in range(len(reg_res.q_val_sex)):\n",
    "        if reg_res.q_val_sex[i] <= 0.05:\n",
    "            fdr_corrected_tvals.append(reg_res.t_val_sex[i])\n",
    "        else:\n",
    "            fdr_corrected_tvals.append(float('nan'))\n",
    "    \n",
    "    fdr_corr_tvals_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"t-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_sex_contrast_t_val_fdr_corr.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append('t-values for FDR-corrected q < 0.05: (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)\n",
    "    \n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ef648a5c-344b-4736-bc7b-d80c9d9d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_contrast_results_breakdown_by_network(reg_res, contrast_type, scatterplot = True, scatter_x = None, scatter_y = None, scatter_x_label = None, scatter_y_label = None, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that outputs the breakdown of regression contrast results by network\n",
    "    \n",
    "    Input:\n",
    "    - reg_res: regression results (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - contrast type: string indicating the contrast that is being studied, e.g., 'sex' (for plot titles)\n",
    "    - scatter_x: x-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_y: y-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_x_label, scatter_y_label\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output (display):\n",
    "    - written breakdown (number and proportion of significant parcels by network (relative proportion (i.e., out of all the parcels belonging to a given network) and absolute proportion (i.e., out of the total significant results)\n",
    "    - plotted breakdown (pie chart) - proportion of significant parcels by network (absolute proportion)\n",
    "    - plotted breakdown by sex (nested pie chart) - proportion of significant parcels by network (absolute proportion) by sex <- !!! HARDCODED M vs F labels !!! - color coding with original Yeo network colors\n",
    "    - plotted breadown by sex (nested pie chart) - same as above, WITHOUT LABELS\n",
    "    - Violin plot of t-values (regression results) by Yeo network\n",
    "    - scatter plot showing of G1 vs G2, displaying parcels showing a significant contrast in dark\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### written breakdown\n",
    "    \n",
    "    # counting number of significant parcels\n",
    "    # storing the Q values in a list (where non significant Q values are marked as 1 -> for later potential scatterplot visualization)\n",
    "    # making a dictionary that counts the number of significant parcels per yeo network\n",
    "    # making dictionaries that count the number of significant parcels per yeo network by sex\n",
    "    \n",
    "    sig_Q_vals_slm = []\n",
    "    count_sig = 0\n",
    "    count_sig_M = 0\n",
    "    count_sig_F = 0\n",
    "    count_sig_per_network = {\"visual\": 0, \"sensory motor\": 0, \"DMN\": 0, \"dorsal attention\": 0, \"ventral attention\": 0, \"limbic\": 0, \"fronto parietal\": 0}\n",
    "    count_sig_per_network_bysex = {\"visual\": [0, 0], \"sensory motor\": [0,0], \"DMN\": [0,0], \"dorsal attention\": [0,0], \"ventral attention\": [0,0], \"limbic\": [0,0], \"fronto parietal\": [0,0]} # M: [0], F: [1]\n",
    "    \n",
    "    for i in range(len(reg_res.q_val_sex)):\n",
    "    \n",
    "        if reg_res.q_val_sex[i] < 0.05:\n",
    "            count_sig += 1\n",
    "            count_sig_per_network[yeo7_networks_array_labels[i]] += 1\n",
    "            sig_Q_vals_slm.append(1)\n",
    "    \n",
    "            # positive t-values mean male > female: increment the first item of the list fort given label\n",
    "            if reg_res.t_val_sex[i] > 0:\n",
    "                count_sig_M += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][0] += 1\n",
    "            \n",
    "            # positive t-values mean female > male: increment the second item of the list for the given label\n",
    "            else:\n",
    "                count_sig_F += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][1] += 1\n",
    "        \n",
    "        else:\n",
    "            sig_Q_vals_slm.append(0)\n",
    "    \n",
    "    print(f\"Number of significant parcels: {count_sig}\\n\")\n",
    "    print(f\"Number of significant parcels for males: {count_sig_M}\")\n",
    "    print(f\"Number of significant parcels for females: {count_sig_F}\\n\")\n",
    "    print(\"Number of significant parcels in each Yeo network (across sexes):\")\n",
    "    \n",
    "    # using ANSI escape sequences to underline -> bold: \\033[1m ; underline: \\033[4m ; end: \\033[0m\n",
    "    for i in range(len(count_sig_per_network)):\n",
    "        print(f\"- {list(count_sig_per_network.keys())[i]}: \\033[4m{count_sig_per_network[list(count_sig_per_network.keys())[i]]}\\033[0m out of {yeo7_networks_array_labels.tolist().count(network_names[i])} ({round(count_sig_per_network[list(count_sig_per_network.keys())[i]] / yeo7_networks_array_labels.tolist().count(network_names[i]) * 100, 2)}%) -> \\033[1m{round(count_sig_per_network[list(count_sig_per_network.keys())[i]]*100/count_sig,2)}%\\033[0m of overall significance\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Pie chart breakdown per network\n",
    "    \n",
    "    # setting figure size\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 7))\n",
    "    \n",
    "    # data to plot: in dictionary count_sig_per_network\n",
    "    network_labels = []\n",
    "    data = []\n",
    "    \n",
    "    for x, y in count_sig_per_network.items():\n",
    "        network_labels.append(x)\n",
    "        data.append(y)\n",
    "    \n",
    "    # define color palette to use\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # color palette matching the raincloudplot colors (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt\n",
    "                    (185/255, 163/255, 204/255),\n",
    "                    (120/255, 162/255, 189/255),\n",
    "                    (236/255, 170/255, 119/255),\n",
    "                    (174/255, 147/255, 143/255),\n",
    "                    (216/255, 128/255, 129/255),\n",
    "                    (128/255, 183/255, 126/255)]\n",
    "    \n",
    "    # plot pie chart\n",
    "    ax.pie(data,\n",
    "           labels = network_labels, colors = color_palette, autopct='%.0f%%',\n",
    "           wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},\n",
    "           textprops={'fontsize': 20})\n",
    "    \n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant {contrast_type} difference in gradient loadings', y=1.03, fontsize=20)\n",
    "    \n",
    "    # display\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Nested pie chart\n",
    "    \n",
    "    ## make data plottable\n",
    "    list_count_sig_per_network_bysex = []\n",
    "    \n",
    "    for label in count_sig_per_network_bysex:\n",
    "        list_count_sig_per_network_bysex.append(count_sig_per_network_bysex[label])\n",
    "    \n",
    "    vals = np.array(list_count_sig_per_network_bysex)\n",
    "    \n",
    "    outer_colors = [\"darkorchid\",  # visual\n",
    "                    \"steelblue\",  # sensorimotor\n",
    "                    \"indianred\",  # dmn\n",
    "                    \"forestgreen\",  # dorsal attention\n",
    "                    \"orchid\",  # ventral attention\n",
    "                    \"lemonchiffon\",  # limbic\n",
    "                    \"orange\"]  # frontoparietal\n",
    "    inner_colors = ['lightblue', 'lightcoral',  # visual\n",
    "                    'lightblue', 'lightcoral',  # sensorimotor\n",
    "                    'lightblue', 'lightcoral',  # dmn\n",
    "                    'lightblue', 'lightcoral',  # dorsal attention\n",
    "                    'lightblue', 'lightcoral',  # ventral attention\n",
    "                    'lightblue', 'lightcoral',  # limbic\n",
    "                    'lightblue', 'lightcoral']  #frontoparietal\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    size = 0.3\n",
    "    \n",
    "    ## plot outer pie\n",
    "    ax.pie(vals.sum(axis=1), radius=1, labels=count_sig_per_network_bysex.keys(), colors=outer_colors, autopct='%.0f%%', pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    ## plot inner pie\n",
    "    \n",
    "    # make a list (in order) containing the labels (sex - hardcoded) only for sections that have more than 1 count (otherwise label is placeholder: blank)\n",
    "    \n",
    "    labels_only_show_non_null = []\n",
    "    \n",
    "    for network in list_count_sig_per_network_bysex:\n",
    "    \n",
    "        # males\n",
    "        if network[0] > 0:\n",
    "            labels_only_show_non_null.append('M')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "        \n",
    "        # females\n",
    "        if network[1] > 0:\n",
    "            labels_only_show_non_null.append('F')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "    \n",
    "    ax.pie(vals.flatten(), radius=1-size, labels=labels_only_show_non_null, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    ax.set(aspect=\"equal\")\n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant {contrast_type} difference in gradient loadings, by {contrast_type}', y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print('Number of significant parcels by sex:')\n",
    "    for network in count_sig_per_network_bysex:\n",
    "        print(f\"{network} - Male: {count_sig_per_network_bysex[network][0]}, Female: {count_sig_per_network_bysex[network][1]}\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### plot outer and inner pie (without labels)\n",
    "    \n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "    \n",
    "    disp.pie(vals.sum(axis=1), radius=1, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='blacK'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    disp.set(aspect=\"equal\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## save figure in directory \n",
    "    fig.savefig(resdir_fig+sample_modality+'_pie_chart_sex_diff_netw.png', dpi=300)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Violin plot of t-values (regression results) by Yeo network\n",
    "    \n",
    "    print(\"Violin plot of t-values (regression results) by Yeo network\")\n",
    "    \n",
    "    df_to_plot = pd.DataFrame(reg_res.t_val_sex)\n",
    "    \n",
    "    df_to_plot['yeo network'] = yeo7_networks_array_labels\n",
    "    \n",
    "    # color palette matching the raincloudplot colors (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,5));\n",
    "    \n",
    "    ax = sns.violinplot(data=df_to_plot,\n",
    "                        x=\"yeo network\",\n",
    "                        y=\"t_val_sex\",\n",
    "                        #hue=\"\",\n",
    "                        palette = color_palette,\n",
    "                  )\n",
    "    \n",
    "    \n",
    "    ### plot of significant parcels on G1 vs G2 visualization\n",
    "    \n",
    "    # problems with this plot\n",
    "        # hard-coded axes labels and title (G1 vs G2)\n",
    "        # legend of colors: showing 0 vs 1\n",
    "    \n",
    "    if scatterplot:\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize = (6,5));\n",
    "        \n",
    "        ax = sns.scatterplot(x = scatter_x,\n",
    "                             y = scatter_y,\n",
    "                             hue = sig_Q_vals_slm,  # gives color coding based on Q value of sex contrast (main model including age, sex, icv) -> dark color: significance\n",
    "                             palette = sns.color_palette([\"lavender\", \"navy\"]),\n",
    "                             legend = True, ax = ax);\n",
    "        \n",
    "        ax.set_xlabel(scatter_x_label, fontsize=20);\n",
    "        ax.set_ylabel(scatter_y_label, fontsize=20);\n",
    "        ax.set_title(f'Scatter plot of G1 vs G2, showing significant {contrast_type} contrast in dark', y=1.05, fontsize=20)\n",
    "        ax.spines['right'].set_visible(False);\n",
    "        ax.spines['top'].set_visible(False);\n",
    "        #plt.legend(title='1 = FDR-corr significance')\n",
    "        \n",
    "        plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dae2cfcf-09ee-4273-a0af-19464744ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot_corr_networks(x, y, x_label, y_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    - correlations between 2 variables, both overall and per network\n",
    "    - scatterplots colorcoded by yeo network, with regression lines per network\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### creating a dataframe in order to have the data in the correct format to be plotted\n",
    "    temp_dict = {x_label: x, y_label: y, 'yeo_network': yeo7_networks_array_labels}  \n",
    "    dataframe = pd.DataFrame(data = temp_dict)\n",
    "    \n",
    "\n",
    "    ### print overall correlation\n",
    "    print(f\"Overall Pearson correlation between {x_label} and {y_label}: r = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[0], 2)}; p = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[1], 3)}\\n\")\n",
    "    \n",
    "    \n",
    "    network_labels = ['visual', 'sensory motor', 'dorsal attention', 'ventral attention', 'limbic', 'fronto parietal', 'DMN']\n",
    "\n",
    "    for i in range(len(network_labels)):\n",
    "        \n",
    "        corr_coef = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[0]\n",
    "        p_val = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[1]\n",
    "        \n",
    "        print(f\"{network_labels[i]}: r = {round(corr_coef, 2)}, p = {round(p_val, 3)}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ### scatter plot color-coded by network, with regression lines \n",
    "        \n",
    "    # color palette matching the RainCloud plot colors - specifying otherwise switches colors visual-DMN in the oder direction\n",
    "    # (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt)\n",
    "\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    # plot\n",
    "    \n",
    "    sns.lmplot(x = x_label, y = y_label, \n",
    "           hue = 'yeo_network',\n",
    "           data = dataframe,\n",
    "           palette = color_palette, \n",
    "           ci = False)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    plt.title(f\"Correlation between {x_label} and {y_label}\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bc5d4c8-1251-449e-9c7d-02715e1e27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpinPermutationTest_PearsonCorr_Schaefer400(x, y):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that conducts spin permutation testing (for pearson correlation) specifically for data in Schaefer400 parcellation (len = 400) \n",
    "    \n",
    "    Input:\n",
    "    - x: data to correlate (len = 400) \n",
    "    - y: data to correlate (len = 400) \n",
    "    \n",
    "    Output (display):  \n",
    "    - spin permutation p-value\n",
    "    - plotted null distribution of generated correlations\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Project gradient loadings (from Schaefer 400 parcellation) to fsaverage5's 20484 vertices\n",
    "    \n",
    "    sample_1_fs5_grad_loadings = []\n",
    "    sample_2_fs5_grad_loadings = []\n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            sample_1_fs5_grad_loadings.append(0)\n",
    "            sample_2_fs5_grad_loadings.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the unimodal-heteromodal gradient eigenvalue of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            sample_1_fs5_grad_loadings.append(x[schaefer_400_fs5[i]-1])\n",
    "            sample_2_fs5_grad_loadings.append(y[schaefer_400_fs5[i]-1])\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings\n",
    "    sample_1_fs5_grad_loadings[sample_1_fs5_grad_loadings == 0] = np.nan\n",
    "    sample_2_fs5_grad_loadings[sample_2_fs5_grad_loadings == 0] = np.nan\n",
    "\n",
    "    # transform list into array\n",
    "    sample_1_fs5_grad_loadings = np.asarray(sample_1_fs5_grad_loadings)\n",
    "    sample_2_fs5_grad_loadings = np.asarray(sample_2_fs5_grad_loadings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Spin permutation testing \n",
    "    \n",
    "    # spin permutation testing for two cortical maps (output of spin_test is the p-value and the null distribution)\n",
    "    spin_test_p, spin_test_d = spin_test(sample_1_fs5_grad_loadings, sample_2_fs5_grad_loadings, surface_name='fsa5', parcellation_name='aparc', type='pearson', n_rot=1000, null_dist=True)\n",
    "    \n",
    "    \n",
    "    # print spin permutation test\n",
    "    print(f\"Spin permutation test p-value: {spin_test_p}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plot null distribution of generated correlations\n",
    "    \n",
    "    # To better interpret statistical significance, we can plot the null distribution of generated correlations (i.e., spun or shuffled correlations) and overlay the correlation coefficient obtained from the empirical (i.e., real) brain maps.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(15, 3))\n",
    "\n",
    "    ax.hist(spin_test_d, bins=50, density=True, color=\"blue\", edgecolor='white', lw=0.5)\n",
    "    ax.set_xlabel('Null correlations')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Null distribution of generated correlations')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98a7ddf0-e1e3-48cc-9fbd-662db11ba4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    Function that produces RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sample\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients, i.e., mean gradient loadings across subjects per parcel, color coded by Yeo network, compared across samples \n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframes of gradient loadings - transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "    \n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    array_grad_sample_1['mean gradient loadings across subjects per parcel'] = array_grad_sample_1.mean(axis=1)\n",
    "    array_grad_sample_2['mean gradient loadings across subjects per parcel'] = array_grad_sample_2.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    array_grad_sample_1 = array_grad_sample_1[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    array_grad_sample_2 = array_grad_sample_2[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows) before merging them in order to make samples identifiable for plotting\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "    \n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    # color palette matching the RainCloud plot colors - specifying otherwise switches colors visual-DMN in the oder direction\n",
    "    # (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt)\n",
    "\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=color_palette,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=1,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9576114-3ca3-496d-abcb-4e3bfa4fc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad_IndDiff(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network by sample\n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients \n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "    \n",
    "    # dataframe of the gradient loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need the all subjects to be vertical in the dataframe in order to be labeled with their corresponding sample \n",
    "    array_grad_sample_1 = array_grad_sample_1.groupby(\"yeo network\", as_index=True).mean().T\n",
    "    array_grad_sample_2 = array_grad_sample_2.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    array_grad_sample_1.index.name = \"sub\"\n",
    "    array_grad_sample_1 = array_grad_sample_1.reset_index()\n",
    "\n",
    "    array_grad_sample_2.index.name = \"sub\"\n",
    "    array_grad_sample_2 = array_grad_sample_2.reset_index()\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sample lable as ID variables\n",
    "    df_to_plot = pd.melt(df_to_plot, id_vars=[\"sub\", 'sample'], var_name='yeo network', value_name='mean grad loadings per yeo network')\n",
    "\n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean grad loadings per yeo network\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=sns.color_palette(n_colors=7),\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a5bab3-dd16-4d8e-9d9b-d03d328d4ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sig_overlap(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_screenshot = False, modality = None):\n",
    "    \n",
    "    '''\n",
    "    Function that displays the overlap of signficant sex differences\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - sample_1_label: e.g., \"GSP G2\"\n",
    "    - sample_2_label: e.g., \"HCP G1\"\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_grad (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output display:\n",
    "    - printed text \"Number of parcels that show statistically significant sex differences\"\n",
    "    - plotted hemispheres: overlap of significant sex differences across samples: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant\n",
    "    - plotted hemispheres: which dataset shows significant sex difference\n",
    "    - plotted hemispheres: parcels showing sex differences in opposite directions (if any)\n",
    "    - plotted hemispheres: mean t-values for parcels showing an overlap of significant FDR-corrected statistical difference across samples (showing the same directionality of effects - opposite effects (different signs) are marked as nan) \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### mormat data to plot\n",
    "    \n",
    "    q_vals_sig_overlap = []  # significant sex differences (per parcel): 2 = in both datasets, 1 = in one dataset only, 0 = not significant in any dataset\n",
    "    sample1_v_sample2_sig = []  # which dataset shows significant sex difference (per parcel): +1 = sample 1, -1 = sample 2, 0 = both datasets, nan = not significant in any dataset\n",
    "    fdr_corrected_tvals_sample_1 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    fdr_corrected_tvals_sample_2 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    \n",
    "    for i in range(len(reg_res_sample_1.q_val_sex)):\n",
    "\n",
    "        count_sig = 0\n",
    "        sample1_v_sample2 = 0\n",
    "        not_sig_at_all = True\n",
    "\n",
    "        # sample 1\n",
    "        \n",
    "        if reg_res_sample_1.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 += 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "            # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(reg_res_sample_1.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # sample 2\n",
    "        \n",
    "        if reg_res_sample_2.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 -= 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "             # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(reg_res_sample_2.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # non significance\n",
    "        \n",
    "        if not_sig_at_all:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # if no significant we want to save as 0\n",
    "            sample1_v_sample2_sig.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "\n",
    "        else:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # append the sig counts in sig overlap\n",
    "            sample1_v_sample2_sig.append(float(sample1_v_sample2))  # append which sample showd significance (final interpretation: +1 = sample 1, -1 = sample 2, 0 = both samples\n",
    "    \n",
    "    \n",
    "    # check whether the directionality of sex differences is the same in the regions that overlap -> append to \"flags\" variable\n",
    "    \n",
    "    flags = []\n",
    "\n",
    "    for i in range(len(q_vals_sig_overlap)):\n",
    "\n",
    "        if q_vals_sig_overlap[i] == 2:\n",
    "\n",
    "            # if the sign of the t value is the same in GSP and HCP (either (+ and +) or (- and -), then append nan for no problem\n",
    "            if (reg_res_sample_1.t_val_sex[i] > 0 and reg_res_sample_2.t_val_sex[i] > 0) or (reg_res_sample_1.t_val_sex[i] < 0 and reg_res_sample_2.t_val_sex[i] < 0):\n",
    "                flags.append(float('nan'))\n",
    "\n",
    "            # else flag the problem with 1\n",
    "            else:\n",
    "                flags.append(float(1))\n",
    "\n",
    "        else:\n",
    "            flags.append(float('nan'))\n",
    "            \n",
    "            \n",
    "            \n",
    "    # mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "\n",
    "    fdr_corrected_tvals_overlap = []  \n",
    "    \n",
    "    for i in range(len(fdr_corrected_tvals_sample_1)):\n",
    "        \n",
    "        # if either (or both) samples is nan, append nan to overlap\n",
    "        if np.isnan(fdr_corrected_tvals_sample_1[i]) or np.isnan(fdr_corrected_tvals_sample_2[i]):\n",
    "            fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "        \n",
    "        # if there is a recorded t-value for both (not nan)\n",
    "        else:\n",
    "            # if the t values have the same sign (ie same direction of effects): take the mean t value\n",
    "            if np.sign(fdr_corrected_tvals_sample_1[i]) == np.sign(fdr_corrected_tvals_sample_2[i]):\n",
    "                fdr_corrected_tvals_overlap.append(statistics.mean((fdr_corrected_tvals_sample_1[i], fdr_corrected_tvals_sample_2[i])))\n",
    "            \n",
    "            # if different signs (ie different direction of effects): append nan\n",
    "            else:\n",
    "                fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "\n",
    "                \n",
    "    \n",
    "    \n",
    "    ### Plotting\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)  #len(labeling) = 64984 (i.e., conte69? at least matches as works with conte69 hemispheres)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0  # do not consider 0 labels which correspond to the midline\n",
    "    \n",
    "    # to be displayed\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## sig q vals correspondance\n",
    "    q_vals_sig_mapped_to_labels = map_to_labels(np.array(q_vals_sig_overlap), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    q_vals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = q_vals_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'Greens', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_fdr_corr.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append('Overlap of significant sex differences: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant')  # title\n",
    "    handles.append(q_vals_plotted_hemispheres)  # plot\n",
    "\n",
    "\n",
    "    \n",
    "    ## sample 1 or sample 2 significance \n",
    "    sample1_v_sample2_sig_mapped_to_labels = map_to_labels(np.array(sample1_v_sample2_sig), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    sample1_v_sample2_sig_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = sample1_v_sample2_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'RdYlGn_r', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sample_showing_sex_diff.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'Which dataset shows significant sex difference: +1 (red) {sample_1_label}, -1 (green) = {sample_2_label}, 0 (yellow) = both datasets, nan (grey) = not significant in any dataset')  # title\n",
    "    handles.append(sample1_v_sample2_sig_plotted_hemispheres)  # plot\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Plot the location of the flagged parcels where the directionality of the overalpping sex differences significant across samples isnt the same (if there are any)\n",
    "\n",
    "    if flags.count(1) > 0:\n",
    "\n",
    "        # defining labeling scheme and mask\n",
    "        # ! if doesn't work anymore for some reason, take this out of the definition (put it before it) !\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "\n",
    "        ### flagged parcels\n",
    "        flagged_mapped_to_labels = map_to_labels(np.array(flags), labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "        flagged_plotted_hemispheres = plot_hemispheres(\n",
    "            surf_lh, \n",
    "            surf_rh, \n",
    "            array_name = flagged_mapped_to_labels, \n",
    "            embed_nb = True, \n",
    "            size = (1400,200), \n",
    "            cmap = 'Reds_r', \n",
    "            color_bar = True, \n",
    "            #color_range = color_range_t,\n",
    "            nan_color = (0.7, 0.7, 0.7, 1),\n",
    "            #label_text = [\"overlap of significant sex differences\"],\n",
    "            zoom = 1.45,\n",
    "            screenshot = save_screenshot,\n",
    "            filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_opposing_directions.png')\n",
    "\n",
    "        # append to what will be displayed\n",
    "        handles.append('Parcels showing sex differences in opposite directions')  # title\n",
    "        handles.append(flagged_plotted_hemispheres)  # plot\n",
    "        \n",
    "        \n",
    "        \n",
    "    ## mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "    \n",
    "    fdr_corr_tvals_overlap_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals_overlap), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_overlap_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"t-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_mean_t_val.png')\n",
    "\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'mean t-values for overlapping significant parcels (FDR-corrected, q < 0.05) across samples (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)  # plot\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Print significant overlap results\n",
    "    \n",
    "    print(f\"Number of parcels that show statistically significant sex differences across datasets: {q_vals_sig_overlap.count(2)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_1_label} only: {sample1_v_sample2_sig.count(1)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_2_label} only: {sample1_v_sample2_sig.count(-1)}\")\n",
    "    print(f\"Number of parcels (out of the {q_vals_sig_overlap.count(2)} parcels that show sig sex differences in both datasets) which show sex differences in opposite directions: {flags.count(1)}\\n\")\n",
    "\n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "312b19aa-9381-44bb-8966-77a41dbb05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_tval(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_violin_plot = False, title = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that produces Rain Cloud and violin plots of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    Input:\n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    - save_violin_plot: True or False to save violin plot in resdir_fig\n",
    "    - modality: string e.g., local_ct or fc_grad\n",
    "    \n",
    "    Output (display):  \n",
    "    - printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "    - RainCloudPlot displaying sample 1 and 2 t-values \n",
    "    - Violin plot displaying sample 1 and 2 t-values\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "\n",
    "    list_samples = [reg_res_sample_1, reg_res_sample_2]\n",
    "    list_sample_labels = [sample_1_label, sample_2_label]\n",
    "\n",
    "    for e in range(len(list_samples)):\n",
    "    \n",
    "        # to record significant t-values (by sex)\n",
    "        tvals_sig_pos = []  # positive t-values == higher eignevalues in M\n",
    "        tvals_sig_neg = []  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        # to record the number of significant t-values per network (by sex)\n",
    "        dict_networks_sig_pos = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # positive t-values == higher eignevalues in M\n",
    "        dict_networks_sig_neg = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        for i in range(len(list_samples[e])):\n",
    "            if list_samples[e].iloc[i].q_val_sex < 0.05:\n",
    "                if list_samples[e].iloc[i].t_val_sex > 0:\n",
    "                    tvals_sig_pos.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_pos[yeo7_networks_array_labels[i]] += 1\n",
    "                else:\n",
    "                    tvals_sig_neg.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_neg[yeo7_networks_array_labels[i]] += 1\n",
    "\n",
    "        print(f\"Minimum positive significant t-value in {list_sample_labels[e]}: {round(min(tvals_sig_pos), 2)}\\nMinimum negative significant t-value in {list_sample_labels[e]}: {round(max(tvals_sig_neg), 2)}\\n\")\n",
    "        print(f\"Number of positive significant t-values (M > F (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_pos)} -> by network: {dict_networks_sig_pos}\\nNumber of negative significant t-values (F > M (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_neg)} -> by network: {dict_networks_sig_neg}\\n\\n\")\n",
    "\n",
    "        \n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "\n",
    "    # dataframe of the t-values \n",
    "    sample_1_tval = pd.DataFrame(reg_res_sample_1.t_val_sex)\n",
    "    sample_2_tval = pd.DataFrame(reg_res_sample_2.t_val_sex)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    sample_1_tval['yeo network'] = yeo7_networks_array_labels\n",
    "    sample_2_tval['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    sample_1_tval[\"sample\"] = sample_1_label\n",
    "    sample_2_tval[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    sample_1_tval.index.name = \"parcel\"\n",
    "    sample_1_tval = sample_1_tval.reset_index()\n",
    "\n",
    "    sample_2_tval.index.name = \"parcel\"\n",
    "    sample_2_tval = sample_2_tval.reset_index()\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets) -> already in the correct shape for the Raincloudplot\n",
    "    df_all_tval = pd.concat([sample_1_tval, sample_2_tval], axis = 'index')\n",
    "\n",
    "\n",
    "    \n",
    "    ### Rain Cloud plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    print(\"Rain Cloud plot of t-values (regression results) by Yeo network by sample\")\n",
    "\n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"t_val_sex\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_all_tval,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    \n",
    "    #ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    \n",
    "    \n",
    "    ### Violin plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    fig, eg = plt.subplots(figsize = (15,5))\n",
    "    eg = sns.violinplot(data=df_all_tval, \n",
    "                        x=\"yeo network\", \n",
    "                        y=\"t_val_sex\",\n",
    "                        hue=\"sample\",\n",
    "                        palette = ['firebrick', 'darkolivegreen'],\n",
    "                        split = True)       \n",
    "    \n",
    "    eg.axes.set_title(\"Violin plot of t-values (sex contrast) by Yeo network\", y=1.05, fontsize=20)\n",
    "    eg.set_xlabel(\"Yeo network\",fontsize=25)\n",
    "    eg.set_ylabel(\"t-value sex contrast\",fontsize=25)\n",
    "    eg.tick_params(labelsize=25)\n",
    "    eg.set_xticklabels(eg.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    eg.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    \n",
    "    if save_violin_plot:\n",
    "         ## save figure in directory \n",
    "        fig.savefig(resdir_fig+title+'_violin_sex_contrast_tval_netw.png', dpi=300, bbox_inches=\"tight\")  # bbox_inches is so that the figure doesn't get cut off when saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15867ed4-aa43-49f2-88ad-c8616381023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_surface_to_parcel_for_all_subjects(surface_level_across_subs, surface_atlas_to_parcellation = ['schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69']):\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    Function that reshapes data from surface-level to parcel-level\n",
    "    \n",
    "    Input:\n",
    "    - surface_level_across_subs: surface level data (i.e., vertices) across subjects in format: N x vertices\n",
    "    - surface_atlas_to_parcellation: what surface atlas (e.g., fsa5 (20484 vertices), conte69 (64984 vertices)) needs to be converted into what parcellation scheme (e.g., Schaefer 400)\n",
    "        - possible string options: 'schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69'\n",
    "        - Note: ONLY USE ON CONVERSION TO SCHAEFER 400 (hardcoded removal of first element yielded by the enigmatoolbox surface_to_parcel function, corresponding to midline (1st out of 401 parcels)\n",
    "                 Need to see manually what comes out of function for other pacellation schemes\n",
    "    \n",
    "    Output:\n",
    "    - dictionary containing: \n",
    "        - parcel_level_all_subs: data in parcellated format\n",
    "        - mean_across_parcels: mean value (of whatever is being manipulated here, e.g., CT) across surface/parcels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import enigma toolbox function surface_to_parcel\n",
    "    from enigmatoolbox.utils.parcellation import surface_to_parcel \n",
    "    \n",
    "    \n",
    "    # define list that will contain the data in new parcellated format\n",
    "    parcel_level_all_subs = []\n",
    "    \n",
    "    # define list that will contain the mean value (of whatever is being computed here) across surface/parcels\n",
    "    mean_across_parcels = []\n",
    "    \n",
    "\n",
    "    ### get the CT data in Schaefer 400 format for all subjects\n",
    "    \n",
    "    # iterate over the number of subjects (surface_level_across_subs is in N x vertices format)\n",
    "    for i in range(len(surface_level_across_subs)):\n",
    "\n",
    "        # transform surface data to parcellated data using enigma toolbox function, according to specified surface_atlas_to_parcellation schemes\n",
    "        sub_parcel_level = surface_to_parcel(surface_level_across_subs[i], surface_atlas_to_parcellation)  # enigmatoolbox function transforming to Schaefer 400 yields array len = 401 (including midline as first array element)\n",
    "\n",
    "        # deleting first element (index = 0) of the array corresponding to midline in order to yield Schaefer 400 (len = 400) parcellated data\n",
    "        sub_parcel_level = np.delete(sub_parcel_level, 0) \n",
    "\n",
    "        # appending current subject's values for all parcels to list of parcel-level values for all subjects \n",
    "        parcel_level_all_subs.append(sub_parcel_level)\n",
    "\n",
    "        # appending current subject's mean value (across parcels) to corresponding list\n",
    "        mean_across_parcels.append(statistics.mean(sub_parcel_level))\n",
    "\n",
    "\n",
    "    # make the variable containing newly parcellated data of all subjects into array    \n",
    "    parcel_level_all_subs = np.array(parcel_level_all_subs)  \n",
    "\n",
    "\n",
    "    #  store \n",
    "    dict_output = {'parcel_level_all_subs': parcel_level_all_subs, 'mean_across_parcels': mean_across_parcels}\n",
    "\n",
    "    \n",
    "    return dict_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "184aed26-59f9-4438-9f37-282f78508cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_structural_covariance_matrix_with_covariates(array_ct_subjects_parcels, covar = []):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes the structural covariance matrix across subjects using partial correlation (i.e., controlling for covariates)\n",
    "    - structural covariance matrix (parcels*parcels) can only be computed at the group-level\n",
    "    - needs to be across subjects otherwise cannot compute correlation because each parcel has 1 CT value per subject\n",
    "    \n",
    "    Note: VERY SLOW FUNCTION (13 min for 1570 subjects) because it calculates every single one of the parcel*parcel covariance matrix pairwise partial correlation coefficients \n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "    - covar: list/series containing covariate variables for the structural covariance matrix (to control for during partial correlation), e.g., 3 covariates: [demographics_df.global_ct, demographics_df.age, demographics_df.sex]\n",
    "        - note: dummy variables need to be coded numerically (not with string labels)\n",
    "        - note: make sure that the length of the covariate variables are as long as the length of array containing CT data (i.e., N = number of subjects)\n",
    "    \n",
    "    Output:\n",
    "    - structural covariance matrix across subjects (parcels*parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import pingouin package which includes partial_corr -> function to compute partial correlation\n",
    "    import pingouin as pg\n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    ### Format data to make it analyzable compute partial correlation: dataframe requirey by pingouin (pg) partial_corr function\n",
    "\n",
    "    # change shape from N x parcels to parcels x N, and turn array into a list in order to add covariates (lists of length = N) \n",
    "    df_ct_cov_matrix = (array_ct_subjects_parcels.T).tolist()\n",
    "\n",
    "    # add specified covariates\n",
    "    for i in range(len(covar)):\n",
    "        df_ct_cov_matrix.append(covar[i])\n",
    "\n",
    "    # make into dataframe (reverting back to shape N x parcels)\n",
    "     # columns = parcels + covariates, which can be called upon to compute pairwise partial correlations between parcels (x and y), whilst taking into account covariates (covar_indices)\n",
    "     # rows = subjects\n",
    "     # in this way, a the pairwise partial correlations are computed between 2 parcels, across all subject CT values for those parcel (e.g. Parcel 1 (CT values for N subjects) correlated with Parcel 2 (CT values for N subjects)\n",
    "    df_ct_cov_matrix = pd.DataFrame(np.array(df_ct_cov_matrix).T) \n",
    "    \n",
    "    \n",
    "    ### Compute structural covariance matrix across subjects using partial correlation (i.e., controling for covariates)\n",
    "    \n",
    "    # list of indices of covariates in dataframe (in descending order but doesn't matter, they are included all at once in partial correlation calculation) \n",
    "    covar_indices = []\n",
    "    \n",
    "    for i in range(len(covar)):\n",
    "        covar_indices.append(len(df_ct_cov_matrix.columns) - 1 - i)  # -1 in order to account for the fact that index starts at 0\n",
    "    \n",
    "\n",
    "    # list containing the structural covariance matrix\n",
    "    ct_cov_matrix_list = []\n",
    "\n",
    "    \n",
    "    # iteration across the parcels: to obtain the number of parcels, calculate length columns minus length covariates\n",
    "    for n in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "        # list for one line of the structural covariance matrix\n",
    "        line_partial_corr_coef = []\n",
    "        \n",
    "        # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to correlate parcel(n) with parcel(i)\n",
    "        for i in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "            # if parcel number n and i are NOT the same, compute partial correlation coefficient\n",
    "            if i != n:\n",
    "                \n",
    "                # define x and y variables to correlate for this iteration (pairwise partial correlation)\n",
    "                x = df_ct_cov_matrix.columns[n]  # x variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                y = df_ct_cov_matrix.columns[i]  # y variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                \n",
    "                # compute the pairwise partial correlation (specifying the x and y variables to be correlated, as well as covariate variables <- what is specified is the dataframe, and the column names)\n",
    "                # directly storing the correlation coefficient (as a float)\n",
    "                partial_corr_coef = float(pg.partial_corr(data = df_ct_cov_matrix, x = x, y = y, covar = covar_indices, x_covar = None, y_covar = None, alternative=\"two-sided\", method = \"pearson\").r)\n",
    "                \n",
    "                # append the partial correlation coefficient to the list for the current line (iteration) of the structural covariance matrix\n",
    "                line_partial_corr_coef.append(partial_corr_coef)\n",
    "\n",
    "\n",
    "            # if i == n: correlation of the parcel with itself, so r = 1 (append this value manually)\n",
    "            else:\n",
    "                line_partial_corr_coef.append(1)\n",
    "\n",
    "            # if last iteration of the line (the line is already at its full length (i.e., len(line_partial_corr_coef) == number of parcels), append line of correlation coefficients to the full matrix list\n",
    "            if len(line_partial_corr_coef) == (len(df_ct_cov_matrix.columns) - len(covar)):  \n",
    "                ct_cov_matrix_list.append(line_partial_corr_coef)\n",
    "\n",
    "\n",
    "    # saving the structural covariance matrix in array format\n",
    "    ct_cov_matrix = np.array(ct_cov_matrix_list)\n",
    "    \n",
    "    \n",
    "    return ct_cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87080f56-e31f-4dd5-a8cf-338de85a3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_correlation_matrices(x, y, label_x, label_y):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that displays the row-wise correlation between structurak and functional 400x400 correlation matrices\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - x: 400x400 mean matrix to correlate (1)\n",
    "    - y: 400x400 mean matrix to correlate (2)\n",
    "    \n",
    "    Output display:\n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "        Interpretation: I get for each of the 400 parcels an r-value of the association/correlation between how that parcel correlates with the other 399 parcels (structure) and how thtat parcels correlates with the other 399 parcels (function)\n",
    "    - plotted hemispheres: p-values of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices that pass bonferonni significance threshold (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    count_sig = 0\n",
    "    count_sig_bonferroni = 0\n",
    "\n",
    "    list_p_val = []\n",
    "    list_corr_coef = []\n",
    "    list_corr_coef_bonferroni = []\n",
    "    list_corr_coef_bonferroni_nan = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        corr_coef = stats.pearsonr(x[i], y[i])[0]\n",
    "        p_val = stats.pearsonr(x[i], y[i])[1]\n",
    "\n",
    "        list_corr_coef.append(corr_coef)\n",
    "        list_p_val.append(p_val)\n",
    "\n",
    "        if p_val < (0.05):\n",
    "            count_sig += 1\n",
    "\n",
    "            if p_val < (0.05/400):\n",
    "                count_sig_bonferroni += 1\n",
    "                list_corr_coef_bonferroni.append(corr_coef)\n",
    "                list_corr_coef_bonferroni_nan.append(corr_coef)\n",
    "\n",
    "            else:\n",
    "                list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "       \n",
    "        else:\n",
    "            list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    " \n",
    "    \n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: {count_sig}\")\n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: (Bonferroni corrected; alpha = 0.05/400 = 0.000125): {count_sig_bonferroni}\")\n",
    "\n",
    "\n",
    "    \n",
    "    ### Plots\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## correlation coefficents\n",
    "    corrcoef_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef), labeling, mask=mask, fill=np.nan)  \n",
    "    \n",
    "    corrcoef_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"PiYG\",\n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r)\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    # plot\n",
    "    handles.append(corrcoef_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ## p-values\n",
    "    pvals_mapped_to_labels = map_to_labels(np.asarray(list_p_val), labeling, mask=mask, fill=np.nan)      \n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## correlation coefficients (only the one passing Bonferroni corrected significance)   \n",
    "    corrcoef_bonf_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef_bonferroni_nan), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # decision of the color coding scheme\n",
    "    if sum(1 for number in list_corr_coef_bonferroni if number < 0) == 0:  # of there are no negative correlation coefficients (passing bonferroni corrected significance level)\n",
    "        color_decision = \"YlGn\"  # use color map that goes gradual from small to high\n",
    "    else:\n",
    "        color_decision = \"PiYG\"  # use color map that goes (-) to 0 to (+)\n",
    "    \n",
    "    corrcoef_bonf_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_bonf_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = color_decision,  \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r) Bonf\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(corrcoef_bonf_plotted_hemispheres)\n",
    "        \n",
    "        \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a39bfceb-7bbb-4714-80c9-088a0a9acdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ct_similarity_matrices_for_all_subjects(array_ct_subjects_parcels):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes cortical thickness similarity matrices for all subjects (individual level)\n",
    "\n",
    "    Note: VERY SLOW FUNCTION (15 min for 1570 subjects) because it calculates every single one of the parcel*parcel similarity coefficient\n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "      \n",
    "    Output:\n",
    "    - CT similarity matrices for each subject (shape: N x parcels x parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### list of standard deviation of CT values for each parcel (across subjects) -> required for formula calculating similarity coefficients\n",
    "\n",
    "    list_std_parcels = []\n",
    "\n",
    "    # iterate over parcels (by taking transposed ct_schaefer400 variable) \n",
    "    for i in range(len(array_ct_subjects_parcels.T)):\n",
    "\n",
    "        # calculate standard deviation of CT values for that parcel (across subjects)\n",
    "        std_parcel = np.std(array_ct_subjects_parcels.T[i])\n",
    "\n",
    "        # add standard deviation for current parcel to list\n",
    "        list_std_parcels.append(std_parcel)\n",
    "\n",
    "\n",
    "    ### compute similarity matrices (containing all subjects)\n",
    "\n",
    "    similarity_ct_matrices = []\n",
    "\n",
    "    # loop over subjects\n",
    "    for sub in range(len(array_ct_subjects_parcels)):\n",
    "\n",
    "        # list containing a subject's similarity matrix (400x400)\n",
    "        sub_similarity_ct_matrix = []\n",
    "\n",
    "        # iteration across parcels\n",
    "        for i in range(len(array_ct_subjects_parcels[sub])):        \n",
    "\n",
    "            # list containing one line (row) of the similarity matrix\n",
    "            line_similarity_ct_matrix_list = []\n",
    "\n",
    "            # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to compute the similarity between parcel(n) with parcel(i)\n",
    "            for j in range(len(array_ct_subjects_parcels[sub])):\n",
    "\n",
    "                # compute similarity coefficient (according to: Wee et al (2013) https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.22156) -> it works, proof: when i=j, yields similarity of 1.0\n",
    "\n",
    "                dissimilarity = (array_ct_subjects_parcels[sub][i] - array_ct_subjects_parcels[sub][j])**2\n",
    "\n",
    "                sigma = math.sqrt(list_std_parcels[i] + list_std_parcels[j])\n",
    "\n",
    "                # similarity coefficient\n",
    "                similarity = math.exp(- dissimilarity / (2 * (sigma)**2))\n",
    "\n",
    "                # append similarity coefficient for current parcel interaction to the line of similarity ct matrix (list)\n",
    "                line_similarity_ct_matrix_list.append(similarity)\n",
    "\n",
    "\n",
    "                # if last iteration (parcel) of the line (the line is already at its full length (i.e., len(line_similarity_ct_matrix_list) == number of parcels), append line of correlation coefficients to the subject's similarity matrix\n",
    "                if len(line_similarity_ct_matrix_list) == len(array_ct_subjects_parcels[sub]):  \n",
    "                    sub_similarity_ct_matrix.append(line_similarity_ct_matrix_list)\n",
    "\n",
    "        # if last iteration (line) of the matrix (the matrix is already at its full length (i.e., len(sub_similarity_ct_matrix) == number of parcels), append the subject's similarity matrix to the list of similarity ct matrices (all subjects)  \n",
    "        if len(sub_similarity_ct_matrix) == len(array_ct_subjects_parcels[sub]):\n",
    "            similarity_ct_matrices.append(sub_similarity_ct_matrix)\n",
    "\n",
    "    # saving the similarity matrix in array format\n",
    "    similarity_ct_matrices = np.array(similarity_ct_matrices)\n",
    "\n",
    "    return similarity_ct_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cade7a03-970f-465a-89f6-d9552bd631e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_parcel_values_scatter_bysex(male_data, female_data, title = None):\n",
    "    \n",
    "    '''\n",
    "    Function that males a scatterplot comparing mean male vs female parcel values (e.g. mean function gradient loading per parcel) color coded per Yeo network for Schaeffer 400\n",
    "    \n",
    "    Input: mean male and female values (format: array len = 400, i.e. number of Schafer parcels)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # make a dataframe containing the male and female data (to make it plottable)\n",
    "    dataframe = pd.DataFrame({'M': male_data, 'F': female_data})\n",
    "    \n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    sns.scatterplot(data = dataframe, x = 'M', y = 'F', \n",
    "                    hue=yeo7_networks_array_labels,  # gives color coding based on yeo networks\n",
    "                    palette=palette_labeled_networks, \n",
    "                    s=70, \n",
    "                    edgecolor='black',\n",
    "                    linewidth=1)\n",
    "\n",
    "    # plot line x = y through getting the x and y limits\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    lims = [max(x0, y0), min(x1, y1)]\n",
    "    ax.plot(lims, lims, 'black', linewidth=2)\n",
    "\n",
    "    ax.axes.set_title(f\"Male vs Female {title}\", y=1.05, fontsize=25)\n",
    "    ax.set_xlabel(\"Males\",fontsize=25)\n",
    "    ax.set_ylabel(\"Females\",fontsize=25)\n",
    "    ax.tick_params(labelsize=25)\n",
    "    ax.legend(fontsize=25, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

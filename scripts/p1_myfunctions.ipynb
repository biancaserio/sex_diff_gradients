{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bea96b-720c-4903-b477-e1282b9784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_sub_conn_matrices(path_conn_matrices):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that fetches the connectivity matrices of all subjects from path and stores them in a variable \n",
    "    \n",
    "    Input:\n",
    "    - path containing all the subject connectivity matrices\n",
    "    \n",
    "    Output (dictionary containing):\n",
    "    - conn_matrices: np array contianing the connectivty matrices of all subjects (in the form of 1 np array per subject)\n",
    "    - sub_list: list containing all the subject IDs\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # list that contains all the subject IDs of subjects with fc matrices\n",
    "    sub_list = []\n",
    "\n",
    "    # list that contains the fc matrices of all subjects in the form of 1 np array per subject\n",
    "    conn_matrices = []\n",
    "\n",
    "    # reads (lists) the content of the path containing the list of fc_matrices and stores the sorted contents in as a list in the variable list_fc_matrices\n",
    "    list_conn_matrices = os.listdir(path_conn_matrices)\n",
    "    list_conn_matrices.sort()\n",
    "\n",
    "    for e in list_conn_matrices:\n",
    "        if '.csv' in e:  # need to do this because there is a hidden files in the path_list_fc_matrices\n",
    "\n",
    "            # add subject to the subjects' list\n",
    "            sub_list.append(e.partition(\".\")[0])  # this partitions the subID.csv into a 3-tuple containing ('subID', '.', 'csv'), and I keep only the subID\n",
    "\n",
    "            # reads csv file in the form of an array\n",
    "            sub_matrix = np.genfromtxt(path_conn_matrices + e, delimiter=',')\n",
    "\n",
    "            # add subject's matrix to the fc_matrices_400 list\n",
    "            conn_matrices.append(sub_matrix)\n",
    "\n",
    "    print(f'Connectivity matrices found in path {path_conn_matrices}: N = {len(sub_list)}')\n",
    "    \n",
    "    dict_output = {'conn_matrices': conn_matrices, 'sub_list': sub_list}\n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a341ca3-4eca-414b-a125-d5d3f9da7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_gradients(mean_conn_matrix, display_output = True, data_reduction_algorithm = 'dm', save_screenshot = False, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the mean gradients from mean connectivity matrix (across subjects)\n",
    "    \n",
    "    Input:\n",
    "    - mean_conn_matrix: variable containing mean connectivity matrix across subjects\n",
    "    - display_output: True (default) or False - displays the plots specified below\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output (display):\n",
    "    - mean connectivity matrix + shape\n",
    "    - 3 first mean connectivity gradients\n",
    "    - scree plot of the variance explained by the 10 gradients + printed detail of variance explained and scaled varience explained\n",
    "    \n",
    "    Output:\n",
    "    - mean_grad: the mean gradients, computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    \n",
    "    '''  \n",
    "    \n",
    "    ## compute the mean gradients \n",
    "    \n",
    "    # GradientMaps function used to build the model parameters\n",
    "    mean_grad = GradientMaps(n_components = 10, random_state = 0, approach = data_reduction_algorithm, kernel = 'normalized_angle')\n",
    "\n",
    "    # fit function used to compute the gradients\n",
    "    mean_grad.fit(mean_conn_matrix)\n",
    "    \n",
    "    \n",
    "    if display_output:\n",
    "        \n",
    "        ## plot the mean connectivity matrix and shape\n",
    "        \n",
    "        plt.imshow(mean_conn_matrix)\n",
    "        plt.show()\n",
    "        print(mean_conn_matrix.shape)\n",
    "        \n",
    "        \n",
    "        ## plot the 3 first mean gradients\n",
    "        \n",
    "        # defining labeling scheme and mask\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "        # list containing placeholders (None) for the number of gradients I want to plot\n",
    "        grad = [None] * 3\n",
    "\n",
    "        for i in range(3):\n",
    "            # map the gradient to the parcels\n",
    "            grad[i] = map_to_labels((mean_grad.gradients_)[:, i], labeling, mask=mask, fill=np.nan)  # mean_grad contains 10 .gradients_ (1 gradient per column) - here I take all rows and individual select column based on gradient I want (first 3)\n",
    "\n",
    "        plot = plot_hemispheres(surf_lh, \n",
    "                                surf_rh, \n",
    "                                array_name=grad, \n",
    "                                embed_nb = True, \n",
    "                                size=(1200, 400), \n",
    "                                cmap='viridis_r', \n",
    "                                color_bar=True, \n",
    "                                label_text=['Gradient 1', 'Gradient 2', 'Gradient 3'], \n",
    "                                zoom=1.55,\n",
    "                                screenshot = save_screenshot,\n",
    "                                filename = resdir_fig+sample_modality+'_plotted_hemispheres_mean_gradients.png')\n",
    "        \n",
    "        display(plot)\n",
    "\n",
    "\n",
    "        ## plot the variance explained by the 10 gradients\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(5, 4))\n",
    "        ax.scatter(range(mean_grad.lambdas_.size), mean_grad.lambdas_)\n",
    "        ax.set_title(\"Variance explained by the 10 gradients\")\n",
    "        ax.set_xlabel('Component Nb')\n",
    "        ax.set_ylabel('Eigenvalue')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Total amount of variance explained by the {len(mean_grad.lambdas_)} gradients (uncorrected sum lambdas): {sum(mean_grad.lambdas_):.2f}\\n\")\n",
    "\n",
    "        # Scaled variance explained by individual gradients: lambda / total(i.e., sum lambdas) * 100 %\n",
    "        print(f\"Scaled variance explained by individual gradients:\\nG1: {mean_grad.lambdas_[0]/sum(mean_grad.lambdas_)*100:.2f}%\\nG2: {mean_grad.lambdas_[1]/sum(mean_grad.lambdas_)*100:.2f}%\\nG3: {mean_grad.lambdas_[2]/sum(mean_grad.lambdas_)*100:.2f}%\\n\")\n",
    "\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b80ad2-1162-4c48-b8ee-b82a54fe2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aligned_gradients(conn_matrices, mean_grad, data_reduction_algorithm = 'dm'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the alligned gradients from all subject connectivity matrices\n",
    "    \n",
    "    Input:\n",
    "    - variable containing all subject connectivity matrices\n",
    "    - array including the mean connectivity gradients\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    \n",
    "    Output (dictionary containing arrays):  \n",
    "    - array_aligned_gradients\n",
    "    - array_aligned_G1\n",
    "    - array_aligned_G2\n",
    "    - array_aligned_G3\n",
    "    \n",
    "    Gradients computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    list_aligned_gradients = []  # will contain all participants (1014), all parcels (400), all gradients (10)\n",
    "    list_aligned_G1 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 1\n",
    "    list_aligned_G2 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 2\n",
    "    list_aligned_G3 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 3\n",
    "\n",
    "    # loop over all the connectivity matrices\n",
    "    for i in range(len(conn_matrices)):\n",
    "        # setting model parameters for gradients to be computed across subjects - with procrustes alignment\n",
    "        grad_procr = GradientMaps(n_components=10, random_state=0, approach = data_reduction_algorithm, kernel='normalized_angle', alignment='procrustes')  # specify alignment method here (procrustes)\n",
    "\n",
    "        # computing\n",
    "        # note that by using an alignment method, .fit yields a variable (grad_procr) containing both types of gradients, callable with: .gradients_ (original) and .aligned_ \n",
    "          # use ._gradients for mean_grad (mean grad was not even calculated with a reference so doesn't have ._aligned) and use .aligned_ for grad_procr \n",
    "\n",
    "        grad_procr.fit(conn_matrices[i], reference=mean_grad)  # align to the gradients of the gradients produced by the mean matrix (reference) \n",
    "\n",
    "        # append array to lists results (.T is necessary in order to be able to first access the gradients layer (10) so that can index the desired gradient, which will then contain all the parcels (400)\n",
    "        list_aligned_gradients.append(grad_procr.aligned_)\n",
    "        list_aligned_G1.append(grad_procr.aligned_.T[0])\n",
    "        list_aligned_G2.append(grad_procr.aligned_.T[1])\n",
    "        list_aligned_G3.append(grad_procr.aligned_.T[2])\n",
    "\n",
    "    # make gradient lists into arrays (for analyses)    \n",
    "    array_aligned_gradients = np.array(list_aligned_gradients)\n",
    "    array_aligned_G1 = np.array(list_aligned_G1)\n",
    "    array_aligned_G2 = np.array(list_aligned_G2)\n",
    "    array_aligned_G3 = np.array(list_aligned_G3)\n",
    "        \n",
    "        \n",
    "    ### dictionary to output\n",
    "    \n",
    "    dict_output = {'array_aligned_gradients': array_aligned_gradients, 'array_aligned_G1': array_aligned_G1, 'array_aligned_G2': array_aligned_G2, 'array_aligned_G3': array_aligned_G3}\n",
    "    \n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef128b14-2ab9-479b-b196-8b0593a98df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison(array_grad, sex_comp = None):\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Function that produced RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sexes\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot of mean gradient loadings across subjects per parcel, color coded by Yeo network, compard by sex\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframe of gradient loadings (shape: sub (vertical) x parcels (horizontal))\n",
    "    df_grad = pd.DataFrame(array_grad)\n",
    "\n",
    "    # adding a column containing the labels for the sex comparison\n",
    "    df_grad[\"sex\"] = sex_comp.tolist()\n",
    "\n",
    "    # separatating the dataframe into two dataframes containing only subjects of the given sex (because need to calculate mean across subjects for each parcel)\n",
    "    df_grad_cat_M = df_grad[df_grad[\"sex\"] == 'M']\n",
    "    df_grad_cat_F = df_grad[df_grad[\"sex\"] == 'F']\n",
    "\n",
    "    # removing the label of sex for the moment because need to have only the parcels in the same column\n",
    "    df_grad_cat_M = df_grad_cat_M.drop('sex', axis=1)\n",
    "    df_grad_cat_F = df_grad_cat_F.drop('sex', axis=1)\n",
    "\n",
    "    # transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    df_grad_cat_M = df_grad_cat_M.T\n",
    "    df_grad_cat_F = df_grad_cat_F.T\n",
    "\n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    df_grad_cat_M['mean gradient loadings across subjects per parcel'] = df_grad_cat_M.mean(axis=1)\n",
    "    df_grad_cat_F['mean gradient loadings across subjects per parcel'] = df_grad_cat_F.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    df_grad_cat_M['yeo network'] = yeo7_networks_array_labels\n",
    "    df_grad_cat_F['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    df_grad_cat_M = df_grad_cat_M[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    df_grad_cat_F = df_grad_cat_F[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # add label of sex for each dataframe before merging them in order to make males and females identifiable for plotting\n",
    "    df_grad_cat_M['sex'] = 'M'\n",
    "    df_grad_cat_F['sex'] = 'F'\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([df_grad_cat_M, df_grad_cat_F], axis = 'index')\n",
    "\n",
    "\n",
    "\n",
    "    ## plot \n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sex\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc26ec4e-7512-4d0e-87c4-bb4ce01f74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison_IndDiff(array_grad, sex_comp = None, plot_type = ['across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate']):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network and optionally by sex \n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "     \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    - plot_type: plot type display - should be one of the following 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot - display according to specified plot_type\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # defining conflicting inputted parameters - error messages\n",
    "    if sex_comp is not None and plot_type == 'across sexes overlayed' or sex_comp is not None and plot_type == 'across sexes separate':\n",
    "        print('ERROR: Conflicting inputted parameters - if you want across sexes, you must input sex_comp = None')\n",
    "    \n",
    "    elif sex_comp is None and plot_type == 'by sex overlayed' or sex_comp is None and plot_type == 'by sex separate':\n",
    "         print('ERROR: Conflicting inputted parameters - if you want by sex, you must provide a variable for sex_comp')\n",
    "            \n",
    "    # if no conflicting parameters, can procede with formatting gradient array for plotting and plotting \n",
    "    else:\n",
    "        \n",
    "        ## format gradient array for plotting\n",
    "        \n",
    "        # dataframe of the G1 loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "        df_grad = pd.DataFrame(array_grad.T)\n",
    "\n",
    "        # adding a column containing the Yeo network labels\n",
    "        df_grad['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "        # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need all subjects to be vertical (1 subject per row) in the dataframe in order to be labeled with their corresponding sex for comparison \n",
    "        df_grad = df_grad.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "        \n",
    "        if sex_comp is None:\n",
    "            df_grad[\"categorical comparison\"] = [1] * len(df_grad)  # making a column of just 1s so that there is no categorical comparison to display (all subject belong in same group)\n",
    "            \n",
    "        else:    \n",
    "            # adding a column containing the labels for the categorical comparison (according to inputted categorical variable\n",
    "            df_grad[\"categorical comparison\"] = sex_comp.tolist()\n",
    "\n",
    "        # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "        df_grad.index.name = \"sub\"\n",
    "        df_grad = df_grad.reset_index()\n",
    "\n",
    "        # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "        # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sex as ID variables\n",
    "        df_grad=pd.melt(df_grad, id_vars=[\"sub\", 'categorical comparison'], var_name='yeo network', value_name='mean gradient loadings across parcels per subject')\n",
    "\n",
    "\n",
    "\n",
    "        ## plot depending on requested plot type\n",
    "\n",
    "        if plot_type == 'across sexes overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "        elif plot_type == 'across sexes separate':    \n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            #hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=True, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex separate':\n",
    "\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"categorical comparison\",\n",
    "                            data=df_grad,\n",
    "                            palette=sns.color_palette(n_colors=2),\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            #figsize=(7,5),  # DELETE THIS\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65, \n",
    "                            dodge=True)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: mis-specified plot_type. Please choose from: 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b84223-e8da-4a8f-864a-4b580ca96163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reg_results_R(reg_res, contrast_type, save_screenshot = False, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    Function that plots regression results coming from R script (t-values, p-values, FDR corrected q-values, and t-values corresponding to sig FDR corrected q values)\n",
    "    \n",
    "    Input: \n",
    "    - reg_res: slm results dataframe containing vales with the following names: t_val, p_val, q_val \n",
    "    - contrast type: string indicating the contrast that is being studied, e.g., 'sex' (for figure name and plot titles)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # defining \n",
    "    \n",
    "    t_val = reg_res.iloc[:, 0]\n",
    "    p_val = reg_res.iloc[:, 1]\n",
    "    q_val = reg_res.iloc[:, 2]\n",
    "    \n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ### t-values\n",
    "    tvals_mapped_to_labels = map_to_labels(np.asarray(reg_res.t_val), labeling, mask=mask, fill=np.nan)  # t[0] because there is a double bracket for the t-values array, need [0] to access the values themselves\n",
    "    \n",
    "    tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"t-values\"],\n",
    "        zoom = 1.45, \n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_t_val.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append(tvals_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ### p-values (uncorrected)\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    pvals = np.asarray(reg_res.p_val.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(pvals, pvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    pvals_mapped_to_labels = map_to_labels(pvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values (uncorr.)\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_p_val.png')\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)    \n",
    "        \n",
    "        \n",
    "                   \n",
    "    ### Q-values\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    Qvals = np.asarray(reg_res.q_val.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(Qvals, Qvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    Qvals_mapped_to_labels = map_to_labels(Qvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    Qvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = Qvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"Q-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_q_val.png')\n",
    "    \n",
    "    handles.append(Qvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    ### t-values (only FDR-corrected) showing sex differences\n",
    "    \n",
    "    ## find t-values\n",
    "    fdr_corrected_tvals = []\n",
    "    \n",
    "    for i in range(len(reg_res.q_val)):\n",
    "        if reg_res.q_val[i] <= 0.05:\n",
    "            fdr_corrected_tvals.append(reg_res.t_val[i])\n",
    "        else:\n",
    "            fdr_corrected_tvals.append(float('nan'))\n",
    "    \n",
    "    fdr_corr_tvals_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"t-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_t_val_fdr_corr.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append('t-values for FDR-corrected q < 0.05: (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)\n",
    "    \n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef648a5c-344b-4736-bc7b-d80c9d9d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_contrast_results_breakdown_by_network(reg_res, contrast_type, scatterplot = True, scatter_x = None, scatter_y = None, scatter_x_label = None, scatter_y_label = None, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that outputs the breakdown of regression contrast results by network\n",
    "    \n",
    "    Input:\n",
    "    - reg_res: regression results (in fomrat: DataFrame, containing columns 'q_val' and 't_val', len = 400 parcels (Schaeffer400))\n",
    "    - contrast type: string indicating the contrast that is being studied, e.g., 'sex' (for figure name and plot titles)\n",
    "    - scatter_x: x-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_y: y-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_x_label, scatter_y_label\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output (display):\n",
    "    - written breakdown (number and proportion of significant parcels by network (relative proportion (i.e., out of all the parcels belonging to a given network) and absolute proportion (i.e., out of the total significant results)\n",
    "    - plotted breakdown (pie chart) - proportion of significant parcels by network (absolute proportion)\n",
    "    - plotted breakdown by sex (nested pie chart) - proportion of significant parcels by network (absolute proportion) by sex <- !!! HARDCODED M vs F labels !!! - color coding with original Yeo network colors\n",
    "    - plotted breadown by sex (nested pie chart) - same as above, WITHOUT LABELS\n",
    "    - Violin plot of t-values (regression results) by Yeo network\n",
    "    - scatter plot showing of G1 vs G2, displaying parcels showing a significant contrast in dark\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### required variables\n",
    "    \n",
    "    ## yeo network numbered labels (hardcoded path)\n",
    "    # labels: 1=visual, 2=sensory motor, 3=dorsal attention, 4=ventral attention, 5=limbic, 6=fronto parietal, 7= DMN\n",
    "    #with open(datadir+'yeo_7.csv') as f:\n",
    "    #    reader = csv.reader(f)\n",
    "    #    yeo7_networks = list(reader)[0]  # need [0] because the network values are contained in double brackets [[ ]]\n",
    "    \n",
    "    \n",
    "    # array with yeo network labels (names instead of numbers)\n",
    "    yeo7_networks_array_labels = []\n",
    "\n",
    "    for i in yeo7_networks:\n",
    "        if i == '1':\n",
    "            yeo7_networks_array_labels.append('visual')\n",
    "        elif i == '2':\n",
    "            yeo7_networks_array_labels.append('sensory motor')\n",
    "        elif i == '3':\n",
    "            yeo7_networks_array_labels.append('dorsal attention')\n",
    "        elif i == '4':\n",
    "            yeo7_networks_array_labels.append('ventral attention')\n",
    "        elif i == '5':\n",
    "            yeo7_networks_array_labels.append('limbic')\n",
    "        elif i == '6':\n",
    "            yeo7_networks_array_labels.append('fronto parietal')\n",
    "        elif i == '7':\n",
    "            yeo7_networks_array_labels.append('DMN')\n",
    "\n",
    "    yeo7_networks_array_labels = np.asarray(yeo7_networks_array_labels)\n",
    "    \n",
    "    \n",
    "    network_names = [\"visual\", \"sensory motor\", \"DMN\", \"dorsal attention\", \"ventral attention\", \"limbic\", \"fronto parietal\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    ### written breakdown\n",
    "    \n",
    "    # counting number of significant parcels\n",
    "    # storing the Q values in a list (where non significant Q values are marked as 1 -> for later potential scatterplot visualization)\n",
    "    # making a dictionary that counts the number of significant parcels per yeo network\n",
    "    # making dictionaries that count the number of significant parcels per yeo network by sex\n",
    "    \n",
    "    sig_Q_vals_slm = []\n",
    "    count_sig = 0\n",
    "    count_sig_M = 0\n",
    "    count_sig_F = 0\n",
    "    count_sig_per_network = {\"visual\": 0, \"sensory motor\": 0, \"DMN\": 0, \"dorsal attention\": 0, \"ventral attention\": 0, \"limbic\": 0, \"fronto parietal\": 0}\n",
    "    count_sig_per_network_bysex = {\"visual\": [0, 0], \"sensory motor\": [0,0], \"DMN\": [0,0], \"dorsal attention\": [0,0], \"ventral attention\": [0,0], \"limbic\": [0,0], \"fronto parietal\": [0,0]} # M: [0], F: [1]\n",
    "    \n",
    "    for i in range(len(reg_res.q_val)):\n",
    "    \n",
    "        if reg_res.q_val[i] < 0.05:\n",
    "            count_sig += 1\n",
    "            count_sig_per_network[yeo7_networks_array_labels[i]] += 1\n",
    "            sig_Q_vals_slm.append(1)\n",
    "    \n",
    "            # positive t-values mean male > female: increment the first item of the list fort given label\n",
    "            if reg_res.t_val[i] > 0:\n",
    "                count_sig_M += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][0] += 1\n",
    "            \n",
    "            # positive t-values mean female > male: increment the second item of the list for the given label\n",
    "            else:\n",
    "                count_sig_F += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][1] += 1\n",
    "        \n",
    "        else:\n",
    "            sig_Q_vals_slm.append(0)\n",
    "    \n",
    "    print(f\"Number of significant parcels: {count_sig}\\n\")\n",
    "    print(f\"Number of significant parcels for males: {count_sig_M}\")\n",
    "    print(f\"Number of significant parcels for females: {count_sig_F}\\n\")\n",
    "    print(\"Number of significant parcels in each Yeo network (across sexes):\")\n",
    "    \n",
    "    # using ANSI escape sequences to underline -> bold: \\033[1m ; underline: \\033[4m ; end: \\033[0m\n",
    "    for i in range(len(count_sig_per_network)):\n",
    "        print(f\"- {list(count_sig_per_network.keys())[i]}: \\033[4m{count_sig_per_network[list(count_sig_per_network.keys())[i]]}\\033[0m out of {yeo7_networks_array_labels.tolist().count(network_names[i])} ({round(count_sig_per_network[list(count_sig_per_network.keys())[i]] / yeo7_networks_array_labels.tolist().count(network_names[i]) * 100, 2)}%) -> \\033[1m{round(count_sig_per_network[list(count_sig_per_network.keys())[i]]*100/count_sig,2)}%\\033[0m of overall significance\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Pie chart breakdown per network\n",
    "    \n",
    "    # setting figure size\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 7))\n",
    "    \n",
    "    # data to plot: in dictionary count_sig_per_network\n",
    "    network_labels = []\n",
    "    data = []\n",
    "    \n",
    "    for x, y in count_sig_per_network.items():\n",
    "        network_labels.append(x)\n",
    "        data.append(y)\n",
    "    \n",
    "    # define color palette to use\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # color palette matching the raincloudplot colors (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt\n",
    "                    (185/255, 163/255, 204/255),\n",
    "                    (120/255, 162/255, 189/255),\n",
    "                    (236/255, 170/255, 119/255),\n",
    "                    (174/255, 147/255, 143/255),\n",
    "                    (216/255, 128/255, 129/255),\n",
    "                    (128/255, 183/255, 126/255)]\n",
    "    \n",
    "    # plot pie chart\n",
    "    ax.pie(data,\n",
    "           labels = network_labels, colors = color_palette, autopct='%.0f%%',\n",
    "           wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},\n",
    "           textprops={'fontsize': 20})\n",
    "    \n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant {contrast_type} difference in gradient loadings', y=1.03, fontsize=20)\n",
    "    \n",
    "    # display\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Nested pie chart\n",
    "    \n",
    "    ## make data plottable\n",
    "    list_count_sig_per_network_bysex = []\n",
    "    \n",
    "    for label in count_sig_per_network_bysex:\n",
    "        list_count_sig_per_network_bysex.append(count_sig_per_network_bysex[label])\n",
    "    \n",
    "    vals = np.array(list_count_sig_per_network_bysex)\n",
    "    \n",
    "    outer_colors = [\"darkorchid\",  # visual\n",
    "                    \"steelblue\",  # sensorimotor\n",
    "                    \"indianred\",  # dmn\n",
    "                    \"forestgreen\",  # dorsal attention\n",
    "                    \"orchid\",  # ventral attention\n",
    "                    \"lemonchiffon\",  # limbic\n",
    "                    \"orange\"]  # frontoparietal\n",
    "    inner_colors = ['lightblue', 'lightcoral',  # visual\n",
    "                    'lightblue', 'lightcoral',  # sensorimotor\n",
    "                    'lightblue', 'lightcoral',  # dmn\n",
    "                    'lightblue', 'lightcoral',  # dorsal attention\n",
    "                    'lightblue', 'lightcoral',  # ventral attention\n",
    "                    'lightblue', 'lightcoral',  # limbic\n",
    "                    'lightblue', 'lightcoral']  #frontoparietal\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    size = 0.3\n",
    "    \n",
    "    ## plot outer pie\n",
    "    ax.pie(vals.sum(axis=1), radius=1, labels=count_sig_per_network_bysex.keys(), colors=outer_colors, autopct='%.0f%%', pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    ## plot inner pie\n",
    "    \n",
    "    # make a list (in order) containing the labels (sex - hardcoded) only for sections that have more than 1 count (otherwise label is placeholder: blank)\n",
    "    \n",
    "    labels_only_show_non_null = []\n",
    "    \n",
    "    for network in list_count_sig_per_network_bysex:\n",
    "    \n",
    "        # males\n",
    "        if network[0] > 0:\n",
    "            labels_only_show_non_null.append('M')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "        \n",
    "        # females\n",
    "        if network[1] > 0:\n",
    "            labels_only_show_non_null.append('F')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "    \n",
    "    ax.pie(vals.flatten(), radius=1-size, labels=labels_only_show_non_null, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    ax.set(aspect=\"equal\")\n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant {contrast_type} difference in gradient loadings, by {contrast_type}', y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print('Number of significant parcels by sex:')\n",
    "    for network in count_sig_per_network_bysex:\n",
    "        print(f\"{network} - Male: {count_sig_per_network_bysex[network][0]}, Female: {count_sig_per_network_bysex[network][1]}\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### plot outer and inner pie (without labels)\n",
    "    \n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "    \n",
    "    disp.pie(vals.sum(axis=1), radius=1, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='blacK'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    disp.set(aspect=\"equal\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## save figure in directory \n",
    "    fig.savefig(resdir_fig+sample_modality+'_pie_chart_'+contrast_type+'_diff_netw.png', dpi=300)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Violin plot of t-values (regression results) by Yeo network\n",
    "    \n",
    "    print(\"Violin plot of t-values (regression results) by Yeo network\")\n",
    "    \n",
    "    df_to_plot = pd.DataFrame(reg_res.t_val)\n",
    "    \n",
    "    df_to_plot['yeo network'] = yeo7_networks_array_labels\n",
    "    \n",
    "    # color palette matching the raincloudplot colors (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,5));\n",
    "    \n",
    "    ax = sns.violinplot(data=df_to_plot,\n",
    "                        x=\"yeo network\",\n",
    "                        y=\"t_val\",\n",
    "                        #hue=\"\",\n",
    "                        palette = color_palette,\n",
    "                  )\n",
    "    \n",
    "    \n",
    "    ### plot of significant parcels on G1 vs G2 visualization\n",
    "    \n",
    "    # problems with this plot\n",
    "        # hard-coded axes labels and title (G1 vs G2)\n",
    "        # legend of colors: showing 0 vs 1\n",
    "    \n",
    "    if scatterplot:\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize = (6,5));\n",
    "        \n",
    "        ax = sns.scatterplot(x = scatter_x,\n",
    "                             y = scatter_y,\n",
    "                             hue = sig_Q_vals_slm,  # gives color coding based on Q value of sex contrast (main model including age, sex, icv) -> dark color: significance\n",
    "                             palette = sns.color_palette([\"lavender\", \"navy\"]),\n",
    "                             legend = True, ax = ax);\n",
    "        \n",
    "        ax.set_xlabel(scatter_x_label, fontsize=20);\n",
    "        ax.set_ylabel(scatter_y_label, fontsize=20);\n",
    "        ax.set_title(f'Scatter plot of G1 vs G2, showing significant {contrast_type} contrast in dark', y=1.05, fontsize=20)\n",
    "        ax.spines['right'].set_visible(False);\n",
    "        ax.spines['top'].set_visible(False);\n",
    "        #plt.legend(title='1 = FDR-corr significance')\n",
    "        \n",
    "        plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae2cfcf-09ee-4273-a0af-19464744ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot_corr_networks(x, y, x_label, y_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    - correlations between 2 variables, both overall and per network\n",
    "    - scatterplots colorcoded by yeo network, with regression lines per network\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### creating a dataframe in order to have the data in the correct format to be plotted\n",
    "    temp_dict = {x_label: x, y_label: y, 'yeo_network': yeo7_networks_array_labels}  \n",
    "    dataframe = pd.DataFrame(data = temp_dict)\n",
    "    \n",
    "\n",
    "    ### print overall correlation\n",
    "    print('Note that the correlation p-values below have not undergone permutation testing! so here the correlations (r coefficients) are only indicative of effect sizes\\n\\n')\n",
    "    \n",
    "    print(f\"Overall Pearson correlation between {x_label} and {y_label}: r = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[0], 2)}; p = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[1], 3)}\\n\")\n",
    "    \n",
    "    network_labels = ['visual', 'sensory motor', 'dorsal attention', 'ventral attention', 'limbic', 'fronto parietal', 'DMN']\n",
    "\n",
    "    for i in range(len(network_labels)):\n",
    "        \n",
    "        corr_coef = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[0]\n",
    "        p_val = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[1]\n",
    "        \n",
    "        print(f\"{network_labels[i]}: r = {round(corr_coef, 2)}, p = {round(p_val, 3)}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ### scatter plot color-coded by network, with regression lines \n",
    "        \n",
    "    # original Yeo network colors\n",
    "    palette_labeled_networks = {'DMN': 'indianred',  \n",
    "                                'dorsal attention' : 'forestgreen',  \n",
    "                                'fronto parietal' : 'orange',  \n",
    "                                'limbic' : 'lemonchiffon',  \n",
    "                                'sensory motor' : 'steelblue',\n",
    "                                'ventral attention' : 'orchid', \n",
    "                                'visual' : 'darkorchid'} \n",
    "\n",
    "    # plot\n",
    "    \n",
    "    sns.lmplot(x = x_label, y = y_label, \n",
    "           hue = 'yeo_network',\n",
    "           data = dataframe,\n",
    "           palette = palette_labeled_networks, \n",
    "           height=10, aspect=1.2,  # aspect gives you the height-width ratio\n",
    "           legend=False)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    plt.title(f\"Correlation between {x_label} and {y_label}\", y=1.05, fontsize=25)\n",
    "    plt.xlabel(x_label, fontsize=25)\n",
    "    plt.ylabel(y_label, fontsize=25)\n",
    "    plt.tick_params(labelsize=25)\n",
    "    plt.legend(fontsize=25, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc5d4c8-1251-449e-9c7d-02715e1e27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpinPermutationTest_PearsonCorr_Schaefer400(x, y):\n",
    "    \n",
    "    '''\n",
    "    OUTDATED: I MADE A NEW FUNCTION THAT ALLOWS TO SPECFIY WHAT KIND OF CORRELATION (INCLUDING SPEARMAN AS OPTION) - the reason why I don't want to delete already is that I don't want it to directly throw an error in previous scripts\n",
    "    \n",
    "    Function that conducts spin permutation testing (for pearson correlation) specifically for data in Schaefer400 parcellation (len = 400) using enigmatoolbox.permutation_testing package\n",
    "    \n",
    "    Input:\n",
    "    - x: data to correlate (len = 400) \n",
    "    - y: data to correlate (len = 400) \n",
    "    \n",
    "    Output (display):  \n",
    "    - spin permutation p-value\n",
    "    - plotted null distribution of generated correlations\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    from enigmatoolbox.permutation_testing import spin_test, shuf_test\n",
    "    \n",
    "    print(\"there is an updated function -> SpinPermutationTest_Schaefer400 with specification of correlation type. Use that one and go to p1_myfunctions.ipynb to delete SpinPermutationTest_PearsonCorr_Schaefer400\")\n",
    "    \n",
    "    ### Project gradient loadings (from Schaefer 400 parcellation) to fsaverage5's 20484 vertices\n",
    "    \n",
    "    sample_1_fs5_grad_loadings = []\n",
    "    sample_2_fs5_grad_loadings = []\n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            sample_1_fs5_grad_loadings.append(0)\n",
    "            sample_2_fs5_grad_loadings.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the unimodal-heteromodal gradient eigenvalue of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            sample_1_fs5_grad_loadings.append(x[schaefer_400_fs5[i]-1])\n",
    "            sample_2_fs5_grad_loadings.append(y[schaefer_400_fs5[i]-1])\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings\n",
    "    sample_1_fs5_grad_loadings[sample_1_fs5_grad_loadings == 0] = np.nan\n",
    "    sample_2_fs5_grad_loadings[sample_2_fs5_grad_loadings == 0] = np.nan\n",
    "\n",
    "    # transform list into array\n",
    "    sample_1_fs5_grad_loadings = np.asarray(sample_1_fs5_grad_loadings)\n",
    "    sample_2_fs5_grad_loadings = np.asarray(sample_2_fs5_grad_loadings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Spin permutation testing \n",
    "    \n",
    "    # spin permutation testing for two cortical maps (output of spin_test is the p-value and the null distribution)\n",
    "    spin_test_p, spin_test_d = spin_test(sample_1_fs5_grad_loadings, sample_2_fs5_grad_loadings, surface_name='fsa5', parcellation_name='aparc', type='pearson', n_rot=1000, null_dist=True)\n",
    "    \n",
    "    \n",
    "    # print spin permutation test\n",
    "    print(f\"Spin permutation test p-value: {spin_test_p}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plot null distribution of generated correlations\n",
    "    \n",
    "    # To better interpret statistical significance, we can plot the null distribution of generated correlations (i.e., spun or shuffled correlations) and overlay the correlation coefficient obtained from the empirical (i.e., real) brain maps.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(15, 3))\n",
    "\n",
    "    ax.hist(spin_test_d, bins=50, density=True, color=\"blue\", edgecolor='white', lw=0.5)\n",
    "    ax.set_xlabel('Null correlations')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Null distribution of generated correlations')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960282b5-6b39-42d4-93a1-2e9d941db64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpinPermutationTest_Schaefer400(x, y, correlation_type = 'pearson'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that conducts spin permutation testing (for pearson correlation) specifically for data in Schaefer400 parcellation (len = 400) using enigmatoolbox.permutation_testing package\n",
    "    \n",
    "    Input:\n",
    "    - x: data to correlate (len = 400) \n",
    "    - y: data to correlate (len = 400) \n",
    "    - correlation_type: 'pearson' or 'spearman'\n",
    "    \n",
    "    Output (display):  \n",
    "    - spin permutation p-value\n",
    "    - plotted null distribution of generated correlations\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    from enigmatoolbox.permutation_testing import spin_test, shuf_test\n",
    "    \n",
    "    ### Project gradient loadings (from Schaefer 400 parcellation) to fsaverage5's 20484 vertices (required for enigmatoolbox.permutation_testing package)\n",
    "    \n",
    "    sample_1_fs5_grad_loadings = []\n",
    "    sample_2_fs5_grad_loadings = []\n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            sample_1_fs5_grad_loadings.append(0)\n",
    "            sample_2_fs5_grad_loadings.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the unimodal-heteromodal gradient eigenvalue of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            sample_1_fs5_grad_loadings.append(x[schaefer_400_fs5[i]-1])\n",
    "            sample_2_fs5_grad_loadings.append(y[schaefer_400_fs5[i]-1])\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings\n",
    "    sample_1_fs5_grad_loadings[sample_1_fs5_grad_loadings == 0] = np.nan\n",
    "    sample_2_fs5_grad_loadings[sample_2_fs5_grad_loadings == 0] = np.nan\n",
    "\n",
    "    # transform list into array\n",
    "    sample_1_fs5_grad_loadings = np.asarray(sample_1_fs5_grad_loadings)\n",
    "    sample_2_fs5_grad_loadings = np.asarray(sample_2_fs5_grad_loadings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Spin permutation testing \n",
    "    \n",
    "    # spin permutation testing for two cortical maps (output of spin_test is the p-value and the null distribution)\n",
    "    spin_test_p, spin_test_d = spin_test(sample_1_fs5_grad_loadings, sample_2_fs5_grad_loadings, surface_name='fsa5', parcellation_name='aparc', type=correlation_type, n_rot=1000, null_dist=True)\n",
    "    \n",
    "    \n",
    "    # print spin permutation test\n",
    "    print(f\"Spin permutation test p-value: {spin_test_p}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plot null distribution of generated correlations\n",
    "    \n",
    "    # To better interpret statistical significance, we can plot the null distribution of generated correlations (i.e., spun or shuffled correlations) and overlay the correlation coefficient obtained from the empirical (i.e., real) brain maps.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(15, 3))\n",
    "\n",
    "    ax.hist(spin_test_d, bins=50, density=True, color=\"blue\", edgecolor='white', lw=0.5)\n",
    "    ax.set_xlabel('Null correlations')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Null distribution of generated correlations')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a7ddf0-e1e3-48cc-9fbd-662db11ba4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    Function that produces RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sample\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients, i.e., mean gradient loadings across subjects per parcel, color coded by Yeo network, compared across samples \n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframes of gradient loadings - transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "    \n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    array_grad_sample_1['mean gradient loadings across subjects per parcel'] = array_grad_sample_1.mean(axis=1)\n",
    "    array_grad_sample_2['mean gradient loadings across subjects per parcel'] = array_grad_sample_2.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    array_grad_sample_1 = array_grad_sample_1[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    array_grad_sample_2 = array_grad_sample_2[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows) before merging them in order to make samples identifiable for plotting\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "    \n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    # color palette matching the RainCloud plot colors - specifying otherwise switches colors visual-DMN in the oder direction\n",
    "    # (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt)\n",
    "\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=color_palette,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=1,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9576114-3ca3-496d-abcb-4e3bfa4fc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad_IndDiff(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network by sample\n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients \n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "    \n",
    "    # dataframe of the gradient loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need the all subjects to be vertical in the dataframe in order to be labeled with their corresponding sample \n",
    "    array_grad_sample_1 = array_grad_sample_1.groupby(\"yeo network\", as_index=True).mean().T\n",
    "    array_grad_sample_2 = array_grad_sample_2.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    array_grad_sample_1.index.name = \"sub\"\n",
    "    array_grad_sample_1 = array_grad_sample_1.reset_index()\n",
    "\n",
    "    array_grad_sample_2.index.name = \"sub\"\n",
    "    array_grad_sample_2 = array_grad_sample_2.reset_index()\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sample lable as ID variables\n",
    "    df_to_plot = pd.melt(df_to_plot, id_vars=[\"sub\", 'sample'], var_name='yeo network', value_name='mean grad loadings per yeo network')\n",
    "\n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean grad loadings per yeo network\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=sns.color_palette(n_colors=7),\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a5bab3-dd16-4d8e-9d9b-d03d328d4ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sig_overlap(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_screenshot = False, modality = None):\n",
    "    \n",
    "    '''\n",
    "    Function that displays the overlap of signficant sex differences\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - sample_1_label: e.g., \"GSP G2\"\n",
    "    - sample_2_label: e.g., \"HCP G1\"\n",
    "    - save_screenshot: True or False - if you want to save screenshot in resdir_fig. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_grad (for name of figures saved in resdir_fig)\n",
    "    \n",
    "    Output display:\n",
    "    - printed text \"Number of parcels that show statistically significant sex differences\"\n",
    "    - plotted hemispheres: overlap of significant sex differences across samples: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant\n",
    "    - plotted hemispheres: which dataset shows significant sex difference\n",
    "    - plotted hemispheres: parcels showing sex differences in opposite directions (if any)\n",
    "    - plotted hemispheres: mean t-values for parcels showing an overlap of significant FDR-corrected statistical difference across samples (showing the same directionality of effects - opposite effects (different signs) are marked as nan) \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### mormat data to plot\n",
    "    \n",
    "    q_vals_sig_overlap = []  # significant sex differences (per parcel): 2 = in both datasets, 1 = in one dataset only, 0 = not significant in any dataset\n",
    "    sample1_v_sample2_sig = []  # which dataset shows significant sex difference (per parcel): +1 = sample 1, -1 = sample 2, 0 = both datasets, nan = not significant in any dataset\n",
    "    fdr_corrected_tvals_sample_1 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    fdr_corrected_tvals_sample_2 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    \n",
    "    for i in range(len(reg_res_sample_1.q_val_sex)):\n",
    "\n",
    "        count_sig = 0\n",
    "        sample1_v_sample2 = 0\n",
    "        not_sig_at_all = True\n",
    "\n",
    "        # sample 1\n",
    "        \n",
    "        if reg_res_sample_1.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 += 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "            # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(reg_res_sample_1.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # sample 2\n",
    "        \n",
    "        if reg_res_sample_2.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 -= 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "             # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(reg_res_sample_2.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # non significance\n",
    "        \n",
    "        if not_sig_at_all:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # if no significant we want to save as 0\n",
    "            sample1_v_sample2_sig.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "\n",
    "        else:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # append the sig counts in sig overlap\n",
    "            sample1_v_sample2_sig.append(float(sample1_v_sample2))  # append which sample showd significance (final interpretation: +1 = sample 1, -1 = sample 2, 0 = both samples\n",
    "    \n",
    "    \n",
    "    # check whether the directionality of sex differences is the same in the regions that overlap -> append to \"flags\" variable\n",
    "    \n",
    "    flags = []\n",
    "\n",
    "    for i in range(len(q_vals_sig_overlap)):\n",
    "\n",
    "        if q_vals_sig_overlap[i] == 2:\n",
    "\n",
    "            # if the sign of the t value is the same in GSP and HCP (either (+ and +) or (- and -), then append nan for no problem\n",
    "            if (reg_res_sample_1.t_val_sex[i] > 0 and reg_res_sample_2.t_val_sex[i] > 0) or (reg_res_sample_1.t_val_sex[i] < 0 and reg_res_sample_2.t_val_sex[i] < 0):\n",
    "                flags.append(float('nan'))\n",
    "\n",
    "            # else flag the problem with 1\n",
    "            else:\n",
    "                flags.append(float(1))\n",
    "\n",
    "        else:\n",
    "            flags.append(float('nan'))\n",
    "            \n",
    "            \n",
    "            \n",
    "    # mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "\n",
    "    fdr_corrected_tvals_overlap = []  \n",
    "    \n",
    "    for i in range(len(fdr_corrected_tvals_sample_1)):\n",
    "        \n",
    "        # if either (or both) samples is nan, append nan to overlap\n",
    "        if np.isnan(fdr_corrected_tvals_sample_1[i]) or np.isnan(fdr_corrected_tvals_sample_2[i]):\n",
    "            fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "        \n",
    "        # if there is a recorded t-value for both (not nan)\n",
    "        else:\n",
    "            # if the t values have the same sign (ie same direction of effects): take the mean t value\n",
    "            if np.sign(fdr_corrected_tvals_sample_1[i]) == np.sign(fdr_corrected_tvals_sample_2[i]):\n",
    "                fdr_corrected_tvals_overlap.append(statistics.mean((fdr_corrected_tvals_sample_1[i], fdr_corrected_tvals_sample_2[i])))\n",
    "            \n",
    "            # if different signs (ie different direction of effects): append nan\n",
    "            else:\n",
    "                fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "\n",
    "                \n",
    "    \n",
    "    \n",
    "    ### Plotting\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)  #len(labeling) = 64984 (i.e., conte69? at least matches as works with conte69 hemispheres)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0  # do not consider 0 labels which correspond to the midline\n",
    "    \n",
    "    # to be displayed\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## sig q vals correspondance\n",
    "    q_vals_sig_mapped_to_labels = map_to_labels(np.array(q_vals_sig_overlap), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    q_vals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = q_vals_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'Greens', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_fdr_corr.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append('Overlap of significant sex differences: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant')  # title\n",
    "    handles.append(q_vals_plotted_hemispheres)  # plot\n",
    "\n",
    "\n",
    "    \n",
    "    ## sample 1 or sample 2 significance \n",
    "    sample1_v_sample2_sig_mapped_to_labels = map_to_labels(np.array(sample1_v_sample2_sig), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    sample1_v_sample2_sig_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = sample1_v_sample2_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'RdYlGn_r', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sample_showing_sex_diff.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'Which dataset shows significant sex difference: +1 (red) {sample_1_label}, -1 (green) = {sample_2_label}, 0 (yellow) = both datasets, nan (grey) = not significant in any dataset')  # title\n",
    "    handles.append(sample1_v_sample2_sig_plotted_hemispheres)  # plot\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Plot the location of the flagged parcels where the directionality of the overalpping sex differences significant across samples isnt the same (if there are any)\n",
    "\n",
    "    if flags.count(1) > 0:\n",
    "\n",
    "        # defining labeling scheme and mask\n",
    "        # ! if doesn't work anymore for some reason, take this out of the definition (put it before it) !\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "\n",
    "        ### flagged parcels\n",
    "        flagged_mapped_to_labels = map_to_labels(np.array(flags), labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "        flagged_plotted_hemispheres = plot_hemispheres(\n",
    "            surf_lh, \n",
    "            surf_rh, \n",
    "            array_name = flagged_mapped_to_labels, \n",
    "            embed_nb = True, \n",
    "            size = (1400,200), \n",
    "            cmap = 'Reds_r', \n",
    "            color_bar = True, \n",
    "            #color_range = color_range_t,\n",
    "            nan_color = (0.7, 0.7, 0.7, 1),\n",
    "            #label_text = [\"overlap of significant sex differences\"],\n",
    "            zoom = 1.45,\n",
    "            screenshot = save_screenshot,\n",
    "            filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_opposing_directions.png')\n",
    "\n",
    "        # append to what will be displayed\n",
    "        handles.append('Parcels showing sex differences in opposite directions')  # title\n",
    "        handles.append(flagged_plotted_hemispheres)  # plot\n",
    "        \n",
    "        \n",
    "        \n",
    "    ## mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "    \n",
    "    fdr_corr_tvals_overlap_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals_overlap), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_overlap_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"t-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = resdir_fig+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_mean_t_val.png')\n",
    "\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'mean t-values for overlapping significant parcels (FDR-corrected, q < 0.05) across samples (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)  # plot\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Print significant overlap results\n",
    "    \n",
    "    print(f\"Number of parcels that show statistically significant sex differences across datasets: {q_vals_sig_overlap.count(2)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_1_label} only: {sample1_v_sample2_sig.count(1)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_2_label} only: {sample1_v_sample2_sig.count(-1)}\")\n",
    "    print(f\"Number of parcels (out of the {q_vals_sig_overlap.count(2)} parcels that show sig sex differences in both datasets) which show sex differences in opposite directions: {flags.count(1)}\\n\")\n",
    "\n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312b19aa-9381-44bb-8966-77a41dbb05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_tval(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_violin_plot = False, title = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that produces Rain Cloud and violin plots of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    Input:\n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    - save_violin_plot: True or False to save violin plot in resdir_fig\n",
    "    - modality: string e.g., local_ct or fc_grad\n",
    "    \n",
    "    Output (display):  \n",
    "    - printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "    - RainCloudPlot displaying sample 1 and 2 t-values \n",
    "    - Violin plot displaying sample 1 and 2 t-values\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "\n",
    "    list_samples = [reg_res_sample_1, reg_res_sample_2]\n",
    "    list_sample_labels = [sample_1_label, sample_2_label]\n",
    "\n",
    "    for e in range(len(list_samples)):\n",
    "    \n",
    "        # to record significant t-values (by sex)\n",
    "        tvals_sig_pos = []  # positive t-values == higher eignevalues in M\n",
    "        tvals_sig_neg = []  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        # to record the number of significant t-values per network (by sex)\n",
    "        dict_networks_sig_pos = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # positive t-values == higher eignevalues in M\n",
    "        dict_networks_sig_neg = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        for i in range(len(list_samples[e])):\n",
    "            if list_samples[e].iloc[i].q_val_sex < 0.05:\n",
    "                if list_samples[e].iloc[i].t_val_sex > 0:\n",
    "                    tvals_sig_pos.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_pos[yeo7_networks_array_labels[i]] += 1\n",
    "                else:\n",
    "                    tvals_sig_neg.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_neg[yeo7_networks_array_labels[i]] += 1\n",
    "\n",
    "        print(f\"Minimum positive significant t-value in {list_sample_labels[e]}: {round(min(tvals_sig_pos), 2)}\\nMinimum negative significant t-value in {list_sample_labels[e]}: {round(max(tvals_sig_neg), 2)}\\n\")\n",
    "        print(f\"Number of positive significant t-values (M > F (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_pos)} -> by network: {dict_networks_sig_pos}\\nNumber of negative significant t-values (F > M (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_neg)} -> by network: {dict_networks_sig_neg}\\n\\n\")\n",
    "\n",
    "        \n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "\n",
    "    # dataframe of the t-values \n",
    "    sample_1_tval = pd.DataFrame(reg_res_sample_1.t_val_sex)\n",
    "    sample_2_tval = pd.DataFrame(reg_res_sample_2.t_val_sex)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    sample_1_tval['yeo network'] = yeo7_networks_array_labels\n",
    "    sample_2_tval['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    sample_1_tval[\"sample\"] = sample_1_label\n",
    "    sample_2_tval[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    sample_1_tval.index.name = \"parcel\"\n",
    "    sample_1_tval = sample_1_tval.reset_index()\n",
    "\n",
    "    sample_2_tval.index.name = \"parcel\"\n",
    "    sample_2_tval = sample_2_tval.reset_index()\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets) -> already in the correct shape for the Raincloudplot\n",
    "    df_all_tval = pd.concat([sample_1_tval, sample_2_tval], axis = 'index')\n",
    "\n",
    "\n",
    "    \n",
    "    ### Rain Cloud plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    print(\"Rain Cloud plot of t-values (regression results) by Yeo network by sample\")\n",
    "\n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"t_val_sex\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_all_tval,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    \n",
    "    #ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    \n",
    "    \n",
    "    ### Violin plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    fig, eg = plt.subplots(figsize = (15,5))\n",
    "    eg = sns.violinplot(data=df_all_tval, \n",
    "                        x=\"yeo network\", \n",
    "                        y=\"t_val_sex\",\n",
    "                        hue=\"sample\",\n",
    "                        palette = ['firebrick', 'darkolivegreen'],\n",
    "                        split = True)       \n",
    "    \n",
    "    eg.axes.set_title(\"Violin plot of t-values (sex contrast) by Yeo network\", y=1.05, fontsize=20)\n",
    "    eg.set_xlabel(\"Yeo network\",fontsize=25)\n",
    "    eg.set_ylabel(\"t-value sex contrast\",fontsize=25)\n",
    "    eg.tick_params(labelsize=25)\n",
    "    eg.set_xticklabels(eg.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    eg.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    \n",
    "    if save_violin_plot:\n",
    "         ## save figure in directory \n",
    "        fig.savefig(resdir_fig+title+'_violin_sex_contrast_tval_netw.png', dpi=300, bbox_inches=\"tight\")  # bbox_inches is so that the figure doesn't get cut off when saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15867ed4-aa43-49f2-88ad-c8616381023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_surface_to_parcel_for_all_subjects(surface_level_across_subs, surface_atlas_to_parcellation = ['schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69']):\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    Function that reshapes data from surface-level to parcel-level\n",
    "    \n",
    "    Input:\n",
    "    - surface_level_across_subs: surface level data (i.e., vertices) across subjects in format: N x vertices\n",
    "    - surface_atlas_to_parcellation: what surface atlas (e.g., fsa5 (20484 vertices), conte69 (64984 vertices)) needs to be converted into what parcellation scheme (e.g., Schaefer 400)\n",
    "        - possible string options: 'schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69'\n",
    "        - Note: ONLY USE ON CONVERSION TO SCHAEFER 400 (hardcoded removal of first element yielded by the enigmatoolbox surface_to_parcel function, corresponding to midline (1st out of 401 parcels)\n",
    "                 Need to see manually what comes out of function for other pacellation schemes\n",
    "    \n",
    "    Output:\n",
    "    - dictionary containing: \n",
    "        - parcel_level_all_subs: data in parcellated format\n",
    "        - mean_across_parcels: mean value (of whatever is being manipulated here, e.g., CT) across surface/parcels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import enigma toolbox function surface_to_parcel\n",
    "    from enigmatoolbox.utils.parcellation import surface_to_parcel \n",
    "    \n",
    "    \n",
    "    # define list that will contain the data in new parcellated format\n",
    "    parcel_level_all_subs = []\n",
    "    \n",
    "    # define list that will contain the mean value (of whatever is being computed here) across surface/parcels\n",
    "    mean_across_parcels = []\n",
    "    \n",
    "\n",
    "    ### get the CT data in Schaefer 400 format for all subjects\n",
    "    \n",
    "    # iterate over the number of subjects (surface_level_across_subs is in N x vertices format)\n",
    "    for i in range(len(surface_level_across_subs)):\n",
    "\n",
    "        # transform surface data to parcellated data using enigma toolbox function, according to specified surface_atlas_to_parcellation schemes\n",
    "        sub_parcel_level = surface_to_parcel(surface_level_across_subs[i], surface_atlas_to_parcellation)  # enigmatoolbox function transforming to Schaefer 400 yields array len = 401 (including midline as first array element)\n",
    "\n",
    "        # deleting first element (index = 0) of the array corresponding to midline in order to yield Schaefer 400 (len = 400) parcellated data\n",
    "        sub_parcel_level = np.delete(sub_parcel_level, 0) \n",
    "\n",
    "        # appending current subject's values for all parcels to list of parcel-level values for all subjects \n",
    "        parcel_level_all_subs.append(sub_parcel_level)\n",
    "\n",
    "        # appending current subject's mean value (across parcels) to corresponding list\n",
    "        mean_across_parcels.append(statistics.mean(sub_parcel_level))\n",
    "\n",
    "\n",
    "    # make the variable containing newly parcellated data of all subjects into array    \n",
    "    parcel_level_all_subs = np.array(parcel_level_all_subs)  \n",
    "\n",
    "\n",
    "    #  store \n",
    "    dict_output = {'parcel_level_all_subs': parcel_level_all_subs, 'mean_across_parcels': mean_across_parcels}\n",
    "\n",
    "    \n",
    "    return dict_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "184aed26-59f9-4438-9f37-282f78508cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_structural_covariance_matrix_with_covariates(array_ct_subjects_parcels, covar = []):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes the structural covariance matrix across subjects using partial correlation (i.e., controlling for covariates)\n",
    "    - structural covariance matrix (parcels*parcels) can only be computed at the group-level\n",
    "    - needs to be across subjects otherwise cannot compute correlation because each parcel has 1 CT value per subject\n",
    "    \n",
    "    Note: VERY SLOW FUNCTION (13 min for 1570 subjects) because it calculates every single one of the parcel*parcel covariance matrix pairwise partial correlation coefficients \n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "    - covar: list/series containing covariate variables for the structural covariance matrix (to control for during partial correlation), e.g., 3 covariates: [demographics_df.global_ct, demographics_df.age, demographics_df.sex]\n",
    "        - note: dummy variables need to be coded numerically (not with string labels)\n",
    "        - note: make sure that the length of the covariate variables are as long as the length of array containing CT data (i.e., N = number of subjects)\n",
    "    \n",
    "    Output:\n",
    "    - structural covariance matrix across subjects (parcels*parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import pingouin package which includes partial_corr -> function to compute partial correlation\n",
    "    import pingouin as pg\n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    ### Format data to make it analyzable compute partial correlation: dataframe requirey by pingouin (pg) partial_corr function\n",
    "\n",
    "    # change shape from N x parcels to parcels x N, and turn array into a list in order to add covariates (lists of length = N) \n",
    "    df_ct_cov_matrix = (array_ct_subjects_parcels.T).tolist()\n",
    "\n",
    "    # add specified covariates\n",
    "    for i in range(len(covar)):\n",
    "        df_ct_cov_matrix.append(covar[i])\n",
    "\n",
    "    # make into dataframe (reverting back to shape N x parcels)\n",
    "     # columns = parcels + covariates, which can be called upon to compute pairwise partial correlations between parcels (x and y), whilst taking into account covariates (covar_indices)\n",
    "     # rows = subjects\n",
    "     # in this way, a the pairwise partial correlations are computed between 2 parcels, across all subject CT values for those parcel (e.g. Parcel 1 (CT values for N subjects) correlated with Parcel 2 (CT values for N subjects)\n",
    "    df_ct_cov_matrix = pd.DataFrame(np.array(df_ct_cov_matrix).T) \n",
    "    \n",
    "    \n",
    "    ### Compute structural covariance matrix across subjects using partial correlation (i.e., controling for covariates)\n",
    "    \n",
    "    # list of indices of covariates in dataframe (in descending order but doesn't matter, they are included all at once in partial correlation calculation) \n",
    "    covar_indices = []\n",
    "    \n",
    "    for i in range(len(covar)):\n",
    "        covar_indices.append(len(df_ct_cov_matrix.columns) - 1 - i)  # -1 in order to account for the fact that index starts at 0\n",
    "    \n",
    "\n",
    "    # list containing the structural covariance matrix\n",
    "    ct_cov_matrix_list = []\n",
    "\n",
    "    \n",
    "    # iteration across the parcels: to obtain the number of parcels, calculate length columns minus length covariates\n",
    "    for n in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "        # list for one line of the structural covariance matrix\n",
    "        line_partial_corr_coef = []\n",
    "        \n",
    "        # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to correlate parcel(n) with parcel(i)\n",
    "        for i in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "            # if parcel number n and i are NOT the same, compute partial correlation coefficient\n",
    "            if i != n:\n",
    "                \n",
    "                # define x and y variables to correlate for this iteration (pairwise partial correlation)\n",
    "                x = df_ct_cov_matrix.columns[n]  # x variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                y = df_ct_cov_matrix.columns[i]  # y variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                \n",
    "                # compute the pairwise partial correlation (specifying the x and y variables to be correlated, as well as covariate variables <- what is specified is the dataframe, and the column names)\n",
    "                # directly storing the correlation coefficient (as a float)\n",
    "                partial_corr_coef = float(pg.partial_corr(data = df_ct_cov_matrix, x = x, y = y, covar = covar_indices, x_covar = None, y_covar = None, alternative=\"two-sided\", method = \"pearson\").r)\n",
    "                \n",
    "                # append the partial correlation coefficient to the list for the current line (iteration) of the structural covariance matrix\n",
    "                line_partial_corr_coef.append(partial_corr_coef)\n",
    "\n",
    "\n",
    "            # if i == n: correlation of the parcel with itself, so r = 1 (append this value manually)\n",
    "            else:\n",
    "                line_partial_corr_coef.append(1)\n",
    "\n",
    "            # if last iteration of the line (the line is already at its full length (i.e., len(line_partial_corr_coef) == number of parcels), append line of correlation coefficients to the full matrix list\n",
    "            if len(line_partial_corr_coef) == (len(df_ct_cov_matrix.columns) - len(covar)):  \n",
    "                ct_cov_matrix_list.append(line_partial_corr_coef)\n",
    "\n",
    "\n",
    "    # saving the structural covariance matrix in array format\n",
    "    ct_cov_matrix = np.array(ct_cov_matrix_list)\n",
    "    \n",
    "    \n",
    "    return ct_cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87080f56-e31f-4dd5-a8cf-338de85a3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_correlation_matrices(x, y, label_x, label_y):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that displays the row-wise correlation between structurak and functional 400x400 correlation matrices\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - x: 400x400 mean matrix to correlate (1)\n",
    "    - y: 400x400 mean matrix to correlate (2)\n",
    "    \n",
    "    Output display:\n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "        Interpretation: I get for each of the 400 parcels an r-value of the association/correlation between how that parcel correlates with the other 399 parcels (structure) and how thtat parcels correlates with the other 399 parcels (function)\n",
    "    - plotted hemispheres: p-values of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices that pass bonferonni significance threshold (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    count_sig = 0\n",
    "    count_sig_bonferroni = 0\n",
    "\n",
    "    list_p_val = []\n",
    "    list_corr_coef = []\n",
    "    list_corr_coef_bonferroni = []\n",
    "    list_corr_coef_bonferroni_nan = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        corr_coef = stats.pearsonr(x[i], y[i])[0]\n",
    "        p_val = stats.pearsonr(x[i], y[i])[1]\n",
    "\n",
    "        list_corr_coef.append(corr_coef)\n",
    "        list_p_val.append(p_val)\n",
    "\n",
    "        if p_val < (0.05):\n",
    "            count_sig += 1\n",
    "\n",
    "            if p_val < (0.05/400):\n",
    "                count_sig_bonferroni += 1\n",
    "                list_corr_coef_bonferroni.append(corr_coef)\n",
    "                list_corr_coef_bonferroni_nan.append(corr_coef)\n",
    "\n",
    "            else:\n",
    "                list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "       \n",
    "        else:\n",
    "            list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    " \n",
    "    \n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: {count_sig}\")\n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: (Bonferroni corrected; alpha = 0.05/400 = 0.000125): {count_sig_bonferroni}\")\n",
    "\n",
    "\n",
    "    \n",
    "    ### Plots\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## correlation coefficents\n",
    "    corrcoef_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef), labeling, mask=mask, fill=np.nan)  \n",
    "    \n",
    "    corrcoef_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"PiYG\",\n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r)\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    # plot\n",
    "    handles.append(corrcoef_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ## p-values\n",
    "    pvals_mapped_to_labels = map_to_labels(np.asarray(list_p_val), labeling, mask=mask, fill=np.nan)      \n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## correlation coefficients (only the one passing Bonferroni corrected significance)   \n",
    "    corrcoef_bonf_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef_bonferroni_nan), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # decision of the color coding scheme\n",
    "    if sum(1 for number in list_corr_coef_bonferroni if number < 0) == 0:  # of there are no negative correlation coefficients (passing bonferroni corrected significance level)\n",
    "        color_decision = \"YlGn\"  # use color map that goes gradual from small to high\n",
    "    else:\n",
    "        color_decision = \"PiYG\"  # use color map that goes (-) to 0 to (+)\n",
    "    \n",
    "    corrcoef_bonf_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_bonf_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = color_decision,  \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r) Bonf\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(corrcoef_bonf_plotted_hemispheres)\n",
    "        \n",
    "        \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a39bfceb-7bbb-4714-80c9-088a0a9acdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ct_similarity_matrices_for_all_subjects(array_ct_subjects_parcels):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes cortical thickness similarity matrices for all subjects (individual level)\n",
    "\n",
    "    Note: VERY SLOW FUNCTION (15 min for 1570 subjects) because it calculates every single one of the parcel*parcel similarity coefficient\n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "      \n",
    "    Output:\n",
    "    - CT similarity matrices for each subject (shape: N x parcels x parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### list of standard deviation of CT values for each parcel (across subjects) -> required for formula calculating similarity coefficients\n",
    "\n",
    "    list_std_parcels = []\n",
    "\n",
    "    # iterate over parcels (by taking transposed ct_schaefer400 variable) \n",
    "    for i in range(len(array_ct_subjects_parcels.T)):\n",
    "\n",
    "        # calculate standard deviation of CT values for that parcel (across subjects)\n",
    "        std_parcel = np.std(array_ct_subjects_parcels.T[i])\n",
    "\n",
    "        # add standard deviation for current parcel to list\n",
    "        list_std_parcels.append(std_parcel)\n",
    "\n",
    "\n",
    "    ### compute similarity matrices (containing all subjects)\n",
    "\n",
    "    similarity_ct_matrices = []\n",
    "\n",
    "    # loop over subjects\n",
    "    for sub in range(len(array_ct_subjects_parcels)):\n",
    "\n",
    "        # list containing a subject's similarity matrix (400x400)\n",
    "        sub_similarity_ct_matrix = []\n",
    "\n",
    "        # iteration across parcels\n",
    "        for i in range(len(array_ct_subjects_parcels[sub])):        \n",
    "\n",
    "            # list containing one line (row) of the similarity matrix\n",
    "            line_similarity_ct_matrix_list = []\n",
    "\n",
    "            # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to compute the similarity between parcel(n) with parcel(i)\n",
    "            for j in range(len(array_ct_subjects_parcels[sub])):\n",
    "\n",
    "                # compute similarity coefficient (according to: Wee et al (2013) https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.22156) -> it works, proof: when i=j, yields similarity of 1.0\n",
    "\n",
    "                dissimilarity = (array_ct_subjects_parcels[sub][i] - array_ct_subjects_parcels[sub][j])**2\n",
    "\n",
    "                sigma = math.sqrt(list_std_parcels[i] + list_std_parcels[j])\n",
    "\n",
    "                # similarity coefficient\n",
    "                similarity = math.exp(- dissimilarity / (2 * (sigma)**2))\n",
    "\n",
    "                # append similarity coefficient for current parcel interaction to the line of similarity ct matrix (list)\n",
    "                line_similarity_ct_matrix_list.append(similarity)\n",
    "\n",
    "\n",
    "                # if last iteration (parcel) of the line (the line is already at its full length (i.e., len(line_similarity_ct_matrix_list) == number of parcels), append line of correlation coefficients to the subject's similarity matrix\n",
    "                if len(line_similarity_ct_matrix_list) == len(array_ct_subjects_parcels[sub]):  \n",
    "                    sub_similarity_ct_matrix.append(line_similarity_ct_matrix_list)\n",
    "\n",
    "        # if last iteration (line) of the matrix (the matrix is already at its full length (i.e., len(sub_similarity_ct_matrix) == number of parcels), append the subject's similarity matrix to the list of similarity ct matrices (all subjects)  \n",
    "        if len(sub_similarity_ct_matrix) == len(array_ct_subjects_parcels[sub]):\n",
    "            similarity_ct_matrices.append(sub_similarity_ct_matrix)\n",
    "\n",
    "    # saving the similarity matrix in array format\n",
    "    similarity_ct_matrices = np.array(similarity_ct_matrices)\n",
    "\n",
    "    return similarity_ct_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cade7a03-970f-465a-89f6-d9552bd631e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_parcel_values_scatter_bysex(male_data, female_data, title = None):\n",
    "    \n",
    "    '''\n",
    "    Function that males a scatterplot comparing mean male vs female parcel values (e.g. mean function gradient loading per parcel) color coded per Yeo network for Schaeffer 400\n",
    "    \n",
    "    Input: mean male and female values (format: array len = 400, i.e. number of Schafer parcels)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # make a dataframe containing the male and female data (to make it plottable)\n",
    "    dataframe = pd.DataFrame({'M': male_data, 'F': female_data})\n",
    "    \n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    sns.scatterplot(data = dataframe, x = 'M', y = 'F', \n",
    "                    hue=yeo7_networks_array_labels,  # gives color coding based on yeo networks\n",
    "                    palette=palette_labeled_networks, \n",
    "                    s=70, \n",
    "                    edgecolor='black',\n",
    "                    linewidth=1)\n",
    "\n",
    "    # plot line x = y through getting the x and y limits\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    lims = [max(x0, y0), min(x1, y1)]\n",
    "    ax.plot(lims, lims, 'black', linewidth=2)\n",
    "\n",
    "    ax.axes.set_title(f\"Male vs Female {title}\", y=1.05, fontsize=25)\n",
    "    ax.set_xlabel(\"Males\",fontsize=25)\n",
    "    ax.set_ylabel(\"Females\",fontsize=25)\n",
    "    ax.tick_params(labelsize=25)\n",
    "    ax.legend(fontsize=25, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb70650-4f4a-41eb-9109-675a884b7104",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a2ea4ec-b6df-4f94-9b56-cdf3d97f6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_wholebrain_corr_to_mean(mean_grad, mean_grad_M, mean_grad_F, subject_grad, subject_ages, subject_sexes):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability at the wholebrain level by correlating individual subject gradient loadings with mean gradient loadings (-> computing deviations from the mean as quantified by correlation coefficient) shown in plots\n",
    "    Ordering HCP subjects by age only for plotting purposes (although it could also include information on variability (i.e., if there seems to be an age effect))\n",
    "    \n",
    "    Input variables: \n",
    "    - mean_grad: mean gradient loadings (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - mean_grad_M: mean gradient loadings for male subsample (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - mean_grad_F: mean gradient loadings for female subsample (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_ages: list of subject ages\n",
    "    - subject_sexes: list of subject sexes\n",
    "    \n",
    "    Output:\n",
    "    - scatter and box plots comparing individual gradients to overall mean (ordered by age) -> To study variability as a function of age\n",
    "    - scatter and box plots comparing individual gradients to overall mean (color coded by sex) -> To study variability as a function of sex\n",
    "    - mean correlation coefficients by sex -> to indicate greater male or female variability\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Ordering subjects by age only for plotting purposes (although it could also include information on variability (i.e., if there seems to be an age effect)\n",
    "    \n",
    "    # getting the ages in their original order from demographics dataframe\n",
    "    subject_ages_rawoder = subject_ages\n",
    "\n",
    "    # np.argsort outputs the indices by which the list would be sorted (ascending order)\n",
    "    subject_indices_age_sorting = np.argsort(subject_ages_rawoder)\n",
    "\n",
    "    # sort the ages list\n",
    "    subject_ages_sorted = subject_ages_rawoder.copy()\n",
    "    subject_ages_sorted.sort()\n",
    "\n",
    "    # sort the subject gradient loadings by age (using the indices used to sort subject age list)\n",
    "    array_aligned_grad_age_sorted = np.array([subject_grad[i] for i in subject_indices_age_sorting])\n",
    "\n",
    "\n",
    "    # sort the subject sex variable by age (using the indices used to sort subject age list)\n",
    "    subject_sex_sorted = np.array([subject_sexes[i] for i in subject_indices_age_sorting])\n",
    "\n",
    "    # need to numberise the sex labels for plotting\n",
    "    subject_sex_sorted_num = []\n",
    "\n",
    "    for letter in subject_sex_sorted:\n",
    "        if letter == 'M':\n",
    "            subject_sex_sorted_num.append(0)\n",
    "        else:\n",
    "            subject_sex_sorted_num.append(1)\n",
    "\n",
    "    subject_sex_sorted_num = np.array(subject_sex_sorted_num)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### computing differences between individual subject gradient loadings and mean sample gradient loadings (correlation coefficient) -> deviations from the mean\n",
    "\n",
    "    # computing the differences between the each HCP G1 and HCP mean G1 using correlation coefficient\n",
    "    list_corr_coeff_ind_mean_grad = []\n",
    "\n",
    "    # for every subject in the aligned gradient array, correlate that subject's gradient loadings with the mean gradient loadings\n",
    "    for sub in array_aligned_grad_age_sorted:\n",
    "\n",
    "        # appending correlation coefficient to the list\n",
    "        list_corr_coeff_ind_mean_grad.append(stats.pearsonr(mean_grad, sub)[0])\n",
    "\n",
    "\n",
    "    ### making a dictionary with correlation data to format it for making boxplots using sns\n",
    "    dict_ind_var = {'ages': subject_ages_sorted, 'sex': subject_sex_sorted, 'r_ind_mean': list_corr_coeff_ind_mean_grad}\n",
    "\n",
    "\n",
    "\n",
    "    ### computing differences between individual gradient loadings and mean gradient loadings FOR GIVEN SEX (correlation coefficient)\n",
    "    # THIS SHOULD BE USED WHEN COMPARING MALE TO FEMALE VARIABILITY IN GRADIENT LOADINGS given that there are more female subjects in sample, which would skew results towards better correlations (less variability) for females\n",
    "\n",
    "    # computing the differences between the each subject's gradient loadings and mean gradient loadings using correlation coefficient\n",
    "    list_corr_coeff_ind_mean_grad_bysex = []\n",
    "\n",
    "    # for every subject in the aligned G1 array, correlate that subject's gradient loadings with the mean HCP G1 loadings\n",
    "    for i in range(len(array_aligned_grad_age_sorted)):\n",
    "\n",
    "        # appending correlation coefficient to the list (correlation with mean male or mean female gradient values depending on sex of current subject iterated over\n",
    "        if subject_sex_sorted[i] == 'M':\n",
    "            list_corr_coeff_ind_mean_grad_bysex.append(stats.pearsonr(mean_grad_M, array_aligned_grad_age_sorted[i])[0])\n",
    "\n",
    "        else:\n",
    "            list_corr_coeff_ind_mean_grad_bysex.append(stats.pearsonr(mean_grad_F, array_aligned_grad_age_sorted[i])[0])\n",
    "\n",
    "    # appending correlation coefficient by sex to dictionary\n",
    "    dict_ind_var['r_ind_mean_bysex'] = list_corr_coeff_ind_mean_grad_bysex\n",
    "\n",
    "\n",
    "    # turning the dictionary into a dataframe\n",
    "    df_ind_var = pd.DataFrame(dict_ind_var)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plots\n",
    "\n",
    "    ## Comparing individual gradients to overall mean (ordered by age)\n",
    "    # To study variability as a function of age\n",
    "    \n",
    "    print(\"Correlation of individual gradient loadings to mean gradient loadings (age ordered)\")\n",
    "    \n",
    "    plt.scatter(subject_ages_sorted, list_corr_coeff_ind_mean_grad)\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(data=dict_ind_var, x='ages', y='r_ind_mean') \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## Comparing individual gradients to mean of given sex\n",
    "    # To study wholebrain variability as a function of sex\n",
    "    \n",
    "    print(\"Correlation of individual gradient loadings to mean gradient loadings of given sex (color-coded by sex)\")\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    plt.scatter(subject_ages_sorted, list_corr_coeff_ind_mean_grad_bysex, c=df_ind_var['sex'].map(colors))\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(data=dict_ind_var, x='sex', y='r_ind_mean_bysex', palette=colors, fliersize = 2) \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean correlation coefficient of male individual gradients and mean male gradient: M = {round(df_ind_var.loc[df_ind_var['sex'] == 'M', 'r_ind_mean_bysex'].mean(), 2)}; SD = {round(df_ind_var.loc[df_ind_var['sex'] == 'M', 'r_ind_mean_bysex'].std(), 3)}\\n\"\n",
    "      f\"Mean correlation coefficient of female individual gradients and mean female gradient: M = {round(df_ind_var.loc[df_ind_var['sex'] == 'F', 'r_ind_mean_bysex'].mean(), 2)}; SD = {round(df_ind_var.loc[df_ind_var['sex'] == 'F', 'r_ind_mean_bysex'].std(), 3)}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de4e0dc-2755-445c-bc48-7b21e591fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_parcel_std(subject_grad, subject_grad_M, subject_grad_F, sample_modality, save_plots = False):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes variability at the parcel level: Visualizing standard deviation by parcels in both sexes separately in order to visualize which sex and parcels have most variability\n",
    "    - computing the 'difference score' of std (male std - female std) as quantification\n",
    "    - testing the significance of the sex difference using Levene's test for homogeneity of variance (+ FDR-correction)\n",
    "    - computing a network breakdown of significant differences (pie charts)\n",
    "    \n",
    "    Input variables:\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    - save_plots: True/False if want to save screenshots of plotted hemispheres and network breakdown of significant differences\n",
    "    - sample_modality: will be included in label of saved plot names (e.g., 'HCP_fc_G1')\n",
    "    \n",
    "    Output:\n",
    "    - Number of parcels for which there males have a statistically significant larger variance than females; and for which females have a statistically significant larger variance than males (before and after FDR correction)\n",
    "    - plotted hemispheres: *STD across all subjects, STD males, STD females, difference STD M - F, p-values Levene's test, q-values Levene's test (FDR), difference STD for p sig, *difference STD for q sig\n",
    "    - nested pie chart: breakdown of statistically significant sex differences by network\n",
    "    - saves in resdir_fig: *STD_plotted_hemispheres_across_sexes, *STD_plotted_hemispheres_sex_differences_fdr_corr, and STD_pie_chart_sex_diff_netw\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad = np.std(subject_grad, axis=0)\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "\n",
    "\n",
    "    ### Compute the difference between males and female std (where positive scores show greater male variability)\n",
    "    std_grad_sexdiff = std_grad_M - std_grad_F\n",
    "\n",
    "    \n",
    "    ### Significance testing of the differences\n",
    "\n",
    "    # list that will contain the p values of the Levene's test for homogeneity of variance (per parcel) -> p < 0.05 mean NOT homogeneous variance, meaning that we can interpret the variability (as provided by difference of STD) as statistically significant\n",
    "    p_val_levene_grad_male_vs_female = []\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(subject_grad_M.T)):\n",
    "\n",
    "        # test for homogeneity of variance within this parcel (between males and females) - [1] indexes the p-value -> append p-value to list\n",
    "        p_val_levene_grad_male_vs_female.append(stats.levene(subject_grad_M.T[i], subject_grad_F.T[i])[1])\n",
    "\n",
    "    p_val_levene_grad_male_vs_female = np.array(p_val_levene_grad_male_vs_female)\n",
    "\n",
    "\n",
    "    # compute the FDR-corrected q values of G1 sex differences in variance as given from Levene's test pvalues\n",
    "    fdr_corr_p_val_levene_grad_male_vs_female = fdrcorrection(p_val_levene_grad_male_vs_female)[1]\n",
    "\n",
    "\n",
    "\n",
    "    # list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) - NOT FDR corrected (just to see patterns)\n",
    "    std_grad_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_levene_sig_sexdiff = np.array(std_grad_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    print(f\"Number of parcels for which there males have a statistically significant larger variance than females: {np.sum(np.array(std_grad_levene_sig_sexdiff) > 0, axis=0)}\")\n",
    "    print(f\"Number of parcels for which there females have a statistically significant larger variance than males: {np.sum(np.array(std_grad_levene_sig_sexdiff) < 0, axis=0)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) AFTER FDR correction (so where q < 0.05)\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = np.array(std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    print(f\"Number of parcels for which there males have a statistically significant larger variance than females after FDR-correction: {np.sum(np.array(std_grad_fdr_corr_levene_sig_sexdiff) > 0, axis=0)}\")\n",
    "    print(f\"Number of parcels for which there females have a statistically significant larger variance than males after FDR-correction: {np.sum(np.array(std_grad_fdr_corr_levene_sig_sexdiff) < 0, axis=0)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Find min and max std across sexes (this is for plotting the color bar in the plotted hemispheres)\n",
    "\n",
    "    if min(std_grad_M) < min(std_grad_F):\n",
    "        min_std = min(std_grad_M)\n",
    "    else:\n",
    "        min_std = min(std_grad_F)\n",
    "\n",
    "    print(f\"\\nMinimum SD: Males = {round(min(std_grad_M), 3)}; Females = {round(min(std_grad_F), 3)}\")\n",
    "\n",
    "\n",
    "    if max(std_grad_M) > max(std_grad_F):\n",
    "        max_std = max(std_grad_M)\n",
    "    else:\n",
    "        max_std = max(std_grad_F)\n",
    "\n",
    "    print(f\"Maximum SD: Males = {round(max(std_grad_M), 3)}; Females = {round(max(std_grad_F), 3)}\")\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    ### plot the standard deviations on hemispheres\n",
    "\n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "\n",
    "    mask = labeling != 0\n",
    "\n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "\n",
    "    std_to_labels = map_to_labels(std_grad, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['STD'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = resdir_fig+sample_modality+'_STD_plotted_hemispheres_across_sexes.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_to_labels_M = map_to_labels(std_grad_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['Males'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_to_labels_F = map_to_labels(std_grad_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['Females'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_grad_sexdiff_to_labels = map_to_labels(std_grad_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 label_text=['STD(M) - STD (F)'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_sexdiff)\n",
    "\n",
    "\n",
    "\n",
    "    levene_pval_to_labels = map_to_labels(p_val_levene_grad_male_vs_female, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_levene_pval = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=levene_pval_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='plasma_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=[\"Levene's p-vals\"], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_levene_pval)\n",
    "\n",
    "\n",
    "\n",
    "    fdr_corr_levene_pval_to_labels = map_to_labels(fdr_corr_p_val_levene_grad_male_vs_female, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_fdr_corr_levene_pval = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=fdr_corr_levene_pval_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='plasma_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=[\"FDR-corrected\\nLevene's q-vals\"], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_fdr_corr_levene_pval)\n",
    "\n",
    "\n",
    "\n",
    "    std_grad_sig_Levene_sexdiff_to_labels = map_to_labels(std_grad_levene_sig_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_levene_sig_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sig_Levene_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['Differences STD\\nfor Levene p<.05'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    std_grad_sig_fdr_corr_levene_sexdiff_to_labels = map_to_labels(std_grad_fdr_corr_levene_sig_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_fdr_corr_levene_sig_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sig_fdr_corr_levene_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['Differences STD\\nfor FDR-corrected\\nLevene q<.05'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = resdir_fig+sample_modality+'_STD_plotted_hemispheres_sex_differences_fdr_corr.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    display(*handles)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    ### breakdown by network\n",
    "    \n",
    "    \n",
    "    ## written breakdown\n",
    "\n",
    "    # counting number of significant parcels\n",
    "    # storing the Q values in a list (where non significant Q values are marked as 1 -> for later potential scatterplot visualization)\n",
    "    # making a dictionary that counts the number of significant parcels per yeo network\n",
    "    # making dictionaries that count the number of significant parcels per yeo network by sex\n",
    "\n",
    "    sig_Q_vals = []\n",
    "    count_sig = 0\n",
    "    count_sig_M = 0\n",
    "    count_sig_F = 0\n",
    "    count_sig_per_network = {\"visual\": 0, \"sensory motor\": 0, \"DMN\": 0, \"dorsal attention\": 0, \"ventral attention\": 0, \"limbic\": 0, \"fronto parietal\": 0}\n",
    "    count_sig_per_network_bysex = {\"visual\": [0, 0], \"sensory motor\": [0,0], \"DMN\": [0,0], \"dorsal attention\": [0,0], \"ventral attention\": [0,0], \"limbic\": [0,0], \"fronto parietal\": [0,0]} # M: [0], F: [1]\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(fdr_corr_p_val_levene_grad_male_vs_female)):\n",
    "\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] < 0.05:\n",
    "            count_sig += 1\n",
    "            count_sig_per_network[yeo7_networks_array_labels[i]] += 1\n",
    "            sig_Q_vals.append(1)\n",
    "\n",
    "            # positive t-values mean male > female: increment the first item of the list fort given label\n",
    "            if std_grad_sexdiff[i] > 0:\n",
    "                count_sig_M += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][0] += 1\n",
    "\n",
    "            # positive t-values mean female > male: increment the second item of the list for the given label\n",
    "            else:\n",
    "                count_sig_F += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][1] += 1\n",
    "\n",
    "        else:\n",
    "            sig_Q_vals.append(0)\n",
    "\n",
    "    print(f\"Number of significant parcels: {count_sig}\\n\")\n",
    "    print(f\"Number of significant parcels for males: {count_sig_M}\")\n",
    "    print(f\"Number of significant parcels for females: {count_sig_F}\\n\")\n",
    "    print(\"Number of significant parcels in each Yeo network (across sexes):\")\n",
    "\n",
    "    # using ANSI escape sequences to underline -> bold: \\033[1m ; underline: \\033[4m ; end: \\033[0m\n",
    "    for i in range(len(count_sig_per_network)):\n",
    "        print(f\"- {list(count_sig_per_network.keys())[i]}: \\033[4m{count_sig_per_network[list(count_sig_per_network.keys())[i]]}\\033[0m out of {yeo7_networks_array_labels.tolist().count(network_names[i])} ({round(count_sig_per_network[list(count_sig_per_network.keys())[i]] / yeo7_networks_array_labels.tolist().count(network_names[i]) * 100, 2)}%) -> \\033[1m{round(count_sig_per_network[list(count_sig_per_network.keys())[i]]*100/count_sig,2)}%\\033[0m of overall significance\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Nested pie chart\n",
    "\n",
    "    ## make data plottable\n",
    "    list_count_sig_per_network_bysex = []\n",
    "\n",
    "    for label in count_sig_per_network_bysex:\n",
    "        list_count_sig_per_network_bysex.append(count_sig_per_network_bysex[label])\n",
    "\n",
    "    vals = np.array(list_count_sig_per_network_bysex)\n",
    "\n",
    "    outer_colors = [\"darkorchid\",  # visual\n",
    "                    \"steelblue\",  # sensorimotor\n",
    "                    \"indianred\",  # dmn\n",
    "                    \"forestgreen\",  # dorsal attention\n",
    "                    \"orchid\",  # ventral attention\n",
    "                    \"lemonchiffon\",  # limbic\n",
    "                    \"orange\"]  # frontoparietal\n",
    "    inner_colors = ['lightblue', 'lightcoral',  # visual\n",
    "                    'lightblue', 'lightcoral',  # sensorimotor\n",
    "                    'lightblue', 'lightcoral',  # dmn\n",
    "                    'lightblue', 'lightcoral',  # dorsal attention\n",
    "                    'lightblue', 'lightcoral',  # ventral attention\n",
    "                    'lightblue', 'lightcoral',  # limbic\n",
    "                    'lightblue', 'lightcoral']  #frontoparietal\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    size = 0.3\n",
    "\n",
    "    ## plot outer pie\n",
    "    ax.pie(vals.sum(axis=1), radius=1, labels=count_sig_per_network_bysex.keys(), colors=outer_colors, autopct='%.0f%%', pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 20})\n",
    "\n",
    "    ## plot inner pie\n",
    "\n",
    "    # make a list (in order) containing the labels (sex - hardcoded) only for sections that have more than 1 count (otherwise label is placeholder: blank)\n",
    "\n",
    "    labels_only_show_non_null = []\n",
    "\n",
    "    for network in list_count_sig_per_network_bysex:\n",
    "\n",
    "        # males\n",
    "        if network[0] > 0:\n",
    "            labels_only_show_non_null.append('M')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "\n",
    "        # females\n",
    "        if network[1] > 0:\n",
    "            labels_only_show_non_null.append('F')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "\n",
    "    ax.pie(vals.flatten(), radius=1-size, labels=labels_only_show_non_null, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "\n",
    "    ax.set(aspect=\"equal\")\n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant sex difference in gradient loadings, by sex', y=1.03, fontsize=20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('Number of significant parcels by sex:')\n",
    "    for network in count_sig_per_network_bysex:\n",
    "        print(f\"{network} - Male: {count_sig_per_network_bysex[network][0]}, Female: {count_sig_per_network_bysex[network][1]}\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ### plot outer and inner pie (without labels)\n",
    "\n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "\n",
    "    disp.pie(vals.sum(axis=1), radius=1, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 20})\n",
    "\n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='blacK'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "\n",
    "    disp.set(aspect=\"equal\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_plots:\n",
    "        ## save figure in directory \n",
    "        fig.savefig(resdir_fig+sample_modality+'_STD_pie_chart_sex_diff_netw.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4204acb9-c97f-4fa9-aa2d-3e7c545737a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_network_corr_to_mean_G1(mean_grad, mean_grad_M, mean_grad_F, subject_grad, subject_grad_M, subject_grad_F):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability at the network level by correlating individual subject gradient loadings (HARDCODED FOR G1!!) with mean gradient loadings (-> computing deviations from the mean as quantified by correlation coefficient) by sex, shown in plots\n",
    "    CAUTION: working with data that is NOT age sorted here (different to variability_wholebrain_corr_to_mean function)\n",
    "    \n",
    "    Input variables: \n",
    "    - mean_grad: mean gradient loadings (full gradient array container -> HCP_mean_fc_grad.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - mean_grad_M: mean gradient loadings for male subsample (full gradient array container -> HCP_mean_fc_grad_M.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - mean_grad_F: mean gradient loadings for female subsample (full gradient array container -> HCP_mean_fc_grad_M.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    \n",
    "    Output:\n",
    "    - box plot correlation coefficients by network (color-coded by sex)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### compute mean gradient loadings per networks (overall and by sex)\n",
    "\n",
    "    # lists that will contain mean gradient loadings (per network)\n",
    "    visual_mean_grad_loadings = []\n",
    "    sensorimotor_mean_grad_loadings = []\n",
    "    dorsalattention_mean_grad_loadings = []\n",
    "    ventralattention_mean_grad_loadings = []\n",
    "    limbic_mean_grad_loadings = []\n",
    "    frontoparietal_mean_grad_loadings = []\n",
    "    dmn_mean_grad_loadings = []\n",
    "\n",
    "\n",
    "    # lists that will contain mean gradient loadings (per network) by sex\n",
    "    visual_mean_grad_loadings_M = []\n",
    "    sensorimotor_mean_grad_loadings_M = []\n",
    "    dorsalattention_mean_grad_loadings_M = []\n",
    "    ventralattention_mean_grad_loadings_M = []\n",
    "    limbic_mean_grad_loadings_M = []\n",
    "    frontoparietal_mean_grad_loadings_M = []\n",
    "    dmn_mean_grad_loadings_M = []\n",
    "\n",
    "    visual_mean_grad_loadings_F = []\n",
    "    sensorimotor_mean_grad_loadings_F = []\n",
    "    dorsalattention_mean_grad_loadings_F = []\n",
    "    ventralattention_mean_grad_loadings_F = []\n",
    "    limbic_mean_grad_loadings_F = []\n",
    "    frontoparietal_mean_grad_loadings_F = []\n",
    "    dmn_mean_grad_loadings_F = []\n",
    "\n",
    "\n",
    "\n",
    "    # iterating over 400 parcels \n",
    "    # CAUTION: THIS PART IS HARCODED FOR GRADIENT 1 (index: [i,0])\n",
    "    for i in range(len(mean_grad[:,0])):\n",
    "\n",
    "        # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to \n",
    "        # doing for overall, males, and females separately (ok because we're looping over the number of parcels, which is the same for all 3 cases\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            visual_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            visual_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            sensorimotor_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            sensorimotor_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "            dorsalattention_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            dorsalattention_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            dorsalattention_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            ventralattention_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            ventralattention_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            limbic_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            limbic_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            frontoparietal_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            frontoparietal_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            dmn_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            dmn_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### compute per subject (overall)\n",
    "\n",
    "    # lists that will contain subject-level gradient loadings (per network) - length of each list is N, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings = []\n",
    "    sensorimotor_sub_grad_loadings = []\n",
    "    dorsalattention_sub_grad_loadings = []\n",
    "    ventralattention_sub_grad_loadings = []\n",
    "    limbic_sub_grad_loadings = []\n",
    "    frontoparietal_sub_grad_loadings = []\n",
    "    dmn_sub_grad_loadings = []\n",
    "\n",
    "\n",
    "    # for every subject in the aligned gradient array\n",
    "    for j in range(len(subject_grad)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of gradient loadings) for given subject\n",
    "        for i in range(len(subject_grad[j])):\n",
    "\n",
    "            # append given parcel's mean gradient loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "\n",
    "    ### compute per subject (by sex) - need to do this separately because looping over subjects in aligned gradients per sex (aligned to that sex's mean gradient) which are of different lengths in males vs females\n",
    "\n",
    "    ## MALES\n",
    "\n",
    "    # lists that will contain subject-level G1 gradient loadings (per network) - length of each list is N males, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings_M = []\n",
    "    sensorimotor_sub_grad_loadings_M = []\n",
    "    dorsalattention_sub_grad_loadings_M = []\n",
    "    ventralattention_sub_grad_loadings_M = []\n",
    "    limbic_sub_grad_loadings_M = []\n",
    "    frontoparietal_sub_grad_loadings_M = []\n",
    "    dmn_sub_grad_loadings_M = []\n",
    "\n",
    "\n",
    "    # for every subject in the HCP aligned G1 array\n",
    "    for j in range(len(subject_grad_M)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of G1 loadings) for given subject\n",
    "        for i in range(len(subject_grad_M[j])):\n",
    "\n",
    "            # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings_M.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings_M.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings_M.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings_M.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings_M.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings_M.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings_M.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "    ## FEMALES\n",
    "\n",
    "    # lists that will contain subject-level G1 gradient loadings (per network) - length of each list is N females, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings_F = []\n",
    "    sensorimotor_sub_grad_loadings_F = []\n",
    "    dorsalattention_sub_grad_loadings_F = []\n",
    "    ventralattention_sub_grad_loadings_F = []\n",
    "    limbic_sub_grad_loadings_F = []\n",
    "    frontoparietal_sub_grad_loadings_F = []\n",
    "    dmn_sub_grad_loadings_F = []\n",
    "\n",
    "\n",
    "    # for every subject in the HCP aligned G1 array\n",
    "    for j in range(len(subject_grad_F)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of G1 loadings) for given subject\n",
    "        for i in range(len(subject_grad_F[j])):\n",
    "\n",
    "            # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings_F.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings_F.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings_F.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings_F.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings_F.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings_F.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings_F.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### computing variability in forms of correlation with mean (overall and by sex)\n",
    "\n",
    "    ### overall\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per network (difference computed using correlation coefficient)\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings = []\n",
    "\n",
    "    # loop over all paricipants (N)\n",
    "    for i in range(len(subject_grad)):\n",
    "\n",
    "        # computing the differences between the given subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings.append(stats.pearsonr(visual_sub_grad_loadings[i], visual_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings.append(stats.pearsonr(sensorimotor_sub_grad_loadings[i], sensorimotor_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings.append(stats.pearsonr(dorsalattention_sub_grad_loadings[i], dorsalattention_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings.append(stats.pearsonr(ventralattention_sub_grad_loadings[i], ventralattention_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings.append(stats.pearsonr(limbic_sub_grad_loadings[i], limbic_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings.append(stats.pearsonr(frontoparietal_sub_grad_loadings[i], frontoparietal_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings.append(stats.pearsonr(dmn_sub_grad_loadings[i], dmn_mean_grad_loadings)[0])\n",
    "\n",
    "\n",
    "    ### by sex\n",
    "\n",
    "    ## MALES\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per netwrok (difference computed using correlation coefficient) in males\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M = []\n",
    "\n",
    "    # loop over all male paricipants \n",
    "    for i in range(len(subject_grad_M)):\n",
    "\n",
    "        # computing the differences between the given male subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M.append(stats.pearsonr(visual_sub_grad_loadings_M[i], visual_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M.append(stats.pearsonr(sensorimotor_sub_grad_loadings_M[i], sensorimotor_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M.append(stats.pearsonr(dorsalattention_sub_grad_loadings_M[i], dorsalattention_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M.append(stats.pearsonr(ventralattention_sub_grad_loadings_M[i], ventralattention_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M.append(stats.pearsonr(limbic_sub_grad_loadings_M[i], limbic_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M.append(stats.pearsonr(frontoparietal_sub_grad_loadings_M[i], frontoparietal_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M.append(stats.pearsonr(dmn_sub_grad_loadings_M[i], dmn_mean_grad_loadings_M)[0])\n",
    "\n",
    "\n",
    "    ## FEMALES\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per network (difference computed using correlation coefficient) in females\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F = []\n",
    "\n",
    "    # loop over all female paricipants \n",
    "    for i in range(len(subject_grad_F)):\n",
    "\n",
    "        # computing the differences between the given female subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F.append(stats.pearsonr(visual_sub_grad_loadings_F[i], visual_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F.append(stats.pearsonr(sensorimotor_sub_grad_loadings_F[i], sensorimotor_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F.append(stats.pearsonr(dorsalattention_sub_grad_loadings_F[i], dorsalattention_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F.append(stats.pearsonr(ventralattention_sub_grad_loadings_F[i], ventralattention_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F.append(stats.pearsonr(limbic_sub_grad_loadings_F[i], limbic_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F.append(stats.pearsonr(frontoparietal_sub_grad_loadings_F[i], frontoparietal_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F.append(stats.pearsonr(dmn_sub_grad_loadings_F[i], dmn_mean_grad_loadings_F)[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### transform / store data to make it plottable\n",
    "    dict_ind_var_network_bysex = {'sex': ['M'] * len(subject_grad_M) + ['F'] * len(subject_grad_F), 'r_visual': list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M + list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F, 'r_sensorimotor': list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M + list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F, 'r_dorsalattention': list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M + list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F, 'r_ventralattention': list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M + list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F, 'r_limbic' : list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M + list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F, 'r_frontoparietal': list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M + list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F, 'r_dmn': list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M + list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F}\n",
    "\n",
    "    df_ind_var_network_bysex = pd.DataFrame(dict_ind_var_network_bysex)\n",
    "\n",
    "    df_ind_var_network_bysex_long = pd.melt(df_ind_var_network_bysex, id_vars=['sex'], value_vars=['r_visual', 'r_sensorimotor', 'r_dorsalattention', 'r_ventralattention', 'r_limbic', 'r_frontoparietal', 'r_dmn'], var_name='network', value_name='corr_coef')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Plot\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10));\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    ax = sns.boxplot(data=df_ind_var_network_bysex_long, x='network', y='corr_coef', hue = 'sex', \n",
    "                palette=colors, \n",
    "                fliersize = 2)\n",
    "\n",
    "    ax.set_xlabel('network', fontsize=25);\n",
    "    ax.set_ylabel('correlation coefficient', fontsize=25);\n",
    "    ax.tick_params(labelsize=25);\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"center\")\n",
    "    ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c28e7d-5df9-42a3-ae50-bdc1df94611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_network_std(subject_grad_M, subject_grad_F):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability (mean standard deviation) across parcels belonging to same network\n",
    "    \n",
    "    Input variables: \n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    \n",
    "    Output:\n",
    "    - bar plot of mean std by network color-coded by sex\n",
    "    \n",
    "    '''\n",
    "     \n",
    "    ### STD computation and arrangement per network\n",
    "    \n",
    "    # Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "    \n",
    "    \n",
    "    # lists that will contain std per sex per network\n",
    "    visual_std_grad_M = []\n",
    "    sensorimotor_std_grad_M = []\n",
    "    dorsalattention_std_grad_M = []\n",
    "    ventralattention_std_grad_M = []\n",
    "    limbic_std_grad_M = []\n",
    "    frontoparietal_std_grad_M = []\n",
    "    dmn_std_grad_M = []\n",
    "\n",
    "    visual_std_grad_F = []\n",
    "    sensorimotor_std_grad_F = []\n",
    "    dorsalattention_std_grad_F = []\n",
    "    ventralattention_std_grad_F = []\n",
    "    limbic_std_grad_F = []\n",
    "    frontoparietal_std_grad_F = []\n",
    "    dmn_std_grad_F = []\n",
    "\n",
    "    # iterating over 400 parcels (of std) \n",
    "    for i in range(len(std_grad_M)):\n",
    "\n",
    "        # append given parcel's std gradient loading to the corresponding list depending on what network it belongs to (and by sex)\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_std_grad_M.append(std_grad_M[i])\n",
    "            visual_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_std_grad_M.append(std_grad_M[i])\n",
    "            sensorimotor_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "            dorsalattention_std_grad_M.append(std_grad_M[i])\n",
    "            dorsalattention_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_std_grad_M.append(std_grad_M[i])\n",
    "            ventralattention_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_std_grad_M.append(std_grad_M[i])\n",
    "            limbic_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_std_grad_M.append(std_grad_M[i])\n",
    "            frontoparietal_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_std_grad_M.append(std_grad_M[i])\n",
    "            dmn_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "\n",
    "\n",
    "    ### Shape data for plotting mean std by network by sex\n",
    "\n",
    "    dict_mean_std_network_bysex = {'sex': ['M','F'], 'visual': [statistics.mean(visual_std_grad_M), statistics.mean(visual_std_grad_F)], 'sensorimotor': [statistics.mean(sensorimotor_std_grad_M), statistics.mean(sensorimotor_std_grad_F)], 'dorsal attention': [statistics.mean(dorsalattention_std_grad_M), statistics.mean(dorsalattention_std_grad_F)], 'ventral attention': [statistics.mean(ventralattention_std_grad_M), statistics.mean(ventralattention_std_grad_F)], 'limbic': [statistics.mean(limbic_std_grad_M), statistics.mean(limbic_std_grad_F)], 'fronto parietal': [statistics.mean(frontoparietal_std_grad_M), statistics.mean(frontoparietal_std_grad_F)], 'DMN': [statistics.mean(dmn_std_grad_M), statistics.mean(dmn_std_grad_F)]}\n",
    "\n",
    "    df_mean_std_network_bysex = pd.DataFrame(dict_mean_std_network_bysex)\n",
    "\n",
    "    df_mean_std_network_bysex_long = pd.melt(df_mean_std_network_bysex, id_vars=['sex'], value_vars=['visual', 'sensorimotor', 'dorsal attention', 'ventral attention', 'limbic', 'fronto parietal', 'DMN'], var_name='network', value_name='mean sd')\n",
    "\n",
    "\n",
    "\n",
    "    ### Plot \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10));\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    ax = sns.barplot(data=df_mean_std_network_bysex_long, x='network', y='mean sd', hue='sex', palette=colors)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('network', fontsize=25);\n",
    "    ax.set_ylabel('mean SD', fontsize=25);\n",
    "    ax.tick_params(labelsize=25);\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"center\")\n",
    "    ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54cb629f-a1a5-4784-8589-5baf6892d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_parcel_std_spotlight_network(subject_grad_M, subject_grad_F):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes variability at the parcel level as done by function variability_parcel_std (visualizing standard deviation by parcels in both sexes separately, as well as difference scores (STD M - STD F) but displays by network (masking all but one network -> spotlight approach)\n",
    "\n",
    "    Input variables:\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    \n",
    "    Output:\n",
    "    - plotted hemispheres -> spotlight approach (per network, masking parcels belonging to other networks): STD males, STD females, difference STD for q sig    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    ### computing the same as function variability_parcel_std\n",
    "    \n",
    "    ## Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "    \n",
    "    \n",
    "    ## Compute the difference between males and female std (where positive scores show greater male variability)\n",
    "    std_grad_sexdiff = std_grad_M - std_grad_F\n",
    "\n",
    "\n",
    "    ## Significance testing of the differences\n",
    "\n",
    "    # list that will contain the p values of the Levene's test for homogeneity of variance (per parcel) -> p < 0.05 mean NOT homogeneous variance, meaning that we can interpret the variability (as provided by difference of STD) as statistically significant\n",
    "    p_val_levene_grad_male_vs_female = []\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(subject_grad_M.T)):\n",
    "\n",
    "        # test for homogeneity of variance within this parcel (between males and females) - [1] indexes the p-value -> append p-value to list\n",
    "        p_val_levene_grad_male_vs_female.append(stats.levene(subject_grad_M.T[i], subject_grad_F.T[i])[1])\n",
    "\n",
    "    p_val_levene_grad_male_vs_female = np.array(p_val_levene_grad_male_vs_female)\n",
    "\n",
    "\n",
    "    ## compute the FDR-corrected q values of G1 sex differences in variance as given from Levene's test pvalues\n",
    "    fdr_corr_p_val_levene_grad_male_vs_female = fdrcorrection(p_val_levene_grad_male_vs_female)[1]\n",
    "    \n",
    "    \n",
    "    ## list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) AFTER FDR correction (so where q < 0.05)\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = np.array(std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Find min and max std across sexes (this is for plotting the color bar in the plotted hemispheres)\n",
    "\n",
    "    if min(std_grad_M) < min(std_grad_F):\n",
    "        min_std = min(std_grad_M)\n",
    "    else:\n",
    "        min_std = min(std_grad_F)\n",
    "\n",
    "    print(f\"\\nMinimum SD: Males = {round(min(std_grad_M), 3)}; Females = {round(min(std_grad_F), 3)}\")\n",
    "\n",
    "\n",
    "    if max(std_grad_M) > max(std_grad_F):\n",
    "        max_std = max(std_grad_M)\n",
    "    else:\n",
    "        max_std = max(std_grad_F)\n",
    "\n",
    "    print(f\"Maximum SD: Males = {round(max(std_grad_M), 3)}; Females = {round(max(std_grad_F), 3)}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Making lists by network\n",
    "    \n",
    "    # lists that will contain the std gradient per sex values for a given network and nans in parcels that do not belong to that network\n",
    "    visual_std_grad_to_plot_M = []\n",
    "    sensorimotor_std_grad_to_plot_M = []\n",
    "    dorsalattention_std_grad_to_plot_M = []\n",
    "    ventralattention_std_grad_to_plot_M = []\n",
    "    limbic_std_grad_to_plot_M = []\n",
    "    frontoparietal_std_grad_to_plot_M = []\n",
    "    dmn_std_grad_to_plot_M = []\n",
    "\n",
    "    visual_std_grad_to_plot_F = []\n",
    "    sensorimotor_std_grad_to_plot_F = []\n",
    "    dorsalattention_std_grad_to_plot_F = []\n",
    "    ventralattention_std_grad_to_plot_F = []\n",
    "    limbic_std_grad_to_plot_F = []\n",
    "    frontoparietal_std_grad_to_plot_F = []\n",
    "    dmn_std_grad_to_plot_F = []\n",
    "\n",
    "    # lists that will contain the difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "\n",
    "\n",
    "\n",
    "    # loop over 400 parcels and each time if parcel corresponds to a given yeo network, append the std value of that parcel for males and females, else append nan\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            visual_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            visual_std_grad_to_plot_M.append(float('nan'))\n",
    "            visual_std_grad_to_plot_F.append(float('nan'))\n",
    "            visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            sensorimotor_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            sensorimotor_std_grad_to_plot_M.append(float('nan'))\n",
    "            sensorimotor_std_grad_to_plot_F.append(float('nan'))\n",
    "            sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "\n",
    "            dorsalattention_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            dorsalattention_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            dorsalattention_std_grad_to_plot_M.append(float('nan'))\n",
    "            dorsalattention_std_grad_to_plot_F.append(float('nan'))\n",
    "            dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            ventralattention_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            ventralattention_std_grad_to_plot_M.append(float('nan'))\n",
    "            ventralattention_std_grad_to_plot_F.append(float('nan'))\n",
    "            ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            limbic_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            limbic_std_grad_to_plot_M.append(float('nan'))\n",
    "            limbic_std_grad_to_plot_F.append(float('nan'))\n",
    "            limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            frontoparietal_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            frontoparietal_std_grad_to_plot_M.append(float('nan'))\n",
    "            frontoparietal_std_grad_to_plot_F.append(float('nan'))\n",
    "            frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            dmn_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            dmn_std_grad_to_plot_M.append(float('nan'))\n",
    "            dmn_std_grad_to_plot_F.append(float('nan'))\n",
    "            dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "\n",
    "    # make lists as array (required for plotting hemispheres)\n",
    "    visual_std_grad_to_plot_M = np.array(visual_std_grad_to_plot_M)\n",
    "    sensorimotor_std_grad_to_plot_M = np.array(sensorimotor_std_grad_to_plot_M)\n",
    "    dorsalattention_std_grad_to_plot_M = np.array(dorsalattention_std_grad_to_plot_M)\n",
    "    ventralattention_std_grad_to_plot_M = np.array(ventralattention_std_grad_to_plot_M)\n",
    "    limbic_std_grad_to_plot_M = np.array(limbic_std_grad_to_plot_M)\n",
    "    frontoparietal_std_grad_to_plot_M = np.array(frontoparietal_std_grad_to_plot_M)\n",
    "    dmn_std_grad_to_plot_M = np.array(dmn_std_grad_to_plot_M)\n",
    "\n",
    "    visual_std_grad_to_plot_F = np.array(visual_std_grad_to_plot_F)\n",
    "    sensorimotor_std_grad_to_plot_F = np.array(sensorimotor_std_grad_to_plot_F)\n",
    "    dorsalattention_std_grad_to_plot_F = np.array(dorsalattention_std_grad_to_plot_F)\n",
    "    ventralattention_std_grad_to_plot_F = np.array(ventralattention_std_grad_to_plot_F)\n",
    "    limbic_std_grad_to_plot_F = np.array(limbic_std_grad_to_plot_F)\n",
    "    frontoparietal_std_grad_to_plot_F = np.array(frontoparietal_std_grad_to_plot_F)\n",
    "    dmn_std_grad_to_plot_F = np.array(dmn_std_grad_to_plot_F)\n",
    "\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### plot the standard deviations by network on hemispheres\n",
    "\n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "\n",
    "    mask = labeling != 0\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### MALES\n",
    "\n",
    "    # will contain the different plots for males\n",
    "    handles_M = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_to_labels_M = map_to_labels(visual_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_visual_M.png')\n",
    "\n",
    "    handles_M.append(visual_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_to_labels_M = map_to_labels(sensorimotor_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_M.png')\n",
    "\n",
    "    handles_M.append(sensorimotor_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_to_labels_M = map_to_labels(dorsalattention_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_M.png')\n",
    "\n",
    "    handles_M.append(dorsalattention_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_to_labels_M = map_to_labels(ventralattention_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_M.png')\n",
    "\n",
    "    handles_M.append(ventralattention_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_to_labels_M = map_to_labels(limbic_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_limbic_M.png')\n",
    "\n",
    "    handles_M.append(limbic_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_to_labels_M = map_to_labels(frontoparietal_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_M.png')\n",
    "\n",
    "    handles_M.append(frontoparietal_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_to_labels_M = map_to_labels(dmn_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dmn_M.png')\n",
    "\n",
    "    handles_M.append(dmn_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    print('Males')\n",
    "    display(*handles_M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### FEMALES\n",
    "\n",
    "    # will contain the different plots for females\n",
    "    handles_F = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_to_labels_F = map_to_labels(visual_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_visual_F.png')\n",
    "\n",
    "    handles_F.append(visual_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_to_labels_F = map_to_labels(sensorimotor_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_F.png')\n",
    "\n",
    "    handles_F.append(sensorimotor_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_to_labels_F = map_to_labels(dorsalattention_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_F.png')\n",
    "\n",
    "    handles_F.append(dorsalattention_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_to_labels_F = map_to_labels(ventralattention_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_F.png')\n",
    "\n",
    "    handles_F.append(ventralattention_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_to_labels_F = map_to_labels(limbic_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_limbic_F.png')\n",
    "\n",
    "    handles_F.append(limbic_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_to_labels_F = map_to_labels(frontoparietal_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_F.png')\n",
    "\n",
    "    handles_F.append(frontoparietal_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_to_labels_F = map_to_labels(dmn_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dmn_F.png')\n",
    "\n",
    "    handles_F.append(dmn_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    print('Females')\n",
    "    display(*handles_F)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ### DIFFERENCE SCORE (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\n",
    "\n",
    "    # will contain the different plots \n",
    "    handles = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_visual_F.png')\n",
    "\n",
    "    handles.append(visual_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_F.png')\n",
    "\n",
    "    handles.append(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_F.png')\n",
    "\n",
    "    handles.append(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_F.png')\n",
    "\n",
    "    handles.append(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_limbic_F.png')\n",
    "\n",
    "    handles.append(limbic_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_F.png')\n",
    "\n",
    "    handles.append(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = resdir_fig+'HCP_fc'+'_plotted_hemispheres_std_dmn_F.png')\n",
    "\n",
    "    handles.append(dmn_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    print(\"difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\")\n",
    "    display(*handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0256814-2346-4faf-8eee-32e5ffb7d247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59665f5c-24ed-4ecb-ab9c-86d5ddd9f2ca",
   "metadata": {},
   "source": [
    "# Project 1: Sex Differences in brain organization\n",
    "\n",
    "### Main Script: Sex classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec93fe-05ce-4116-9a20-61d219f03e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b981a67-12da-409f-ab72-d3d8c224110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from math import isnan\n",
    "import statistics\n",
    "import pingouin as pg\n",
    "import pickle\n",
    "\n",
    "# Computing\n",
    "import scipy.io  # loadmat\n",
    "from scipy import stats\n",
    "import sklearn \n",
    "from brainstat.stats.terms import FixedEffect\n",
    "from brainstat.stats.SLM import SLM\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import vtk\n",
    "from IPython.display import display\n",
    "import matplotlib.collections as clt\n",
    "import ptitprince as pt\n",
    "\n",
    "# Neuroimaging\n",
    "import nibabel\n",
    "import nilearn\n",
    "from brainstat.datasets import fetch_parcellation\n",
    "from enigmatoolbox.permutation_testing import spin_test, shuf_test\n",
    "\n",
    "# Gradients\n",
    "import brainspace\n",
    "from brainspace.datasets import load_parcellation, load_conte69\n",
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.utils.parcellation import map_to_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9ee12-b367-4666-b82e-1adc816a6b3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d613a43a-6d0c-4143-9ea6-6b3a8e17efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "codedir = os.path.abspath('')  # obtain current direction from which script is runnning\n",
    "\n",
    "datadir = '/data/p_02667/sex_diff_gradients/data/'\n",
    "\n",
    "resdir_gsp = '/data/p_02667/sex_diff_gradients/results/GSP/'\n",
    "resdir_hcp = '/data/p_02667/sex_diff_gradients/results/HCP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cb6b6-8812-4420-b618-1439cad70154",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859407f-e499-40fa-926c-9f11b98765de",
   "metadata": {},
   "source": [
    "#### Confound removal\n",
    "https://academic.oup.com/gigascience/article/doi/10.1093/gigascience/giac014/6547681#339860007\n",
    "https://github.com/darya-chyzhyk/confound_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36b85f5d-2608-41ea-8e85-586d690e9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ConfoundRegressor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Fits a confound onto each feature in X and returns their residuals.\"\"\"\n",
    "\n",
    "    def __init__(self, confound, X, cross_validate=True, precise=False,\n",
    "                 stack_intercept=True):\n",
    "        \"\"\" Regresses out a variable (confound) from each feature in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confound : numpy array\n",
    "            Array of length (n_samples, n_confounds) to regress out of each\n",
    "            feature; May have multiple columns for multiple confounds.\n",
    "        X : numpy array\n",
    "            Array of length (n_samples, n_features), from which the confound\n",
    "            will be regressed. This is used to determine how the\n",
    "            confound-models should be cross-validated (which is necessary\n",
    "            to use in in scikit-learn Pipelines).\n",
    "        cross_validate : bool\n",
    "            Whether to cross-validate the confound-parameters (y~confound)\n",
    "            estimated from the train-set to the test set (cross_validate=True)\n",
    "            or whether to fit the confound regressor separately on the test-set\n",
    "            (cross_validate=False). Setting this parameter to True is equivalent\n",
    "            to \"foldwise confound regression\" (FwCR) as described in our paper\n",
    "            (https://www.biorxiv.org/content/early/2018/03/28/290684). Setting\n",
    "            this parameter to False, however, is NOT equivalent to \"whole\n",
    "            dataset confound regression\" (WDCR) as it does not apply confound\n",
    "            regression to the *full* dataset, but simply refits the confound\n",
    "            model on the test-set. We recommend setting this parameter to True.\n",
    "        precise: bool\n",
    "            Transformer-objects in scikit-learn only allow to pass the data\n",
    "            (X) and optionally the target (y) to the fit and transform methods.\n",
    "            However, we need to index the confound accordingly as well. To do so,\n",
    "            we compare the X during initialization (self.X) with the X passed to\n",
    "            fit/transform. As such, we can infer which samples are passed to the\n",
    "            methods and index the confound accordingly. When setting precise to\n",
    "            True, the arrays are compared feature-wise, which is accurate, but\n",
    "            relatively slow. When setting precise to False, it will infer the index\n",
    "            by looking at the sum of all the features, which is less accurate, but much\n",
    "            faster. For dense data, this should work just fine. Also, to aid the\n",
    "            accuracy, we remove the features which are constant (0) across samples.\n",
    "        stack_intercept : bool\n",
    "            Whether to stack an intercept to the confound (default is True)\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        weights_ : numpy array\n",
    "            Array with weights for the confound(s).\n",
    "        \"\"\"\n",
    "\n",
    "        self.confound = confound\n",
    "        self.cross_validate = cross_validate\n",
    "        self.X = X\n",
    "        self.precise = precise\n",
    "        self.stack_intercept = stack_intercept\n",
    "        self.weights_ = None\n",
    "        self.nonzero_X_ = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Fits the confound-regressor to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array\n",
    "            An array of shape (n_samples, n_features), which should correspond\n",
    "            to your train-set only!\n",
    "        y : None\n",
    "            Included for compatibility; does nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.stack_intercept:\n",
    "            icept = np.ones(self.confound.shape[0])\n",
    "            self.confound = np.c_[icept, self.confound]\n",
    "\n",
    "        # Find nonzero voxels (i.e., voxels which have not all zero\n",
    "        # values across samples)\n",
    "        if self.nonzero_X_ is None:\n",
    "            self.nonzero_X_ = np.sum(self.X, axis=0) != 0\n",
    "            self.X = self.X[:, self.nonzero_X_]\n",
    "\n",
    "        X_nz = X[:, self.nonzero_X_]\n",
    "        confound = self.confound\n",
    "\n",
    "        if self.precise:\n",
    "            tmp = np.in1d(self.X, X_nz).reshape(self.X.shape)\n",
    "            fit_idx = tmp.sum(axis=1) == self.X.shape[1]\n",
    "        else:\n",
    "            fit_idx = np.in1d(self.X.sum(axis=1), X_nz.sum(axis=1))\n",
    "\n",
    "        confound_fit = confound[fit_idx, :]\n",
    "\n",
    "        # Vectorized implementation estimating weights for all features\n",
    "        self.weights_ = np.linalg.lstsq(confound_fit, X_nz, rcond=None)[0]\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Regresses out confound from X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array\n",
    "            An array of shape (n_samples, n_features), which should correspond\n",
    "            to your train-set only!\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : ndarray\n",
    "            ndarray with confound-regressed features\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.cross_validate:\n",
    "            self.fit(X)\n",
    "\n",
    "        X_nz = X[:, self.nonzero_X_]\n",
    "\n",
    "        if self.precise:\n",
    "            tmp = np.in1d(self.X, X_nz).reshape(self.X.shape)\n",
    "            transform_idx = tmp.sum(axis=1) == self.X.shape[1]\n",
    "        else:\n",
    "            transform_idx = np.in1d(self.X.sum(axis=1), X_nz.sum(axis=1))\n",
    "\n",
    "        confound_transform = self.confound[transform_idx]\n",
    "        X_new = X - confound_transform.dot(self.weights_)\n",
    "        X_corr = np.zeros_like(X)\n",
    "        X_corr[:, self.nonzero_X_] = X_new\n",
    "        return X_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb23bb-4f9c-4fd0-8360-bc71cbf325eb",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0c545ef-d5d0-4af0-ab42-17969a3ef39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics data\n",
    "GSP_demographics_cleaned = pd.read_csv(resdir_gsp+'demographics_cleaned.csv')\n",
    "HCP_demographics_cleaned = pd.read_csv(resdir_hcp+'demographics_cleaned.csv')\n",
    "\n",
    "# CT data\n",
    "GSP_ct_schaefer400 = pd.read_csv(resdir_gsp+'ct_schaefer400.csv')\n",
    "HCP_ct_schaefer400 = pd.read_csv(resdir_hcp+'ct_schaefer400.csv')\n",
    "\n",
    "# functional gradient (visual-heteromodal) data\n",
    "GSP_fc_grad = pd.read_csv(resdir_gsp+'array_aligned_fc_G2.csv')  # G2\n",
    "HCP_fc_grad = pd.read_csv(resdir_hcp+'array_aligned_fc_G1.csv')  # G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fa571052-5c13-4d84-bdb2-64af82a34a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some data columns to make them same across samples\n",
    "GSP_demographics_cleaned = GSP_demographics_cleaned.rename(columns={'Sex': 'sex', 'Age_Bin': 'age', 'ICV': 'icv'})\n",
    "HCP_demographics_cleaned = HCP_demographics_cleaned.rename(columns={'Gender': 'sex', 'Age_in_Yrs': 'age', 'FS_IntraCranial_Vol': 'icv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335391f-cd3e-4072-a3ca-3f221a1d3d45",
   "metadata": {},
   "source": [
    "## Classification with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ab356-e576-4aca-a8d2-93b30cca891e",
   "metadata": {},
   "source": [
    "### local structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8de8578f-0fb5-43aa-87dd-7e2fcc90e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e0b3f0f-2967-408b-b35f-6d060a0985ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean cross-validation accuracy is: 0.840 +/- 0.020\n"
     ]
    }
   ],
   "source": [
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "\n",
    "x_GSP = GSP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "\n",
    "##### create model via pipeline\n",
    "\n",
    "# Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "\n",
    "\n",
    "\n",
    "##### within sample cross valiation \n",
    "cv_results = cross_validate(model, x_GSP_unconf, y_GSP, cv = 10)\n",
    "scores = cv_results['test_score']\n",
    "\n",
    "print(f\"the mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf3999-0893-4ee2-aecd-cfe59f0d27bd",
   "metadata": {},
   "source": [
    "### functional gradient\n",
    "\n",
    "\n",
    "if I need to be able to distinguish the func/struct data (parcels): df = df.add_suffix('_some_suffix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0b32613a-14f0-4dfd-ae61-9434fcd67e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean cross-validation accuracy is: 0.587 +/- 0.038\n"
     ]
    }
   ],
   "source": [
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "\n",
    "x_GSP = GSP_fc_grad\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'icv']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "\n",
    "##### create model via pipeline\n",
    "\n",
    "# Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "\n",
    "\n",
    "\n",
    "##### within sample cross valiation \n",
    "cv_results = cross_validate(model, x_GSP_unconf, y_GSP, cv = 10)\n",
    "scores = cv_results['test_score']\n",
    "\n",
    "print(f\"the mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bccc3c-8dc8-4696-b901-9da0f614b4cf",
   "metadata": {},
   "source": [
    "### local structure and functional gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f0b4395a-45d2-4ff6-853a-397a05834c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean cross-validation accuracy is: 0.818 +/- 0.027\n"
     ]
    }
   ],
   "source": [
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "\n",
    "x_GSP_struct = GSP_ct_schaefer400\n",
    "x_GSP_func = GSP_fc_grad\n",
    "\n",
    "\n",
    "## confound removal (removing structural and functional data's confounding variables respectively)\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor_struct = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP_struct))\n",
    "confound_regressor_func = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'icv']]), X = np.array(x_GSP_func))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor_struct.fit(X = np.array(x_GSP_struct))\n",
    "_ = confound_regressor_func.fit(X = np.array(x_GSP_func))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_struct_unconf = confound_regressor_struct.transform(X = np.array(x_GSP_struct))\n",
    "x_GSP_func_unconf = confound_regressor_func.transform(X = np.array(x_GSP_func))\n",
    "\n",
    "# concatenate the two arrays stored in one predictor variable (800 parcels (400 structural, 400 functional)\n",
    "x_GSP_unconf = np.concatenate((x_GSP_struct_unconf, x_GSP_func_unconf), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "##### create model via pipeline\n",
    "\n",
    "# Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "\n",
    "\n",
    "\n",
    "##### within sample cross valiation \n",
    "cv_results = cross_validate(model, x_GSP_unconf, y_GSP, cv = 10)\n",
    "scores = cv_results['test_score']\n",
    "\n",
    "print(f\"the mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e2012-477e-4242-be2d-d4afd5214fbf",
   "metadata": {},
   "source": [
    "## Classification out of sample\n",
    "\n",
    "**STILL NEED TO DO: REGRESS OUT FAMILY AND TWIN IN HCP PART** https://techoverflow.net/2019/05/22/how-to-fix-numpy-typeerror-cannot-cast-ufunc-subtract-output-from-dtypefloat64-to-dtypeint64-with-casting-rule-same_kind/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b704a27-6a7b-4710-a49c-b23bea28f43a",
   "metadata": {},
   "source": [
    "### local CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3abe7b7b-f398-4756-ad6c-be012cfab93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model's out of sample prediction accuracy is: 0.736\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_GSP = GSP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "##### preprocess\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(x_GSP_unconf)\n",
    "x_GSP_unconf_scaled = scaler.transform(x_GSP_unconf)\n",
    "\n",
    "\n",
    "##### model\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "_ = model.fit(x_GSP_unconf_scaled, y_GSP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_HCP = HCP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_HCP = HCP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor # ADD Twin stat and Family ID (but categorical so make own preprocessing\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_HCP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_HCP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_HCP_unconf = confound_regressor.transform(X = np.array(x_HCP))\n",
    "\n",
    "\n",
    "##### preprocess - scale using prefitted scaler on GSP data (correct?) by simply transforming because this is test data \n",
    "    # this is what is instructed at https://stackoverflow.com/questions/57775530/why-does-calling-transform-on-test-data-return-an-error-that-the-data-is-not-f?rq=1\n",
    "x_HCP_unconf_scaled = scaler.transform(x_HCP_unconf)\n",
    "\n",
    "\n",
    "##### compute prediction accuracy\n",
    "score = model.score(x_HCP_unconf_scaled, y_HCP)\n",
    "\n",
    "print(f\"the model's out of sample prediction accuracy is: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39345e81-d4c3-463e-842f-39b25806046f",
   "metadata": {},
   "source": [
    "### TRYING TO INCLUDE CATEGORICAL CONFOUND REGRESSION BELOW: ERROR\n",
    "### TROUBLESHOOT https://techoverflow.net/2019/05/22/how-to-fix-numpy-typeerror-cannot-cast-ufunc-subtract-output-from-dtypefloat64-to-dtypeint64-with-casting-rule-same_kind/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "72551281-2588-48db-8102-a195330cd4c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'lstsq_n' input 0 from dtype('O') to dtype('float64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32906/477944775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# fit it to the predictor data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfound_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_HCP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# transform the predictor data with confound variables regressed out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32906/1126990707.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Vectorized implementation estimating weights for all features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfound_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_nz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/u_serio_software/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/data/u_serio_software/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;31m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rhs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'lstsq_n' input 0 from dtype('O') to dtype('float64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_GSP = GSP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "##### preprocess\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(x_GSP_unconf)\n",
    "x_GSP_unconf_scaled = scaler.transform(x_GSP_unconf)\n",
    "\n",
    "\n",
    "##### model\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "_ = model.fit(x_GSP_unconf_scaled, y_GSP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_HCP = HCP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_HCP = HCP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor # ADD Twin stat and Family ID (but categorical so make own preprocessing\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'global_ct', 'Family_ID', 'TwinStatus']]), X = np.array(x_HCP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_HCP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_HCP_unconf = confound_regressor.transform(X = np.array(x_HCP))\n",
    "\n",
    "\n",
    "##### preprocess - scale using prefitted scaler on GSP data (correct?) by simply transforming because this is test data \n",
    "    # this is what is instructed at https://stackoverflow.com/questions/57775530/why-does-calling-transform-on-test-data-return-an-error-that-the-data-is-not-f?rq=1\n",
    "x_HCP_unconf_scaled = scaler.transform(x_HCP_unconf)\n",
    "\n",
    "\n",
    "##### compute prediction accuracy\n",
    "score = model.score(x_HCP_unconf_scaled, y_HCP)\n",
    "\n",
    "print(f\"the model's out of sample prediction accuracy is: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c030d-aba7-4a6e-897b-d29cc586e82c",
   "metadata": {},
   "source": [
    "### functional gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5eb17f79-9518-44a9-94b5-e5b5f929de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model's out of sample prediction accuracy is: 0.598\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_GSP = GSP_fc_grad\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'icv']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "##### preprocess\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(x_GSP_unconf)\n",
    "x_GSP_unconf_scaled = scaler.transform(x_GSP_unconf)\n",
    "\n",
    "\n",
    "##### model\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "_ = model.fit(x_GSP_unconf_scaled, y_GSP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_HCP = HCP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_HCP = HCP_fc_grad\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor # ADD Twin stat and Family ID (but categorical so make own preprocessing\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'icv']]), X = np.array(x_HCP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_HCP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_HCP_unconf = confound_regressor.transform(X = np.array(x_HCP))\n",
    "\n",
    "\n",
    "##### preprocess - scale using prefitted scaler on GSP data (correct?) by simply transforming because this is test data \n",
    "    # this is what is instructed at https://stackoverflow.com/questions/57775530/why-does-calling-transform-on-test-data-return-an-error-that-the-data-is-not-f?rq=1\n",
    "x_HCP_unconf_scaled = scaler.transform(x_HCP_unconf)\n",
    "\n",
    "\n",
    "##### compute prediction accuracy\n",
    "score = model.score(x_HCP_unconf_scaled, y_HCP)\n",
    "\n",
    "print(f\"the model's out of sample prediction accuracy is: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daa481-34fe-487e-a550-cfc0ed899c5f",
   "metadata": {},
   "source": [
    "### local structure and functional gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "91eb63e8-fbbf-4280-b14c-c2b44624ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model's out of sample prediction accuracy is: 0.738\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_GSP_struct = GSP_ct_schaefer400\n",
    "x_GSP_func = GSP_fc_grad\n",
    "\n",
    "\n",
    "## confound removal (removing structural and functional data's confounding variables respectively)\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor_struct = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP_struct))\n",
    "confound_regressor_func = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'icv']]), X = np.array(x_GSP_func))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor_struct.fit(X = np.array(x_GSP_struct))\n",
    "_ = confound_regressor_func.fit(X = np.array(x_GSP_func))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_struct_unconf = confound_regressor_struct.transform(X = np.array(x_GSP_struct))\n",
    "x_GSP_func_unconf = confound_regressor_func.transform(X = np.array(x_GSP_func))\n",
    "\n",
    "# concatenate the two arrays stored in one predictor variable (800 parcels (400 structural, 400 functional)\n",
    "x_GSP_unconf = np.concatenate((x_GSP_struct_unconf, x_GSP_func_unconf), axis = 1)\n",
    "\n",
    "\n",
    "##### preprocess\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(x_GSP_unconf)\n",
    "x_GSP_unconf_scaled = scaler.transform(x_GSP_unconf)\n",
    "\n",
    "\n",
    "##### model\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "_ = model.fit(x_GSP_unconf_scaled, y_GSP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_HCP = HCP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_HCP_struct = HCP_ct_schaefer400\n",
    "x_HCP_func = HCP_fc_grad\n",
    "\n",
    "\n",
    "## confound removal (removing structural and functional data's confounding variables respectively)\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor_struct = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_HCP_struct))\n",
    "confound_regressor_func = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'icv']]), X = np.array(x_HCP_func))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor_struct.fit(X = np.array(x_HCP_struct))\n",
    "_ = confound_regressor_func.fit(X = np.array(x_HCP_func))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_HCP_struct_unconf = confound_regressor_struct.transform(X = np.array(x_HCP_struct))\n",
    "x_HCP_func_unconf = confound_regressor_func.transform(X = np.array(x_HCP_func))\n",
    "\n",
    "# concatenate the two arrays stored in one predictor variable (800 parcels (400 structural, 400 functional)\n",
    "x_HCP_unconf = np.concatenate((x_HCP_struct_unconf, x_HCP_func_unconf), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "##### preprocess - scale using prefitted scaler on GSP data (correct?) by simply transforming because this is test data \n",
    "    # this is what is instructed at https://stackoverflow.com/questions/57775530/why-does-calling-transform-on-test-data-return-an-error-that-the-data-is-not-f?rq=1\n",
    "x_HCP_unconf_scaled = scaler.transform(x_HCP_unconf)\n",
    "\n",
    "\n",
    "##### compute prediction accuracy\n",
    "score = model.score(x_HCP_unconf_scaled, y_HCP)\n",
    "\n",
    "print(f\"the model's out of sample prediction accuracy is: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16942d-0bfe-490f-bcfb-8a85fb6b59f4",
   "metadata": {},
   "source": [
    "## Classification out of sample\n",
    "\n",
    "**STILL NEED TO DO: REGRESS OUT FAMILY AND TWIN IN HCP PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24584dbb-0560-471f-af55-fe1fe3b1b54e",
   "metadata": {},
   "source": [
    "### local CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d4cb6560-7b5b-4024-8059-75a4ad639bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model's out of sample prediction accuracy is: 0.736\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_GSP = GSP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_GSP = GSP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(GSP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_GSP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_GSP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_GSP_unconf = confound_regressor.transform(X = np.array(x_GSP))\n",
    "\n",
    "\n",
    "##### preprocess\n",
    "\n",
    "scaler = StandardScaler()\n",
    "_ = scaler.fit(x_GSP_unconf)\n",
    "x_GSP_unconf_scaled = scaler.transform(x_GSP_unconf)\n",
    "\n",
    "\n",
    "##### model\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "_ = model.fit(x_GSP_unconf_scaled, y_GSP)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "##### define predictor and target variables\n",
    "\n",
    "### target: sex\n",
    "y_HCP = HCP_demographics_cleaned['sex']\n",
    "\n",
    "\n",
    "### predictor: brain data (400 parcels)\n",
    "x_HCP = HCP_ct_schaefer400\n",
    "\n",
    "## confound removal\n",
    "\n",
    "# make a preprocessor confound regressor # ADD Twin stat and Family ID (but categorical so make own preprocessing\n",
    "confound_regressor = ConfoundRegressor(confound = np.array(HCP_demographics_cleaned[['age', 'global_ct']]), X = np.array(x_HCP))\n",
    "\n",
    "# fit it to the predictor data\n",
    "_ = confound_regressor.fit(X = np.array(x_HCP))\n",
    "\n",
    "# transform the predictor data with confound variables regressed out\n",
    "x_HCP_unconf = confound_regressor.transform(X = np.array(x_HCP))\n",
    "\n",
    "\n",
    "##### preprocess - scale using prefitted scaler on GSP data (correct?) by simply transforming because this is test data \n",
    "    # this is what is instructed at https://stackoverflow.com/questions/57775530/why-does-calling-transform-on-test-data-return-an-error-that-the-data-is-not-f?rq=1\n",
    "x_HCP_unconf_scaled = scaler.transform(x_HCP_unconf)\n",
    "\n",
    "\n",
    "##### compute prediction accuracy\n",
    "score = model.score(x_HCP_unconf_scaled, y_HCP)\n",
    "\n",
    "print(f\"the model's out of sample prediction accuracy is: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fc19b-08ee-46dc-b36f-2e4dd91546b3",
   "metadata": {},
   "source": [
    "### functional gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e440b-b17c-4e7a-9515-4852380c43ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde0f63-607c-4ebd-ad94-7a40d6fcc868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c9371-0050-4a7f-84f8-d3377ddc4a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993cdeb-fe7e-4511-9170-f25a6a7725a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb2414-a5c7-426a-81b2-0a3f43d8563a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03305e5c-77ae-42e6-980f-798b21a9b3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8d19c04-3fa9-4d4e-89c6-b7e271a58b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9bdde6-05d8-4866-802d-b1a1fc47b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 1.]]\n",
      "[0 1]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# get support vectors (=training data)\n",
    "print(clf.support_vectors_)\n",
    "\n",
    "# get indices of support vectors\n",
    "print(clf.support_)\n",
    "\n",
    "# get number of support vectors for each class\n",
    "print(clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abc5db-0079-4c05-9e3b-946bbb241e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6399ec-d0e4-48cb-af50-fa2d642343c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6044d-fb37-456c-ad02-836ab1240ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203580ed-3994-4f10-84c2-d2dd61348d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371d991-e76d-4385-9018-fb805ae04140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2358c1-1a71-49da-9749-9656fffbac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60be64f-2ef6-43eb-8d60-41daba86a845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eb8a78ca-e85b-4a71-b209-ad7ea61be2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>struct_1struct_</th>\n",
       "      <th>struct_ 2struct_</th>\n",
       "      <th>struct_ 3struct_</th>\n",
       "      <th>struct_ 4struct_</th>\n",
       "      <th>struct_ 5struct_</th>\n",
       "      <th>struct_ 6struct_</th>\n",
       "      <th>struct_ 7struct_</th>\n",
       "      <th>struct_ 8struct_</th>\n",
       "      <th>struct_ 9struct_</th>\n",
       "      <th>struct_ 10struct_</th>\n",
       "      <th>...</th>\n",
       "      <th>struct_ 391struct_</th>\n",
       "      <th>struct_ 392struct_</th>\n",
       "      <th>struct_ 393struct_</th>\n",
       "      <th>struct_ 394struct_</th>\n",
       "      <th>struct_ 395struct_</th>\n",
       "      <th>struct_ 396struct_</th>\n",
       "      <th>struct_ 397struct_</th>\n",
       "      <th>struct_ 398struct_</th>\n",
       "      <th>struct_ 399struct_</th>\n",
       "      <th>struct_ 400struct_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.093285</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>-0.090736</td>\n",
       "      <td>-0.106147</td>\n",
       "      <td>-0.094011</td>\n",
       "      <td>-0.098007</td>\n",
       "      <td>-0.025013</td>\n",
       "      <td>-0.098085</td>\n",
       "      <td>-0.088955</td>\n",
       "      <td>-0.046987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084511</td>\n",
       "      <td>0.053425</td>\n",
       "      <td>0.052758</td>\n",
       "      <td>0.025645</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.100447</td>\n",
       "      <td>0.083106</td>\n",
       "      <td>0.083238</td>\n",
       "      <td>0.102053</td>\n",
       "      <td>-0.013530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024041</td>\n",
       "      <td>0.105338</td>\n",
       "      <td>-0.071556</td>\n",
       "      <td>-0.059716</td>\n",
       "      <td>-0.104843</td>\n",
       "      <td>-0.086958</td>\n",
       "      <td>0.065324</td>\n",
       "      <td>-0.078393</td>\n",
       "      <td>-0.091654</td>\n",
       "      <td>-0.077376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.056192</td>\n",
       "      <td>-0.060981</td>\n",
       "      <td>-0.021545</td>\n",
       "      <td>0.133430</td>\n",
       "      <td>0.072175</td>\n",
       "      <td>-0.015382</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.108403</td>\n",
       "      <td>0.005609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.049901</td>\n",
       "      <td>0.059752</td>\n",
       "      <td>-0.125352</td>\n",
       "      <td>-0.064487</td>\n",
       "      <td>-0.093566</td>\n",
       "      <td>-0.110654</td>\n",
       "      <td>-0.019181</td>\n",
       "      <td>-0.132276</td>\n",
       "      <td>-0.071831</td>\n",
       "      <td>-0.114914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070498</td>\n",
       "      <td>0.056943</td>\n",
       "      <td>0.056084</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.083126</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>0.012058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015274</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>-0.075639</td>\n",
       "      <td>-0.127220</td>\n",
       "      <td>-0.123355</td>\n",
       "      <td>-0.117995</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>-0.071264</td>\n",
       "      <td>-0.010436</td>\n",
       "      <td>-0.116792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096095</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.057976</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>0.122786</td>\n",
       "      <td>0.123089</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>0.071941</td>\n",
       "      <td>0.117249</td>\n",
       "      <td>0.074399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017485</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>-0.089764</td>\n",
       "      <td>-0.059690</td>\n",
       "      <td>-0.096601</td>\n",
       "      <td>-0.084487</td>\n",
       "      <td>-0.052344</td>\n",
       "      <td>-0.090220</td>\n",
       "      <td>-0.095404</td>\n",
       "      <td>-0.074597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076119</td>\n",
       "      <td>0.048153</td>\n",
       "      <td>-0.039816</td>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.094465</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.072920</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>-0.120128</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>-0.137043</td>\n",
       "      <td>-0.146324</td>\n",
       "      <td>-0.122973</td>\n",
       "      <td>-0.094081</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>-0.062940</td>\n",
       "      <td>-0.113368</td>\n",
       "      <td>-0.122586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061912</td>\n",
       "      <td>0.033051</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.063845</td>\n",
       "      <td>0.055230</td>\n",
       "      <td>0.047795</td>\n",
       "      <td>0.054769</td>\n",
       "      <td>0.080993</td>\n",
       "      <td>0.021291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.059904</td>\n",
       "      <td>-0.057393</td>\n",
       "      <td>-0.095516</td>\n",
       "      <td>-0.087502</td>\n",
       "      <td>-0.062153</td>\n",
       "      <td>-0.012518</td>\n",
       "      <td>-0.064893</td>\n",
       "      <td>-0.079708</td>\n",
       "      <td>-0.096062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078555</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>-0.048281</td>\n",
       "      <td>-0.081537</td>\n",
       "      <td>0.110326</td>\n",
       "      <td>0.090343</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>-0.060747</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>-0.020079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>-0.065135</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>-0.088779</td>\n",
       "      <td>-0.092067</td>\n",
       "      <td>-0.082901</td>\n",
       "      <td>-0.047635</td>\n",
       "      <td>-0.061776</td>\n",
       "      <td>-0.088769</td>\n",
       "      <td>-0.014669</td>\n",
       "      <td>-0.081091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>-0.005900</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.053522</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>0.069221</td>\n",
       "      <td>0.086213</td>\n",
       "      <td>0.037602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0.020420</td>\n",
       "      <td>0.025629</td>\n",
       "      <td>-0.129486</td>\n",
       "      <td>-0.121391</td>\n",
       "      <td>-0.141431</td>\n",
       "      <td>-0.131816</td>\n",
       "      <td>0.071019</td>\n",
       "      <td>-0.030575</td>\n",
       "      <td>-0.127403</td>\n",
       "      <td>-0.066715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>0.069310</td>\n",
       "      <td>0.044957</td>\n",
       "      <td>0.063577</td>\n",
       "      <td>0.088689</td>\n",
       "      <td>0.090828</td>\n",
       "      <td>0.074498</td>\n",
       "      <td>0.066097</td>\n",
       "      <td>0.085203</td>\n",
       "      <td>0.068996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>-0.070745</td>\n",
       "      <td>-0.041746</td>\n",
       "      <td>-0.163064</td>\n",
       "      <td>-0.160050</td>\n",
       "      <td>-0.163389</td>\n",
       "      <td>-0.037995</td>\n",
       "      <td>0.059813</td>\n",
       "      <td>-0.144050</td>\n",
       "      <td>-0.052062</td>\n",
       "      <td>-0.165908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>0.081411</td>\n",
       "      <td>0.058645</td>\n",
       "      <td>0.073659</td>\n",
       "      <td>0.135327</td>\n",
       "      <td>0.129526</td>\n",
       "      <td>0.122194</td>\n",
       "      <td>0.147377</td>\n",
       "      <td>0.142277</td>\n",
       "      <td>0.008010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1568 rows  400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      struct_1struct_  struct_ 2struct_  struct_ 3struct_  struct_ 4struct_  \\\n",
       "0           -0.093285          0.014340         -0.090736         -0.106147   \n",
       "1            0.024041          0.105338         -0.071556         -0.059716   \n",
       "2           -0.049901          0.059752         -0.125352         -0.064487   \n",
       "3           -0.015274          0.054603         -0.075639         -0.127220   \n",
       "4           -0.017485          0.035287         -0.089764         -0.059690   \n",
       "...               ...               ...               ...               ...   \n",
       "1563        -0.120128          0.044156         -0.137043         -0.146324   \n",
       "1564         0.009092          0.059904         -0.057393         -0.095516   \n",
       "1565        -0.065135         -0.008746         -0.088779         -0.092067   \n",
       "1566         0.020420          0.025629         -0.129486         -0.121391   \n",
       "1567        -0.070745         -0.041746         -0.163064         -0.160050   \n",
       "\n",
       "      struct_ 5struct_  struct_ 6struct_  struct_ 7struct_  struct_ 8struct_  \\\n",
       "0            -0.094011         -0.098007         -0.025013         -0.098085   \n",
       "1            -0.104843         -0.086958          0.065324         -0.078393   \n",
       "2            -0.093566         -0.110654         -0.019181         -0.132276   \n",
       "3            -0.123355         -0.117995          0.012339         -0.071264   \n",
       "4            -0.096601         -0.084487         -0.052344         -0.090220   \n",
       "...                ...               ...               ...               ...   \n",
       "1563         -0.122973         -0.094081          0.008933         -0.062940   \n",
       "1564         -0.087502         -0.062153         -0.012518         -0.064893   \n",
       "1565         -0.082901         -0.047635         -0.061776         -0.088769   \n",
       "1566         -0.141431         -0.131816          0.071019         -0.030575   \n",
       "1567         -0.163389         -0.037995          0.059813         -0.144050   \n",
       "\n",
       "      struct_ 9struct_  struct_ 10struct_  ...  struct_ 391struct_  \\\n",
       "0            -0.088955          -0.046987  ...            0.084511   \n",
       "1            -0.091654          -0.077376  ...            0.083916   \n",
       "2            -0.071831          -0.114914  ...            0.070498   \n",
       "3            -0.010436          -0.116792  ...            0.096095   \n",
       "4            -0.095404          -0.074597  ...            0.076119   \n",
       "...                ...                ...  ...                 ...   \n",
       "1563         -0.113368          -0.122586  ...            0.061912   \n",
       "1564         -0.079708          -0.096062  ...            0.078555   \n",
       "1565         -0.014669          -0.081091  ...            0.066905   \n",
       "1566         -0.127403          -0.066715  ...            0.033368   \n",
       "1567         -0.052062          -0.165908  ...            0.090009   \n",
       "\n",
       "      struct_ 392struct_  struct_ 393struct_  struct_ 394struct_  \\\n",
       "0               0.053425            0.052758            0.025645   \n",
       "1               0.056192           -0.060981           -0.021545   \n",
       "2               0.056943            0.056084            0.029230   \n",
       "3               0.061396            0.057976           -0.001887   \n",
       "4               0.048153           -0.039816           -0.015104   \n",
       "...                  ...                 ...                 ...   \n",
       "1563            0.033051            0.004043            0.032202   \n",
       "1564            0.044381           -0.048281           -0.081537   \n",
       "1565           -0.005900           -0.004692            0.031398   \n",
       "1566            0.069310            0.044957            0.063577   \n",
       "1567            0.081411            0.058645            0.073659   \n",
       "\n",
       "      struct_ 395struct_  struct_ 396struct_  struct_ 397struct_  \\\n",
       "0               0.109971            0.100447            0.083106   \n",
       "1               0.133430            0.072175           -0.015382   \n",
       "2               0.083126            0.078022            0.079190   \n",
       "3               0.122786            0.123089            0.078660   \n",
       "4               0.094465            0.077439            0.037047   \n",
       "...                  ...                 ...                 ...   \n",
       "1563            0.063845            0.055230            0.047795   \n",
       "1564            0.110326            0.090343            0.013574   \n",
       "1565            0.053522            0.053951            0.072585   \n",
       "1566            0.088689            0.090828            0.074498   \n",
       "1567            0.135327            0.129526            0.122194   \n",
       "\n",
       "      struct_ 398struct_  struct_ 399struct_  struct_ 400struct_  \n",
       "0               0.083238            0.102053           -0.013530  \n",
       "1               0.053279            0.108403            0.005609  \n",
       "2               0.038425            0.073943            0.012058  \n",
       "3               0.071941            0.117249            0.074399  \n",
       "4               0.036123            0.072920            0.005451  \n",
       "...                  ...                 ...                 ...  \n",
       "1563            0.054769            0.080993            0.021291  \n",
       "1564           -0.060747            0.108213           -0.020079  \n",
       "1565            0.069221            0.086213            0.037602  \n",
       "1566            0.066097            0.085203            0.068996  \n",
       "1567            0.147377            0.142277            0.008010  \n",
       "\n",
       "[1568 rows x 400 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_GSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b965fd00-f791-4298-8185-62af9d8e4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_GSP = x_GSP.add_prefix('struct_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb06eff-8075-4791-9399-fe4eb676d50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d72bd0-b8bc-476f-9d23-bd215bc7145c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68ad3c-6ec2-4fa8-8ac6-e56b9dbbf8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d49a0e5-d628-439b-8afd-13be01cc7e4b",
   "metadata": {},
   "source": [
    "Sofie's script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553ce49-8e33-4e9f-86bf-485c64c47a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a python script for running supervised machine learning to predict compassion score\n",
    "\n",
    "data input : foldname\n",
    "\n",
    "data output $np.save..... \n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import sklearn.linear_model as slm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_data = pd.read_csv ('../data/attention_data.csv')\n",
    "sex_code = df_data['sex1'].unique()\n",
    "if type(sex_code[0]) == str:\n",
    "    sex_dict = {k: idx for idx, k in enumerate(sex_code)}\n",
    "    df_data['sex1'] = df_data['sex1'].replace(sex_dict)  \n",
    "\n",
    "\n",
    "def model_elasticnet(m): # l1_ratio\n",
    "  print('m', str(m))\n",
    "\n",
    "  dic = {}\n",
    "  for i in range(sample): \n",
    "    lr = slm.ElasticNetCV(alphas=[0.0001, 0.001, 0.01, 0.1, 1], l1_ratio=m, cv=5)\n",
    "    sfs = SFS(lr, k_features=7, forward=True, floating=False, n_jobs=-1,\n",
    "              scoring='neg_mean_absolute_error', cv=False)\n",
    "    model = sfs.fit(x_correct[i], y_train[i])\n",
    "    x_1 = model.transform(x_correct[i])\n",
    "    x_2 = model.transform(x_test_corr[i])\n",
    "    model2 = lr.fit(x_1, y_train[i])\n",
    "    y_pred = lr.predict(x_2)\n",
    "    corr = ss.pearsonr(y_pred, y_test[i])\n",
    "    a = model.get_metric_dict()[7]\n",
    "    a['importance'] = model.estimator.coef_\n",
    "    a['intercept'] = model.estimator.intercept_\n",
    "    a['alpha_best'] = model.estimator.alpha_\n",
    "    a['predict_test_r_p'] = np.array(corr)\n",
    "    a['mean_lr_mse']  = model2.mse_path_.mean()\n",
    "    dic['train_test_'+str(i+1)] = a\n",
    "    print('finish model......', str(i+1))\n",
    "    print(a)\n",
    "  np.save('../results/'+foldname+'feature_20_l1ratio_' + str(m)+ 'zscore.npy', dic)\n",
    "  return print('feature_' + str(20) + '_l1ratio_' + str(m)+'   finished')\n",
    "\n",
    "foldname=['attention']\n",
    "for foldname in foldname:\n",
    "\n",
    "  # IMPORT sample train_test iterations\n",
    "  sample = 100\n",
    "\n",
    "  x_train = [None] * sample\n",
    "  y_train = [None] * sample\n",
    "  x_test = [None] * sample\n",
    "  y_test = [None] * sample\n",
    "  x_correct = [None]  * sample\n",
    "  x_test_corr = [None] * sample\n",
    "  for i in range(sample):\n",
    "    Y_col = 'val1'\n",
    "    X_cols = df_data.loc[:, df_data.columns != Y_col].columns\n",
    "\n",
    "    x_train[i], x_test[i], y_train[i], y_test[i] = train_test_split(        \n",
    "          df_data[X_cols], df_data.iloc[:, 1], test_size=0.3, random_state=i)\n",
    "\t\n",
    "    x_conf = x_train[i].iloc[:,[2,3]]\n",
    "    y_conf = x_train[i].iloc[:,4:39]\n",
    "    x, y   = np.array(x_conf), np.array(y_conf)\n",
    "    model_conf = LinearRegression().fit(x, y)\n",
    "    y_pred = model_conf.predict(x)\n",
    "    x_correct[i] = y  - y_pred\n",
    "    x_conf = x_test[i].iloc[:,[2,3]]\n",
    "    y_conf = x_test[i].iloc[:,4:39]\n",
    "    x, y   = np.array(x_conf), np.array(y_conf)\n",
    "    model_conf = LinearRegression().fit(x, y)\n",
    "    y_pred = model_conf.predict(x)\n",
    "    x_test_corr[i] = y  - y_pred\n",
    "\n",
    "\n",
    "  regulation = [1.0]\n",
    "\n",
    "  for j in regulation:\n",
    "    model_elasticnet(m=j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
